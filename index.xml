<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
      <title>rushiagr</title>
      <generator uri="https://hugo.spf13.com">Hugo</generator>
    <link>http://rushiagr.com/</link>
    <language>en-us</language>
    <author>Rushi Agrawal</author>
    <copyright>2016 Rushi Agrawal</copyright>
    <updated>Sun, 24 Jan 2016 11:14:25 UTC</updated>
    
    
    
    
    <item>
      <title>Tmux session shortcuts</title>
      <link>http://rushiagr.com/blog/2016/01/10/tmux-session-shortcuts/</link>
      <pubDate>Sun, 10 Jan 2016 00:00:00 &#43;0000</pubDate>
      <author>Rushi Agrawal</author>
      <guid>http://rushiagr.com/blog/2016/01/10/tmux-session-shortcuts/</guid>
      <description>

&lt;p&gt;Tmux is awesome. But the session management commands are way too long for my
liking. Listing all sessions is &lt;code&gt;tmux list-sessions&lt;/code&gt;, attaching to a session
&lt;code&gt;mysession&lt;/code&gt; is &lt;code&gt;tmux attach -t mysession&lt;/code&gt;, etc.&lt;/p&gt;

&lt;p&gt;So I created a few functions and aliases, which can be found
&lt;a href=&#34;https://github.com/rushiagr/myutils/blob/master/aliases/tmux.sh&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;The general idea is, all commands start with &lt;code&gt;mx&lt;/code&gt;, which is basically a
shortcut for &amp;lsquo;tMuX&amp;rsquo;. So &lt;code&gt;mxl&lt;/code&gt; is to &amp;lsquo;l&amp;rsquo;ist tmux sessions, &lt;code&gt;mxa&lt;/code&gt; is to &amp;lsquo;a&amp;rsquo;ttach
to a tmux session, etc.&lt;/p&gt;

&lt;p&gt;List all running tmux sessions&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;r@rushi:~$ mxl
0: 4 windows (created Sun Jan 10 17:14:11 2016) [89x23] (attached)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;You can see one tmux session. Let&amp;rsquo;s create another tmux session with name
&lt;code&gt;dev&lt;/code&gt;.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;mx dev
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;List all sessions now&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;r@rushi:~$ mxl
0: 4 windows (created Sun Jan 10 17:14:11 2016) [89x23] (attached)
dev: 1 windows (created Sun Jan 10 17:59:30 2016) [89x23] (attached)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;To attach to session with name &lt;code&gt;dev&lt;/code&gt;:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;mxa dev
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;You can also omit session name, and it will attach to the last session you
attached to.&lt;/p&gt;

&lt;p&gt;If there was no session with name &lt;code&gt;dev2&lt;/code&gt;, and you type this:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;mxa dev2
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;It will automatically create a session for you and attach you to it.&lt;/p&gt;

&lt;p&gt;To detach:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;mxd
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;I find this &lt;code&gt;mxd&lt;/code&gt; to be easier to type than both &lt;code&gt;CTRL&lt;/code&gt;+&lt;code&gt;d&lt;/code&gt; and &lt;code&gt;tmux
detach&lt;/code&gt;.&lt;/p&gt;

&lt;h3 id=&#34;installation:e0f68b4969c4b0e373b3bdfb560cffb9&#34;&gt;Installation&lt;/h3&gt;

&lt;p&gt;You just need to copy the content in the above referenced link to &lt;code&gt;~/.bashrc&lt;/code&gt;
file and from a new terminal session things will be ready for you to use :)&lt;/p&gt;
</description>
    </item>
    
    
    
    <item>
      <title>Better AWS Command Line Interface</title>
      <link>http://rushiagr.com/blog/2016/01/02/better-aws-command-line-interface/</link>
      <pubDate>Sat, 02 Jan 2016 00:00:00 &#43;0000</pubDate>
      <author>Rushi Agrawal</author>
      <guid>http://rushiagr.com/blog/2016/01/02/better-aws-command-line-interface/</guid>
      <description>

&lt;p&gt;When I first tried to use the AWS CLIs provided by Amazon, I found them not so
human-friendly. Sure, maybe they&amp;rsquo;re good for automating stuff, but if you just
want to view the public IP of a virtual machine, and the CLI throws this on
your screen for just one VM instance, you&amp;rsquo;re likely not going to be impressed:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;r@rushi:~$ aws ec2 describe-instances
{
    &amp;quot;Reservations&amp;quot;: [
        {
            &amp;quot;OwnerId&amp;quot;: &amp;quot;123456789012&amp;quot;,
            &amp;quot;ReservationId&amp;quot;: &amp;quot;r-abcd1234&amp;quot;,
            &amp;quot;Groups&amp;quot;: [],
            &amp;quot;Instances&amp;quot;: [
                {
                    &amp;quot;Monitoring&amp;quot;: {
                        &amp;quot;State&amp;quot;: &amp;quot;disabled&amp;quot;
                    },
                    &amp;quot;PublicDnsName&amp;quot;: &amp;quot;ec2-52-52-52-52.ap-southeast-1.compute.amazonaws.com&amp;quot;,
                    &amp;quot;State&amp;quot;: {
                        &amp;quot;Code&amp;quot;: 16,
                        &amp;quot;Name&amp;quot;: &amp;quot;running&amp;quot;
                    },
                    &amp;quot;EbsOptimized&amp;quot;: false,
                    &amp;quot;LaunchTime&amp;quot;: &amp;quot;2015-12-31T12:59:59.000Z&amp;quot;,
                    &amp;quot;PublicIpAddress&amp;quot;: &amp;quot;52.52.52.52&amp;quot;,
                    &amp;quot;PrivateIpAddress&amp;quot;: &amp;quot;172.31.31.31&amp;quot;,
                    &amp;quot;ProductCodes&amp;quot;: [],
                    &amp;quot;VpcId&amp;quot;: &amp;quot;vpc-1234abcd&amp;quot;,
                    &amp;quot;StateTransitionReason&amp;quot;: &amp;quot;&amp;quot;,
                    &amp;quot;InstanceId&amp;quot;: &amp;quot;i-1234abcd&amp;quot;,
                    &amp;quot;ImageId&amp;quot;: &amp;quot;ami-1234abcd&amp;quot;,
                    &amp;quot;PrivateDnsName&amp;quot;: &amp;quot;ip-172-31-31-31.ap-southeast-1.compute.internal&amp;quot;,
                    &amp;quot;KeyName&amp;quot;: &amp;quot;mykey&amp;quot;,
                    &amp;quot;SecurityGroups&amp;quot;: [
                        {
                            &amp;quot;GroupName&amp;quot;: &amp;quot;rushi-sg&amp;quot;,
                            &amp;quot;GroupId&amp;quot;: &amp;quot;sg-abcd1234&amp;quot;
                        }
                    ],
                    &amp;quot;ClientToken&amp;quot;: &amp;quot;&amp;quot;,
                    &amp;quot;SubnetId&amp;quot;: &amp;quot;subnet-abcd1234&amp;quot;,
                    &amp;quot;InstanceType&amp;quot;: &amp;quot;t2.micro&amp;quot;,
                    &amp;quot;NetworkInterfaces&amp;quot;: [
                        {
                            &amp;quot;Status&amp;quot;: &amp;quot;in-use&amp;quot;,
                            &amp;quot;MacAddress&amp;quot;: &amp;quot;06:f3:82:a1:fb:c5&amp;quot;,
                            &amp;quot;SourceDestCheck&amp;quot;: true,
                            &amp;quot;VpcId&amp;quot;: &amp;quot;vpc-abcd1234&amp;quot;,
                            &amp;quot;Description&amp;quot;: &amp;quot;&amp;quot;,
                            &amp;quot;Association&amp;quot;: {
                                &amp;quot;PublicIp&amp;quot;: &amp;quot;52.52.52.52&amp;quot;,
                                &amp;quot;PublicDnsName&amp;quot;: &amp;quot;ec2-52-52-52-52.ap-southeast-1.compute.amazonaws.com&amp;quot;,
                                &amp;quot;IpOwnerId&amp;quot;: &amp;quot;amazon&amp;quot;
                            },
                            &amp;quot;NetworkInterfaceId&amp;quot;: &amp;quot;eni-abcd1234&amp;quot;,
                            &amp;quot;PrivateIpAddresses&amp;quot;: [
                                {
                                    &amp;quot;PrivateDnsName&amp;quot;: &amp;quot;ip-172-31-31-32.ap-southeast-1.compute.internal&amp;quot;,
                                    &amp;quot;Association&amp;quot;: {
                                        &amp;quot;PublicIp&amp;quot;: &amp;quot;52.52.52.52&amp;quot;,
                                        &amp;quot;PublicDnsName&amp;quot;: &amp;quot;ec2-52-52-52-52.ap-southeast-1.compute.amazonaws.com&amp;quot;,
                                        &amp;quot;IpOwnerId&amp;quot;: &amp;quot;amazon&amp;quot;
                                    },
                                    &amp;quot;Primary&amp;quot;: true,
                                    &amp;quot;PrivateIpAddress&amp;quot;: &amp;quot;172.31.31.31&amp;quot;
                                }
                            ],
                            &amp;quot;PrivateDnsName&amp;quot;: &amp;quot;ip-172-31-31-31.ap-southeast-1.compute.internal&amp;quot;,
                            &amp;quot;Attachment&amp;quot;: {
                                &amp;quot;Status&amp;quot;: &amp;quot;attached&amp;quot;,
                                &amp;quot;DeviceIndex&amp;quot;: 0,
                                &amp;quot;DeleteOnTermination&amp;quot;: true,
                                &amp;quot;AttachmentId&amp;quot;: &amp;quot;eni-attach-abcd1234&amp;quot;,
                                &amp;quot;AttachTime&amp;quot;: &amp;quot;2015-12-31T12:59:59.000Z&amp;quot;
                            },
                            &amp;quot;Groups&amp;quot;: [
                                {
                                    &amp;quot;GroupName&amp;quot;: &amp;quot;mygroup&amp;quot;,
                                    &amp;quot;GroupId&amp;quot;: &amp;quot;sg-abcd1234&amp;quot;
                                }
                            ],
                            &amp;quot;SubnetId&amp;quot;: &amp;quot;subnet-abcd1234&amp;quot;,
                            &amp;quot;OwnerId&amp;quot;: &amp;quot;123456789012&amp;quot;,
                            &amp;quot;PrivateIpAddress&amp;quot;: &amp;quot;172.31.31.31&amp;quot;
                        }
                    ],
                    &amp;quot;SourceDestCheck&amp;quot;: true,
                    &amp;quot;Placement&amp;quot;: {
                        &amp;quot;Tenancy&amp;quot;: &amp;quot;default&amp;quot;,
                        &amp;quot;GroupName&amp;quot;: &amp;quot;&amp;quot;,
                        &amp;quot;AvailabilityZone&amp;quot;: &amp;quot;ap-southeast-1a&amp;quot;
                    },
                    &amp;quot;Hypervisor&amp;quot;: &amp;quot;xen&amp;quot;,
                    &amp;quot;BlockDeviceMappings&amp;quot;: [
                        {
                            &amp;quot;DeviceName&amp;quot;: &amp;quot;/dev/sda1&amp;quot;,
                            &amp;quot;Ebs&amp;quot;: {
                                &amp;quot;Status&amp;quot;: &amp;quot;attached&amp;quot;,
                                &amp;quot;DeleteOnTermination&amp;quot;: true,
                                &amp;quot;VolumeId&amp;quot;: &amp;quot;vol-abcd1234&amp;quot;,
                                &amp;quot;AttachTime&amp;quot;: &amp;quot;2015-12-31T12:59:59.000Z&amp;quot;
                            }
                        }
                    ],
                    &amp;quot;Architecture&amp;quot;: &amp;quot;x86_64&amp;quot;,
                    &amp;quot;RootDeviceType&amp;quot;: &amp;quot;ebs&amp;quot;,
                    &amp;quot;RootDeviceName&amp;quot;: &amp;quot;/dev/sda1&amp;quot;,
                    &amp;quot;VirtualizationType&amp;quot;: &amp;quot;hvm&amp;quot;,
                    &amp;quot;Tags&amp;quot;: [
                        {
                            &amp;quot;Value&amp;quot;: &amp;quot;rushi some VM&amp;quot;,
                            &amp;quot;Key&amp;quot;: &amp;quot;Name&amp;quot;
                        }
                    ],
                    &amp;quot;AmiLaunchIndex&amp;quot;: 0
                }
            ]
        },
    ]
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The only things I&amp;rsquo;m interested in, after creating a VM is to see it&amp;rsquo;s public
IP, it&amp;rsquo;s flavor, volume size, and instance name. The JSON output which it
throws on my face makes viewing that basic information much harder.&lt;/p&gt;

&lt;p&gt;Fortunately, I am a programmer. So I wrote a simple CLI: &lt;code&gt;lsvm&lt;/code&gt;:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;r@rushi:~$ lsvm -h
lsvm [-h] [-s] [&amp;lt;name&amp;gt;]
    -h      Prints helptext and exits
    -s      Prints sizes of VM disks in GB, starting with root disk
    &amp;lt;name&amp;gt;  Only prints VM whose name contains &#39;&amp;lt;name&amp;gt;&#39;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Installing the CLI is simple. Just run this command:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;sudo sh -c &amp;quot;$(wget -q https://raw.githubusercontent.com/rushiagr/public/master/scripts/simplest-aws-cli.sh -O -)&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Ensure that you have internet connection before running this command, and also
make sure that your computer can run &lt;code&gt;pip&lt;/code&gt; commands. Keep your access and
secret key handy.&lt;/p&gt;

&lt;h3 id=&#34;list-all-the-vm-instances:a9c5ded79a164e4b6c02d02a570b1d97&#34;&gt;List all the VM instances&lt;/h3&gt;

&lt;pre&gt;&lt;code&gt;r@rushi:~$ lsvm
    ID              Name           Status   Flavor        IP      Vols
i-abcd1234     rushi dev m/c      running  t2.micro 52.12.123.123  1
i-abcd1233   rushi pkg builder    running  t2.micro 52.12.123.122  1
i-abcd1232 rushi vanilla devstack running  t2.large 54.12.123.121  1
i-abcd1231  rushi dbaas devstack  running m4.xlarge 52.12.123.120  1
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;List all VMs whose name contains word &amp;lsquo;devstack&amp;rsquo;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;r@rushi:~$ lsvm
    ID              Name           Status   Flavor        IP      Vols
i-abcd1232 rushi vanilla devstack running  t2.large 54.12.123.121  1
i-abcd1231  rushi dbaas devstack  running m4.xlarge 52.12.123.120  1
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Show sizes of volumes of instances:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;r@rushi:~$ lsvm  -s
    ID                   Name               Status   Flavor        IP       Vols(GB)
i-abcd1234          rushi dev m/c          running  t2.micro 52.12.123.123    [8]
i-abcd1233        rushi pkg builder        running  t2.micro 52.12.123.122    [8]
i-abcd1232      rushi vanilla devstack     running  t2.large 54.12.123.121    [50]
i-abcd1231       rushi dbaas devstack      running m4.xlarge 52.12.123.120    [50]
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;creating-vm-instance:a9c5ded79a164e4b6c02d02a570b1d97&#34;&gt;Creating VM instance&lt;/h3&gt;

&lt;p&gt;Creating a VM instance is tough too, with AWS CLI, so I made another command
&lt;code&gt;mkvm&lt;/code&gt; (installed already with the previous script) which is very intuitive for human use. It asks for information in a
step-by-step manner - exactly the way a human sitting in front of a computer should be
treated with:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;r@rushi:~$ mkvm
Only Ubuntu image supported as of now
Available flavors: [&#39;t1.micro&#39;, &#39;m1.small&#39;, &#39;m1.medium&#39;, &#39;m1.large&#39;, &#39;m1.xlarge&#39;, &#39;m3.medium&#39;, &#39;m3.large&#39;, &#39;m3.xlarge&#39;, &#39;m3.2xlarge&#39;, &#39;m4.large&#39;, &#39;m4.xlarge&#39;, &#39;m4.2xlarge&#39;, &#39;m4.4xlarge&#39;, &#39;m4.10xlarge&#39;, &#39;t2.micro&#39;, &#39;t2.small&#39;, &#39;t2.medium&#39;, &#39;t2.large&#39;, &#39;m2.xlarge&#39;, &#39;m2.2xlarge&#39;, &#39;m2.4xlarge&#39;, &#39;cr1.8xlarge&#39;, &#39;i2.xlarge&#39;, &#39;i2.2xlarge&#39;, &#39;i2.4xlarge&#39;, &#39;i2.8xlarge&#39;, &#39;hi1.4xlarge&#39;, &#39;hs1.8xlarge&#39;, &#39;c1.medium&#39;, &#39;c1.xlarge&#39;, &#39;c3.large&#39;, &#39;c3.xlarge&#39;, &#39;c3.2xlarge&#39;, &#39;c3.4xlarge&#39;, &#39;c3.8xlarge&#39;, &#39;c4.large&#39;, &#39;c4.xlarge&#39;, &#39;c4.2xlarge&#39;, &#39;c4.4xlarge&#39;, &#39;c4.8xlarge&#39;, &#39;cc1.4xlarge&#39;, &#39;cc2.8xlarge&#39;, &#39;g2.2xlarge&#39;, &#39;cg1.4xlarge&#39;, &#39;r3.large&#39;, &#39;r3.xlarge&#39;, &#39;r3.2xlarge&#39;, &#39;r3.4xlarge&#39;, &#39;r3.8xlarge&#39;, &#39;d2.xlarge&#39;, &#39;d2.2xlarge&#39;, &#39;d2.4xlarge&#39;, &#39;d2.8xlarge&#39;]
Select flavor [&#39;l&#39; to list]: t2.micro
Available key pairs: [&#39;rushi-kp-1&#39;, &#39;prod-keypair&#39;, &#39;test-keypair&#39;]
Select keypair: rushi-kp-1
Available security groups: [&#39;Rushi SecGroup&#39;, &#39;openToAll&#39;, &#39;Rushi SG&#39;, &#39;Rushi Devstack SG&#39;]
Select security group. None to create new one: Rushi SecGroup
Enter root volume size in GBs: 8
r@rushi:~$
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;ending-notes:a9c5ded79a164e4b6c02d02a570b1d97&#34;&gt;Ending notes&lt;/h3&gt;

&lt;p&gt;The AWS CLI was created maybe to help automation, but they&amp;rsquo;re not quite
suitable for human use. Here is my attempt to show to the world how the things
could be made easier for human consumption. I use these commands quite a lot
when I want to quickly create a VM, or want to get information about already
created VMs. Logging in into the console is way too slow for my liking.&lt;/p&gt;

&lt;p&gt;Just to recap:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;The commands are shorter, so you have to type less&lt;/li&gt;
&lt;li&gt;The output is concise - only important information is included&lt;/li&gt;
&lt;li&gt;&lt;code&gt;mkvm&lt;/code&gt; provides you with information which you&amp;rsquo;ll require while creating the
instances, e.g. security group names, etc.&lt;/li&gt;
&lt;li&gt;Nowhere do you need to specify (hexadecimal) IDs while creating VMs&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;I just spent a few hours over the weekend to get this working. So obviously
the code is going to have rough edges, frowned-upon software practices, and a
lot of unhandled edge cases. I&amp;rsquo;ll be pretty excited if you want to help wit
the idea! I&amp;rsquo;ve created a repository at
&lt;a href=&#34;http://github.com/rushiagr/aclih&#34;&gt;http://github.com/rushiagr/aclih&lt;/a&gt; where
please feel free to submit pull requests or issues. Interested in writing
&amp;lsquo;rmvm&amp;rsquo; to delete VM anyone? :)&lt;/p&gt;

&lt;p&gt;Thank you :)&lt;/p&gt;
</description>
    </item>
    
    
    
    <item>
      <title>Build VM Images using Diskimage-builder</title>
      <link>http://rushiagr.com/blog/2016/01/02/build-vm-image-using-diskimage-builder/</link>
      <pubDate>Sat, 02 Jan 2016 00:00:00 &#43;0000</pubDate>
      <author>Rushi Agrawal</author>
      <guid>http://rushiagr.com/blog/2016/01/02/build-vm-image-using-diskimage-builder/</guid>
      <description>&lt;p&gt;OpenStack has this nice tool &lt;a href=&#34;https://github.com/openstack/diskimage-builder&#34;&gt;diskimage-builder&lt;/a&gt;to create virtual machine images without the need
of a cloud. These vm images can then be uploaded to cloud (e.g. in Glance for
OpenStack cloud), and they become immediately usable. You can also create VMs in
virtualbox from these images (though I don&amp;rsquo;t remember exact steps to make the
image work with VirtualBox. Do let me know if you get the VM working with
VirtualBox/Vagrant)&lt;/p&gt;

&lt;p&gt;Here I&amp;rsquo;ll describe ways to create a bare cloud-uploadable Ubuntu image. I will
also provide information as to how to build an image which will have some
packages pre-installed in them. Note that the commands here will create only
one image file as opposed to three &amp;ndash; one each for ramdisk, kernel and machine image.&lt;/p&gt;

&lt;p&gt;Prerequisites&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;sudo apt-get install qemu-utils
git clone http://github.com/openstack/diskimage-builder
cd diskimage-builder
sudo pip install -r requirements.txt
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;All the binaries are in bin filder. You can go in the &lt;code&gt;bin\&lt;/code&gt; directory to
execute diskimage-builder commands, or add that directory to your &lt;code&gt;$PATH&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;Create bare Ubuntu image, which you can directly upload to a cloud e.g.
OpenStack.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;disk-image-create -a amd64 -o ubuntu-amd64 vm ubuntu
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Image generated will be of name &lt;code&gt;ubuntu-amd64.qcow2&lt;/code&gt;. Such an image will be for
same OS version as your host Ubuntu version. If you want
to build an image against a different OS version, specify
&lt;code&gt;DIB_RELEASE=&amp;lt;releasename&amp;gt;&lt;/code&gt; as a prefix to the command.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;DIB_RELEASE=trusty disk-image-create -a amd64 -o ubuntu-amd64 vm ubuntu
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Create an Ubuntu VM image which you can boot via KVM or VirtualBox/Vagrant.
You will need to manually
add public keys to authorized_keys for a user inside that VM.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;disk-image-create -o base -a amd64 vm base ubuntu cloud-init-nocloud
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Create an image with &lt;code&gt;mysql-server&lt;/code&gt; and &lt;code&gt;tmux&lt;/code&gt; package (and their dependencies) installed inside the image:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;disk-image-create -a amd64 -o ubuntu-amd64 -p mysql-server,tmux vm ubuntu
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;How to upload image to glance:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;glance image-create --name dib-ubuntu --disk-format=qcow2 --container-format=bare &amp;lt; img/ubuntu-amd64.qcow2
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Where &lt;code&gt;ubuntu-amd64.qcow2&lt;/code&gt; is the image to upload.&lt;/p&gt;

&lt;p&gt;Thanks!&lt;/p&gt;
</description>
    </item>
    
    
    
    <item>
      <title>Better way to view MySQL tables</title>
      <link>http://rushiagr.com/blog/2015/12/12/better-way-to-view-mysql-tables/</link>
      <pubDate>Sat, 12 Dec 2015 00:00:00 &#43;0000</pubDate>
      <author>Rushi Agrawal</author>
      <guid>http://rushiagr.com/blog/2015/12/12/better-way-to-view-mysql-tables/</guid>
      <description>

&lt;h3 id=&#34;the-problem:1a3447b8e3a40d86311532717f0ef6f7&#34;&gt;The problem&lt;/h3&gt;

&lt;p&gt;You are trying to print a MySQL table with a large number of columns, with
&lt;code&gt;SELECT *&lt;/code&gt; command. You type &lt;code&gt;SELECT * FROM mysql.user LIMIT 1&lt;/code&gt;, and your terminal
becomes &lt;a href=&#34;https://raw.githubusercontent.com/rushiagr/public/master/img/mysql-table-with-many-rows-messy.png&#34;&gt;this&lt;/a&gt;.
If you wanted to view more than one row, you&amp;rsquo;re in a trouble :)&lt;/p&gt;

&lt;h3 id=&#34;the-solution:1a3447b8e3a40d86311532717f0ef6f7&#34;&gt;The solution&lt;/h3&gt;

&lt;p&gt;Run MySQL with this option:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;mysql --pager=&amp;quot;less --chop-long-lines --quit-if-one-screen --no-init&#39;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This will make your table display only the rows it can in the current screen, something like &lt;a href=&#34;https://raw.githubusercontent.com/rushiagr/public/master/img/mysql-with-less-pager-neat.png&#34;&gt;this&lt;/a&gt;. You can
use the arrow keys to move sideways to view the hidden column. Pressing the &amp;lsquo;right&amp;rsquo; arrow key will move half page towards right. Neat, isn&amp;rsquo;t it?&lt;/p&gt;

&lt;p&gt;You can create an alias for mysql:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;# Using shorter version of &#39;less&#39; flags mentioned above
alias mysql=&#39;mysql -SFX&#39;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;You can put the above line in your &lt;code&gt;~/.bashrc&lt;/code&gt; file to load this alias
in every new terminal session.&lt;/p&gt;

&lt;h3 id=&#34;bonus-point-for-vim-users:1a3447b8e3a40d86311532717f0ef6f7&#34;&gt;Bonus point for Vim users&lt;/h3&gt;

&lt;p&gt;&lt;code&gt;less&lt;/code&gt; allows using keys &lt;code&gt;j&lt;/code&gt; and &lt;code&gt;k&lt;/code&gt; for scrolling down and scrolling up. Unfortunately, you cannot directly use keys &lt;code&gt;h&lt;/code&gt; and &lt;code&gt;l&lt;/code&gt; to move sideways using &lt;code&gt;less&lt;/code&gt;. Fortunately, you can map &lt;code&gt;h&lt;/code&gt; and &lt;code&gt;l&lt;/code&gt; to move left or right, respectively. Here&amp;rsquo;s how to do that:&lt;/p&gt;

&lt;p&gt;Create a file &lt;code&gt;.lesskey&lt;/code&gt; in your home directory, with the following contents&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;l noaction 10\e)
h noaction 10\e)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Now run this command, to generate &lt;code&gt;~/.less&lt;/code&gt; file.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;lesskey
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This will generate a binary file which &lt;code&gt;less&lt;/code&gt; understands. If you now start a new MySQL terminal session (of course with the above said &lt;code&gt;--pages&lt;/code&gt; flag), you can use Vim&amp;rsquo;s &lt;code&gt;HJKL&lt;/code&gt; movements. Here I have specified to move 10 characters to the right if you make one &amp;lsquo;right&amp;rsquo; Vim movement.&lt;/p&gt;

&lt;h3 id=&#34;quick-setup-script:1a3447b8e3a40d86311532717f0ef6f7&#34;&gt;Quick setup script&lt;/h3&gt;

&lt;p&gt;Don&amp;rsquo;t want to do the above stuff manually? Just run this command and your computer will be set up in a second!&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;sh -c &amp;quot;$(wget -q https://raw.githubusercontent.com/rushiagr/public/master/scripts/mysql-pretty-table.sh -O -)&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Note that changes will take effect from a new shell session (or you can run &lt;code&gt;source ~/.bashrc&lt;/code&gt; if you want things to work in the current session too.&lt;/p&gt;

&lt;h3 id=&#34;more-information:1a3447b8e3a40d86311532717f0ef6f7&#34;&gt;More information&lt;/h3&gt;

&lt;p&gt;Find more information at below links:&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://unix.stackexchange.com/a/169969/91602&#34;&gt;About mapping &amp;lsquo;h&amp;rsquo; and &amp;lsquo;k&amp;rsquo; to Vim movements in &amp;lsquo;less&amp;rsquo;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://stackoverflow.com/a/6422698/1143173&#34;&gt;About using &amp;lsquo;less&amp;rsquo; as MySQL pager&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Cheers!&lt;/p&gt;
</description>
    </item>
    
    
    
    <item>
      <title>Quick JustDial scraper</title>
      <link>http://rushiagr.com/blog/2015/09/14/quick-justdial-scraper/</link>
      <pubDate>Mon, 14 Sep 2015 00:00:00 &#43;0000</pubDate>
      <author>Rushi Agrawal</author>
      <guid>http://rushiagr.com/blog/2015/09/14/quick-justdial-scraper/</guid>
      <description>&lt;p&gt;So my friend asked me to scrape data from JustDial and give it to him in an excel sheet.
I thought let&amp;rsquo;s give it a try. He needed
name of firm, address and phone number of any JustDial URL he wants to scrape. After effectively
around 4 hours of work, the below script was created.&lt;/p&gt;

&lt;p&gt;Note that the script is dirty. You need to edit the jd_url to search any other URL. Also,
the looping will go on forever, so you have to keep checking the file size of generated
&amp;lsquo;data.csv&amp;rsquo; file, and when you&amp;rsquo;re sure it&amp;rsquo;s not increasing any more, kill the script by
pressing CTRL+C. This script works as of today. Tomorrow it might not. Also, excuse
stray comments/bad formatting of code. I&amp;rsquo;m not sure I want to clean it right now :)&lt;/p&gt;

&lt;p&gt;Feel free to use/modify it the way you want.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;# PIP requirements: requests, beautifulsoup4
import requests
from bs4 import BeautifulSoup
import json
import csv

jd_url = &amp;quot;http://www.justdial.com/Bangalore/Car-Hire-%3Cnear%3E-Shanthinagar&amp;quot;

# Split http/https prefix if any
# TODO: work on URLs which dont&#39; have the CT part in URL
jd_url = jd_url.split(&#39;http://www.justdial.com/&#39;)[-1].split(&#39;https://www.justdial.com/&#39;)[-1]
city, search, cat_id = &#39;&#39;, &#39;&#39;, &#39;&#39;
split_vals = jd_url.split(&#39;/&#39;)
if len(split_vals) == 3:
    city, search, cat_id = jd_url.split(&#39;/&#39;)
    cat_id = cat_id.split(&#39;-&#39;)[-1]
elif len(split_vals) == 2:
    city, search = jd_url.split(&#39;/&#39;)
search = search.replace(&#39;-&#39;, &#39;+&#39;)


with open(&#39;data.csv&#39;, &#39;w&#39;) as f:
    #writer = csv.writer(f, delimiter=&#39;,&#39;, quoting=csv.QUOTE_ALL, lineterminator=&#39;\n&#39;)

    page = 1
    while True:
        print &#39;page&#39;, page
        resp = requests.get(&#39;http://www.justdial.com&#39;+&#39;/functions/ajxsearch.php?national_search=0&amp;amp;act=pagination&amp;amp;city={0}&amp;amp;search={1}&amp;amp;where=&amp;amp;catid={2}&amp;amp;psearch=&amp;amp;prid=&amp;amp;page={3}&#39;.format(city, search, cat_id, page))
        markup = resp.json()[&#39;markup&#39;].replace(&#39;\/&#39;, &#39;/&#39;)
        soup = BeautifulSoup(markup, &#39;html.parser&#39;)


        for thing in soup.find_all(&#39;section&#39;):
            csv_list = []
            if thing.get(&#39;class&#39;)==[u&#39;jcar&#39;]:
                # Company name
                for a_tag in thing.find_all(&#39;a&#39;):
                    if a_tag.get(&#39;onclick&#39;)==&amp;quot;_ct(&#39;clntnm&#39;, &#39;lspg&#39;);&amp;quot;:
                        csv_list.append(a_tag.get(&#39;title&#39;))

                # Address
                for span_tag in thing.find_all(&#39;span&#39;):
                    if span_tag.get(&#39;class&#39;)==[u&#39;mrehover&#39;, u&#39;dn&#39;]:
                        csv_list.append(span_tag.get_text().strip())

                # Phone number
                for a_tag in thing.find_all(&#39;a&#39;):
                    if a_tag.get(&#39;href&#39;).startswith(&#39;tel:&#39;):
                        csv_list.append(a_tag.get(&#39;href&#39;).split(&#39;:&#39;)[-1])


                csv_list = [&#39;&amp;quot;&#39;+item+&#39;&amp;quot;&#39; for item in csv_list]
                writeline = &#39;,&#39;.join(csv_list)+&#39;\n&#39;
                f.write(&#39;,&#39;.join(csv_list)+&#39;\n&#39;)
        page+=1
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Cheers!&lt;/p&gt;
</description>
    </item>
    
    
    
    <item>
      <title>OpenStack Keystone with Cassandra Database in DevStack</title>
      <link>http://rushiagr.com/blog/2015/09/10/openstack-keystone-with-cassandra-database-in-devstack/</link>
      <pubDate>Thu, 10 Sep 2015 00:00:00 &#43;0000</pubDate>
      <author>Rushi Agrawal</author>
      <guid>http://rushiagr.com/blog/2015/09/10/openstack-keystone-with-cassandra-database-in-devstack/</guid>
      <description>

&lt;p&gt;Using Cassandra as backing database for OpenStack Keystone was our solution
to multi-region deployment problem of OpenStack cloud. This blog post is not
to discuss the problem. We are talking about how to have a development
environment to play around with Keystone working with a dev Cassandra deployment.&lt;/p&gt;

&lt;h4 id=&#34;just-run-this-script-and-you-re-all-set:ac993324848a8aead891c139adf0f8b7&#34;&gt;&amp;ldquo;Just run this script and you&amp;rsquo;re all set!&amp;rdquo;&lt;/h4&gt;

&lt;p&gt;I&amp;rsquo;ve put together all commands into a script which can be found here:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;https://raw.githubusercontent.com/rushiagr/keystone-cassandra/master/keystone-cassandra.sh
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;If you have a fresh Ubuntu VM, just copy this script into that machine and
execute it. Give it 15-20 mins at least (depending upon your internet connection), and it will set up:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;DevStack with Keystone installed and running with all the data stored in/fetched from local Cassandra installation&lt;/li&gt;
&lt;li&gt;A Cassandra development cluster (CCM) with 5 nodes and replication factor of 3&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Of course, you will need Internet access inside the VM. Also, give the VM around
3GB of RAM, else things might not work properly. Actually, if you change the
Cassandra configuration to one node instead of 5, probably 2 GB will suffice. But I&amp;rsquo;ve
not tried it. (Let me know if you tried it and it works!)&lt;/p&gt;

&lt;p&gt;Notes:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;Remember, this is a dev cluster. It&amp;rsquo;s not supposed to be used in production. Hell, it&amp;rsquo;s not even ready for it.&lt;/li&gt;
&lt;li&gt;Keystone is running on 127.0.0.1. I&amp;rsquo;ve done this so that it will work on any person&amp;rsquo;s VM&lt;/li&gt;
&lt;li&gt;I&amp;rsquo;ve tested only on a Ubuntu Trusty VM, on Amazon EC2 m4.large instance which has 8 GB RAM. OpenStack on AWS &amp;ndash; ironic, isn&amp;rsquo;t it? :)&lt;/li&gt;
&lt;li&gt;I&amp;rsquo;m using Java which comes with Ubuntu&amp;rsquo;s APT packages. In production one is supposed to use Oracle Java as per Cassandra folks.&lt;/li&gt;
&lt;li&gt;The code for this script is located at &lt;code&gt;https://github.com/rushiagr/keystone/tree/liberty-cassandra&lt;/code&gt;, i.e. on &lt;code&gt;liberty-cassandra&lt;/code&gt; branch. Note that this work is currently based upon Keystone&amp;rsquo;s Liberty code as on first week of June. It might not work directly with latest code as it might require fixing imports which might have become outdated. However, I don&amp;rsquo;t think it&amp;rsquo;s going to take more than an hour to make it work with latest code; just that I don&amp;rsquo;t have enough motivation right now to keep the code updated with &amp;lsquo;latest&amp;rsquo; all the time.&lt;/li&gt;
&lt;/ol&gt;

&lt;h4 id=&#34;credits:ac993324848a8aead891c139adf0f8b7&#34;&gt;Credits&lt;/h4&gt;

&lt;p&gt;This work was done by the &amp;lsquo;distributed database&amp;rsquo; team of 4 people: Ajaya Agrawal, Rushi Agrawal (me), Vivek Dhayaal and Yogeshwar Shenoy, listed in alphabetical order. And obviously Reliance, for providing us an opportunity to work on this thing.&lt;/p&gt;
</description>
    </item>
    
    
    
    <item>
      <title>Apache mod_wsgi parallelization notes</title>
      <link>http://rushiagr.com/blog/2015/07/24/apache-mod_wsgi-parallelization-notes/</link>
      <pubDate>Fri, 24 Jul 2015 00:00:00 &#43;0000</pubDate>
      <author>Rushi Agrawal</author>
      <guid>http://rushiagr.com/blog/2015/07/24/apache-mod_wsgi-parallelization-notes/</guid>
      <description>

&lt;p&gt;This is my notes on
&lt;a href=&#34;https://code.google.com/p/modwsgi/wiki/ProcessesAndThreading&#34;&gt;&amp;lsquo;Processes and Threading&amp;rsquo;&lt;/a&gt;
doc by the author of mod_wsgi module of Apache. This blog post just serves as a &amp;lsquo;quick refresher&amp;rsquo;, and
is only useful if you have read the original document but it&amp;rsquo;s been too long since you
read it :)&lt;/p&gt;

&lt;h2 id=&#34;apache-with-mod-wsgi:d8164b9dd960e232cff9349f39ccb12e&#34;&gt;Apache with mod_wsgi&lt;/h2&gt;

&lt;p&gt;A Python application can run with multiple processes as well as multiple threads
with mod_wsgi.&lt;/p&gt;

&lt;h3 id=&#34;prefork-multiprocessing-module:d8164b9dd960e232cff9349f39ccb12e&#34;&gt;Prefork multiprocessing module&lt;/h3&gt;

&lt;p&gt;Apache creates multiple processes, and each request is handled by one process.
A process only handles one request at a time.
This means, if you have set number of processes to 1, there will be only one
request handeled at a time overall.&lt;/p&gt;

&lt;h3 id=&#34;worker-multiprocessing-module:d8164b9dd960e232cff9349f39ccb12e&#34;&gt;Worker multiprocessing module&lt;/h3&gt;

&lt;p&gt;Multiple processes, and multiple threads in each processa.
Even if a process is handling a request, another thread in the same process
can handle one more request.
You might need some synchronization primitive to make sure multiple threads
of same process don&amp;rsquo;t corrupt shared memory (only occurs when shared memory
is mutated)&lt;/p&gt;

&lt;h3 id=&#34;but-gil:d8164b9dd960e232cff9349f39ccb12e&#34;&gt;But GIL?&lt;/h3&gt;

&lt;p&gt;Python GIL problem is largely alleviated with mod_wsgi since multiple processes
can handle requests, and GIL has impact ranging to only one process. One more
point to note is that the apache code which maps a URL/request to a wsgi application,
and the code which maps static file URLs to actual static files to serve is
written in C, and is free from GIL.&lt;/p&gt;

&lt;p&gt;In the wsgi python code, two environment variables: &amp;lsquo;wsgi.multithread&amp;rsquo; and
&amp;lsquo;wsgi.multiprocess&amp;rsquo; will define which of the above two modules are going to be
used.&lt;/p&gt;
</description>
    </item>
    
    
    
    <item>
      <title>Docker quick start notes</title>
      <link>http://rushiagr.com/blog/2015/06/07/docker-quick-start-notes/</link>
      <pubDate>Sun, 07 Jun 2015 00:00:00 &#43;0000</pubDate>
      <author>Rushi Agrawal</author>
      <guid>http://rushiagr.com/blog/2015/06/07/docker-quick-start-notes/</guid>
      <description>

&lt;p&gt;After reading about docker and containers, I thought let&amp;rsquo;s try them out.
Here are my notes. Obviously all of them are taken from Internet. Maybe this
collection here will help someone start with docker faster than spending time
searching all over the internet.&lt;/p&gt;

&lt;p&gt;It assumes your base OS is Ubuntu 14.04 Trusty Tahr (when was the last time
you saw the codename spelled &amp;lsquo;Trusty Tahr&amp;rsquo; and not &amp;lsquo;Trusty&amp;rsquo;? :) ).&lt;/p&gt;

&lt;p&gt;Install docker&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;sudo apt-get install docker.io
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;See docker version&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;sudo docker version
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Pull an Ubuntu Trusty docker image&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;sudo docker pull ubuntu:14.04
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Alternatively, you can search for a docker image &amp;lsquo;tutorial&amp;rsquo; in docker&amp;rsquo;s repository&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;sudo docker search tutorial
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;And them pull a docker image &amp;lsquo;tutorial&amp;rsquo; by user &amp;lsquo;learn&amp;rsquo;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;sudo docker pull learn/tutorial
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;List all docker images present in the system&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;sudo docker images
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Run a docker image, and execute command &amp;lsquo;echo &amp;ldquo;hello world&amp;rdquo;&amp;rsquo; in the docker
container created out of that image&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;sudo docker run ubuntu:14.04 echo &amp;quot;hello world&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Container information is stored in /var/lib/docker&lt;/p&gt;

&lt;p&gt;If you run the above command multiple times, it will create a new container
each time.&lt;/p&gt;

&lt;p&gt;To know the ID of the last container, run&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;sudo docker ps -l
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;To list all the running containers&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;sudo docker ps
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Note that the above command will not show the container we last run, because
the container which we ran last time terminated just after it finished
executing echo command.&lt;/p&gt;

&lt;p&gt;Create a new docker image by name &lt;code&gt;&amp;lt;yourname&amp;gt;/echo&lt;/code&gt; by &amp;lsquo;committing&amp;rsquo; the last
container which you ran&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;sudo docker commit &amp;lt;container ID&amp;gt; &amp;lt;yourname&amp;gt;/echo
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Now running &lt;code&gt;sudo docker images&lt;/code&gt; will list you two containers instead of one&lt;/p&gt;

&lt;p&gt;Now you can run this new docker container like this:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;sudo docker run &amp;lt;yourname&amp;gt;/echo ls -alrth
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;If we installed something, or created a file in the old container, it will
be visible now in this container too.&lt;/p&gt;

&lt;p&gt;Get more information about a docker image or a running container:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;sudo docker inspect &amp;lt;yourname&amp;gt;/echo
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;To push docker image to docker repository&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;sudo docker push &amp;lt;yourname&amp;gt;/echo
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;To download ubuntu Trusty base image if not present locally, and open a shell session into it&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;sudo docker run -t -i ubuntu:14.04 /bin/bash
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;-i i.e. &amp;ndash;interactive=false, keeps STDIN open even if not attached&lt;/p&gt;

&lt;p&gt;-t i.e. &amp;ndash;tty=false allocates a pseudo tty&lt;/p&gt;

&lt;p&gt;Don&amp;rsquo;t worry what these mean. If you add these options, you&amp;rsquo;ll see that
you already get logged in into the container shell, and the container
only dies off once you exit from that session (usually by writing &lt;code&gt;exit&lt;/code&gt;
or pressing CTRL + D.&lt;/p&gt;

&lt;p&gt;To remove an image:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;sudo docker rmi learn/tutorial
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&#34;things-not-covered-in-this-tutorial:49285dca7b53d383ade641738736c634&#34;&gt;Things not covered in this tutorial:&lt;/h4&gt;

&lt;ol&gt;
&lt;li&gt;Create your own custom docker images and share with other people:
&lt;a href=&#34;https://docs.docker.com/userguide/dockerimages/&#34;&gt;https://docs.docker.com/userguide/dockerimages/&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Cheers!&lt;/p&gt;
</description>
    </item>
    
    
    
    <item>
      <title>Cache APT packages with Squid proxy</title>
      <link>http://rushiagr.com/blog/2015/06/05/cache-apt-packages-with-squid-proxy/</link>
      <pubDate>Fri, 05 Jun 2015 00:00:00 &#43;0000</pubDate>
      <author>Rushi Agrawal</author>
      <guid>http://rushiagr.com/blog/2015/06/05/cache-apt-packages-with-squid-proxy/</guid>
      <description>

&lt;p&gt;TL;DR: Know how to install and set up Squid proxy, so that you can cache packages,
and hence save bandwidth if you want to install those packages again and again.
Also works if you are already behind a squid proxy.&lt;/p&gt;

&lt;h2 id=&#34;problem-repetitive-download-slow:4536ae7fffd586a321b78960b2283427&#34;&gt;Problem: Repetitive download. Slow.&lt;/h2&gt;

&lt;p&gt;If you deal with virtual machines a lot, you might know the pain of
managing packages on each one of them. Every time I had to create a new VM,
I would run &lt;code&gt;apt-get update&lt;/code&gt; (to get information about all the latest packages
available for my Ubuntu system), &lt;code&gt;apt-get dist-upgrade&lt;/code&gt; (to install latest
versions of all packages already installed), and also install some packages
not present in stock Ubuntu image, like &lt;code&gt;git&lt;/code&gt; (yes, it&amp;rsquo;s 2015
and Ubuntu still doesn&amp;rsquo;t come pre-installed with &lt;code&gt;git&lt;/code&gt;), &lt;code&gt;ipython&lt;/code&gt;, &lt;code&gt;bwm-ng&lt;/code&gt;
and some others. This would mean I&amp;rsquo;m downloading the same file over the network
over and over again. Now there are two ways to deal with this situation&lt;/p&gt;

&lt;h2 id=&#34;solution-1-local-ubuntu-mirror-super-fast-but-unweildy:4536ae7fffd586a321b78960b2283427&#34;&gt;Solution 1: Local Ubuntu mirror - Super fast but unweildy&lt;/h2&gt;

&lt;p&gt;The first solution is to download a complete Ubuntu mirror to your computer.
That is, download ALL Ubuntu packages to your system, and then it is super fast.
The first download will be close to 80GBs though. It would have been fine for
me to download 80GBs, but you&amp;rsquo;ll realize the problem when you want to update
this mirror. If you are trying to update the local mirror every week or so,
each time it will ask you to download around 5GB of data. And that unfortunately
is too much for me to download every few days.&lt;/p&gt;

&lt;h2 id=&#34;solution-2-cache-with-squid-proxy-just-about-perfect:4536ae7fffd586a321b78960b2283427&#34;&gt;Solution 2: Cache with Squid proxy - Just about perfect&lt;/h2&gt;

&lt;p&gt;The other alternative is use a local cache, using Squid proxy. It works like
just another cache: if you want a package of a specific version, Squid will connect
over the internet to find more details about that file. Once it gets these details,
it checks if a file (package) matching those details is already present in the local
cache. If it is locally present, it just sends this local copy to the requester.
So the total Internet bandwidth utilised is only to get the file details, which
is miniscule (Bytes) compared to downloading the whole package (MBs)j. If the
details doesn&amp;rsquo;t match any locally cached packages, the proxy fetches that package
from internet and responds to the requester.&lt;/p&gt;

&lt;h2 id=&#34;practical:4536ae7fffd586a321b78960b2283427&#34;&gt;Practical!&lt;/h2&gt;

&lt;p&gt;Enough of theory, let&amp;rsquo;s put theory to some practice :)&lt;/p&gt;

&lt;p&gt;All of the commands below are run on Ubuntu 14.04 (Trusty).&lt;/p&gt;

&lt;p&gt;Install Squid proxy package.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;sudo apt-get install squid
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Configure: replace &lt;code&gt;/etc/squid3/squid.conf&lt;/code&gt; and make it contain these lines.
You will need root permissions to edit this file&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;acl localhost src 127.0.0.1/32 ::1
acl to_localhost dst 127.0.0.0/8 0.0.0.0/32 ::1
acl localnet src 10.0.0.0/8 # RFC1918 possible internal network
acl localnet src 172.16.0.0/12  # RFC1918 possible internal network
acl localnet src 192.168.0.0/16 # RFC1918 possible internal network
acl SSL_ports port 443
acl Safe_ports port 80      # http
acl Safe_ports port 21      # ftp
acl Safe_ports port 443     # https
acl Safe_ports port 70      # gopher
acl Safe_ports port 210     # wais
acl Safe_ports port 1025-65535  # unregistered ports
acl Safe_ports port 280     # http-mgmt
acl Safe_ports port 488     # gss-http
acl Safe_ports port 591     # filemaker
acl Safe_ports port 777     # multiling http
acl CONNECT method CONNECT
http_access allow manager localhost
http_access deny manager
http_access deny !Safe_ports
http_access deny CONNECT !SSL_ports
http_access allow localnet
http_access allow localhost
http_access deny all
http_port 3128
maximum_object_size 1024 MB
cache_dir aufs /var/spool/squid3 5000 24 256
coredump_dir /var/spool/squid3
refresh_pattern ^ftp:       1440    20% 10080
refresh_pattern ^gopher:    1440    0%  1440
refresh_pattern -i (/cgi-bin/|\?) 0 0%  0
refresh_pattern (Release|Packages(.gz)*)$      0       20%     2880
refresh_pattern .       0   20% 4320
refresh_all_ims on
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;You don&amp;rsquo;t need to know or remember what is happening here right now. Just copy
and paste :)&lt;/p&gt;

&lt;p&gt;Restart the service:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;sudo service squid3 restart
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Now squid service is running, and listening on port 3128. You can use any IP
of your base system which is accessible from your VMs to get packages
via this cache. I give my base system an IP of &lt;code&gt;192.168.100.1&lt;/code&gt;, so I just
need to do:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;export http_proxy=http://192.168.100.1:3128/
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;to source the proxy environment variable, which we&amp;rsquo;ll use to point the APT system
to, to fetch packages from. To test if you proxy is working fine locally,
you can provide &lt;code&gt;127.0.0.1&lt;/code&gt;, your localhost IP instead.&lt;/p&gt;

&lt;p&gt;And after that can start using the cache to download packages by just passing &lt;code&gt;-E&lt;/code&gt;
option to the &lt;code&gt;sudo&lt;/code&gt; command&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;sudo -E apt-get install &amp;lt;your package&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Sure there are alternative ways of using the proxy, but this is my favourite!&lt;/p&gt;

&lt;h2 id=&#34;i-m-already-behind-a-proxy:4536ae7fffd586a321b78960b2283427&#34;&gt;I&amp;rsquo;m already behind a proxy!&lt;/h2&gt;

&lt;p&gt;Worry not, add these lines to &lt;code&gt;squid.conf&lt;/code&gt;, restart squid and you&amp;rsquo;re all set for using the
brand new proxy instead of the old one :)&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;cache_peer 10.135.121.138 parent 3128 0 no-query no-digest
never_direct allow all
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;ending-thoughts:4536ae7fffd586a321b78960b2283427&#34;&gt;Ending thoughts&lt;/h2&gt;

&lt;p&gt;You can go to &lt;code&gt;/var/spool/squid3&lt;/code&gt; and run a &lt;code&gt;du -sch&lt;/code&gt; to see the total size
of cached files. I find it easy sometimes to calculate the total size of
files this directory holds, to make sure the proxy is working correctly &amp;ndash;
if you can &amp;lsquo;new&amp;rsquo; packages being downloaded, but the size of this directory
is not increasing, they&amp;rsquo;re not coming via this proxy, and you need to figure
out why :)&lt;/p&gt;

&lt;p&gt;One more important thing I should tell is that the configuration file
we&amp;rsquo;ve used not only caches APT packages, but also any static files
hosted anywhere on the internet. So if let&amp;rsquo;s say you want to download an
Ubuntu ISO or some other ISO multiple times in your setup (say, inside VMs),
you can cache the ISO file as well with our current setup.&lt;/p&gt;

&lt;p&gt;Tell me what is the size your &lt;code&gt;/var/spool/squid3/&lt;/code&gt; directory has
reached. Mine is at 1GB right now after a year of it&amp;rsquo;s usage.&lt;/p&gt;

&lt;p&gt;Cheers!&lt;/p&gt;

&lt;p&gt;-Rushi&lt;/p&gt;
</description>
    </item>
    
    
    
    
    
    
    
    <item>
      <title>Plight of Online Banking in India</title>
      <link>http://rushiagr.com/blog/2014/11/09/plight-of-online-banking-in-india/</link>
      <pubDate>Sun, 09 Nov 2014 00:00:00 &#43;0000</pubDate>
      <author>Rushi Agrawal</author>
      <guid>http://rushiagr.com/blog/2014/11/09/plight-of-online-banking-in-india/</guid>
      <description>

&lt;p&gt;So India is moving ahead. Industry is growing, common facilities are improving,
conditions for living are improving (or so it seems from a middle class guy&amp;rsquo;s
eyes). Banks are becoming more accessible, and easier to use. All banks now
have online banking facility, and makes it less of a hassle to transact - now
you can sit at home and pay your bills, buy things, transfer money to friends
or parents, etc. But, after using online banking for about 4 years, I feel
there is a lot still to be achieved. I find it&amp;rsquo;s not &amp;lsquo;very very&amp;rsquo; convenient.
Online banking experience can be made much much better by fixing these issues.
Below I&amp;rsquo;m writing about my experiences with some of the Indian banks I&amp;rsquo;ve done
online banking with.&lt;/p&gt;

&lt;h2 id=&#34;state-bank-of-india:8e2dd647e7d0560715f28db5fe7e69c3&#34;&gt;State Bank of India&lt;/h2&gt;

&lt;p&gt;Hands down India&amp;rsquo;s largest bank. But the user interface of the online website
haven&amp;rsquo;t changed much in the last 4 years I&amp;rsquo;ve seen. There are quite a few
problems with the way the site behaves.&lt;/p&gt;

&lt;h4 id=&#34;immediate-transfer:8e2dd647e7d0560715f28db5fe7e69c3&#34;&gt;Immediate transfer&lt;/h4&gt;

&lt;p&gt;The rules of beneficiary addition, and
money transfer are outdated. You can&amp;rsquo;t transfer any amount within the first 24
hours of beneficiary addition. It&amp;rsquo;s Painful that you cannot add a
beneficiary immediately. Beneficiary addition and approval can take upto 24
hours, and I&amp;rsquo;ve seen it taking 4+ hours all the time. If you want to transfer
money immediately, you&amp;rsquo;re out of luck!&lt;/p&gt;

&lt;h4 id=&#34;imps-is-not-really-immediate:8e2dd647e7d0560715f28db5fe7e69c3&#34;&gt;IMPS is not really &amp;lsquo;Immediate&amp;rsquo;&lt;/h4&gt;

&lt;p&gt;IMPS was introduced as a faster &amp;lsquo;NEFT&amp;rsquo; &amp;ndash; to work around the limitation that
NEFT transfer cannot be done outside bank working hours, so that you can
transact round the clock. Frustratingly, SBI&amp;rsquo;s IMPS works only till 8PM. You
cannot transfer money after 8PM!&lt;/p&gt;

&lt;p&gt;If that was not all, beneficiary addition is separate for NEFT and IMPS. So you
have to add your friend/relative&amp;rsquo;s account number &amp;lsquo;twice&amp;rsquo; to be able to do both
types of transactions.&lt;/p&gt;

&lt;p&gt;Also, you need to remember two passwords - one your online banking password,
and another, the &amp;lsquo;profile&amp;rsquo; password, where you can change your profile
settings. I don&amp;rsquo;t know who came up with this idea of two passwords (both
requiring a special character, and a capital, and a digit, sigh) thinking it
might &amp;lsquo;enhance&amp;rsquo; security. Who cares about users anyway, right?&lt;/p&gt;

&lt;h2 id=&#34;icici:8e2dd647e7d0560715f28db5fe7e69c3&#34;&gt;ICICI&lt;/h2&gt;

&lt;p&gt;This bank recently completely refurbished its UI, and it&amp;rsquo;s pretty good compared
to the old one. I was pretty impressed that a bank is really putting efforts
into improving the user experience, and not just introducing online banking
because all have it, and just be done with it. Only problem is, it thinks I&amp;rsquo;m
dumb, and wants to force it&amp;rsquo;s own unreasonable &amp;lsquo;secure&amp;rsquo; policies on me.&lt;/p&gt;

&lt;p&gt;ICICI debit card has alphabet-digit combinations at the back. For example
A=23,B=01,C=81 upto P=44. Every time you have to do an online transaction, you
need to possess near you 1. Your mobile phone (where it will send an OTP (one
time password), and 2. Your debit card, so that you can enter digits for any
three randomly selected alphabets. I&amp;rsquo;m not sure how the second part increases
security. The bank stops asking OTP once it knows that some specific IP is your
home computer, but still, the debit card alphabet thingy is mandatory. And you
know, there is NO option whatsoever to change this behavior.&lt;/p&gt;

&lt;p&gt;There have been two cases when I needed to urgently transfer some amount, but the
poor OTP SMS got stuck somewhere on their servers and didn&amp;rsquo;t reach me for the
whole freaking day.&lt;/p&gt;

&lt;h2 id=&#34;citibank:8e2dd647e7d0560715f28db5fe7e69c3&#34;&gt;CitiBank&lt;/h2&gt;

&lt;p&gt;For a couple of months, funnily, their site was not working on any browser except
Internet Explorer. Also, this bank also takes security too seriously. It
doesn&amp;rsquo;t show you all the digits of your bank account (e.g. 1234xxxxxx9), and
does the same with all the account numbers of beneficiaries you added. So once
you add your friend as a beneficiary to this bank, and later you want to add
him/her to another bank, you cannot see his/her account number here by any
possible way. You need to ask him/her again his bank details, or store it
somewhere in your notepad, physical or virtual.&lt;/p&gt;

&lt;h2 id=&#34;common-problem:8e2dd647e7d0560715f28db5fe7e69c3&#34;&gt;Common problem&lt;/h2&gt;

&lt;p&gt;All of this don&amp;rsquo;t frustrate me enough. What makes me really furious is
these banks have a habit of not sending an SMS when they debit my account for
maintenance charges or a default. Every other transaction, be it a 10 Rupee
mobile recharge, is accompanied with an SMS. Except when it&amp;rsquo;s them who are
deducting the amount. SBI does it for annual debit card charges, Citibank
deducted 300 Rupees each month, for 4 months, when my account stopped
receiving any salary, without my attention. Turned out they changed my account
from &amp;lsquo;suvidha&amp;rsquo; to &amp;lsquo;basic&amp;rsquo; without my knowledge. And ICICI did that with me too,
debiting annual maintenance fee for the trading account, without a hint of me
noticing. Do they want me to keep checking the online transaction history once
in a while to catch my mistakes?&lt;/p&gt;

&lt;p&gt;I consider this practice as ugly way of treating customers, and very very unfair, and should be stopped if the banks
have any moral sense left in them. Perhaps I&amp;rsquo;ll some day use consumer forum (or
will I need to file a PIL maybe?)
to stop this fooling of common people by
these banks. For today, I have an excuse that I don&amp;rsquo;t have enough time.&lt;/p&gt;

&lt;p&gt;I am sure these are not the only banks which are below par in customer
satisfaction. India has always had this culture that you need to be just as
good as your competitors. If they are exploiting, you too can exploit upto the
same extent. These banks too don&amp;rsquo;t seem to bother much about user satisfaction.
They are just trying to be as good as their competitors. They don&amp;rsquo;t see this
that if they provide superior services than their rivals, a guy will never ever
leave them and won&amp;rsquo;t think of opening another bank account in his life.&lt;/p&gt;

&lt;p&gt;Comments welcome!&lt;/p&gt;

&lt;p&gt;Cheers!&lt;/p&gt;

&lt;p&gt;-Rushi&lt;/p&gt;
</description>
    </item>
    
    
    
    <item>
      <title>Puppet installation from modules</title>
      <link>http://rushiagr.com/blog/2014/09/14/puppet-installation-from-modules/</link>
      <pubDate>Sun, 14 Sep 2014 00:00:00 &#43;0000</pubDate>
      <author>Rushi Agrawal</author>
      <guid>http://rushiagr.com/blog/2014/09/14/puppet-installation-from-modules/</guid>
      <description>&lt;p&gt;A quick example of how to use Puppet to install and manage MySQL. We&amp;rsquo;ll
download required Puppet modules from their git repositories.&lt;/p&gt;

&lt;p&gt;Again, everything is tried on Ubuntu (14.04).&lt;/p&gt;

&lt;p&gt;Make sure &lt;code&gt;hostname -f&lt;/code&gt; shows your FQDN. Then install puppet&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;sudo apt-get install puppet
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;We&amp;rsquo;ll use &lt;code&gt;git submodules&lt;/code&gt; to manage different git repositories. But first,
create our own repository&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;mkdir puppet-mysql
cd puppet-mysql
git init
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Install Puppet modules &lt;code&gt;stdlib&lt;/code&gt; and &lt;code&gt;mysql&lt;/code&gt; into directory &lt;code&gt;modules&lt;/code&gt; as git
submodules.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;git submodule add https://github.com/puppetlabs/puppetlabs-stdlib.git modules/stdlib
git submodule add https://github.com/puppetlabs/puppetlabs-mysql.git modules/mysql
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Now create a site.pp file in the root directory of this repository, with the following contents&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;node default {
    class { &#39;mysql::server&#39;:
        root_password =&amp;gt; &#39;nova&#39;
    }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Now we&amp;rsquo;ll apply this &lt;code&gt;site.pp&lt;/code&gt; file to the system. As our modules directory is
different from Puppet&amp;rsquo;s default, we&amp;rsquo;ll need to specify that while running
Puppet.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;sudo puppet apply site.pp --modulepath modules/
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;To see the action in more detail, also pass the &lt;code&gt;--debug&lt;/code&gt; option to the above
execution&lt;/p&gt;

&lt;p&gt;And you&amp;rsquo;re all set.&lt;/p&gt;

&lt;p&gt;Now from your commandline, you can try to access mysql and it will work!&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;mysql -uroot -pnova
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Done! Cheers!&lt;/p&gt;
</description>
    </item>
    
    
    
    <item>
      <title>OpenStack Unit Testing Nuggets</title>
      <link>http://rushiagr.com/blog/2014/09/05/openstack-unit-testing-nuggets/</link>
      <pubDate>Fri, 05 Sep 2014 00:00:00 &#43;0000</pubDate>
      <author>Rushi Agrawal</author>
      <guid>http://rushiagr.com/blog/2014/09/05/openstack-unit-testing-nuggets/</guid>
      <description>

&lt;p&gt;A small post about little things I found out while running unit tests in
OpenStack.&lt;/p&gt;

&lt;h2 id=&#34;unit-testing-setup:ef0fed5d80bf1672d3195cb4c6973c84&#34;&gt;Unit-testing setup&lt;/h2&gt;

&lt;p&gt;Everybody knows &lt;code&gt;./run_tests.sh&lt;/code&gt; is used to run the unit tests of an OpenStack
project. But, you require to install dependencies before doing it. And
installing dependencies might not always succeed. So make sure you install
these packages before running &lt;code&gt;pip install -r requirements.txt&lt;/code&gt;:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;sudo apt-get install build-essential libssl-dev libffi-dev \
    python-dev libxslt1-dev libpq-dev python-mysqldb \
    libmysqlclient-dev libvirt-dev
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Atleast &lt;code&gt;cinder&lt;/code&gt; and &lt;code&gt;nova&lt;/code&gt; dependencies will get installed properly after
this.&lt;/p&gt;

&lt;h2 id=&#34;run-tests-frequently-used-commands:ef0fed5d80bf1672d3195cb4c6973c84&#34;&gt;run_tests frequently used commands&lt;/h2&gt;

&lt;p&gt;To force the tests to NOT run in a virtual environment, even if it is present:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;./run_tests.sh -N
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Force a clean rebuild of virtual environment&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;./run_tests.sh -f
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Run only PEP8 checks&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;./run_tests.sh -p
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Run PEP8 checks only on the files which have been changed since last commit&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;./run_tests.sh -8
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Run all tests from a specific file only, e.g. nova/tests/test_utils.py&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;./run_tests.sh nova.tests.test_utils
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Run all tests of only a specific class inside a test file&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;./run_tests.sh nova.tests.test_utils.ResourceFilterTestCase
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Run only a specific test&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;./run_tests.sh nova.tests.test_utils.ResourceFilterTestCase.test_resource_filtering
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;wildcards-while-running-the-tests:ef0fed5d80bf1672d3195cb4c6973c84&#34;&gt;Wildcards while running the tests&lt;/h2&gt;

&lt;p&gt;Frequently you&amp;rsquo;ll find yourself testing only a couple of tests. In such cases,
a wildcard will save you from typing the whole path of the test. The below
command will also run &lt;code&gt;test_resource_filtering&lt;/code&gt; test:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;./run_tests.sh nova.tests.*resource_filt*
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;I currently don&amp;rsquo;t know how to make a test work without adding &lt;code&gt;nova.tests&lt;/code&gt;
before it&lt;/p&gt;

&lt;h2 id=&#34;run-tests-is-not-happy:ef0fed5d80bf1672d3195cb4c6973c84&#34;&gt;run_tests is not happy&lt;/h2&gt;

&lt;p&gt;Sometimes you&amp;rsquo;ll see running &lt;code&gt;./run_tests.sh&lt;/code&gt; can throw a lot of lines of
ununderstandable gibberish on your screen. In the end it will say &lt;code&gt;testr
failed&lt;/code&gt;, but it won&amp;rsquo;t give an indication of where it failed and why. I have
seen that this happens due to only one of the following two reasons:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;&lt;em&gt;Syntax error&lt;/em&gt;: There is a syntax error in your code.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;em&gt;Dependencies outdated&lt;/em&gt;: Dependencies in your virtual environment is
outdated. In such cases, you will need to recreate a virtual environment with
latest packages. Or better: just update the virtual environment with the latest
packages using this command:&lt;/p&gt;

&lt;p&gt;./run_tests.sh -u&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;UPDATE: I&amp;rsquo;ve seen that nowadays it doesn&amp;rsquo;t throw a lot of gibberish, but just
says &amp;lsquo;testr failed&amp;rsquo;, without any error log or stacktrace. This is the same
situation &amp;ndash; can only happen when there is a syntax error, or if the
dependencies are outdated.&lt;/p&gt;

&lt;p&gt;That&amp;rsquo;s it for now.&lt;/p&gt;
</description>
    </item>
    
    
  </channel>
</rss>