<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en-us">
<head>
  <link href="https://gmpg.org/xfn/11" rel="profile">
  <meta http-equiv="content-type" content="text/html; charset=utf-8">

  
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1">

  

  <title> Cache APT packages with Squid proxy  &middot; rushiagr </title>

  
  <link rel="stylesheet" href="http://www.rushiagr.com/css/poole.css">
  <link rel="stylesheet" href="http://www.rushiagr.com/css/syntax.css">
  <link rel="stylesheet" href="http://www.rushiagr.com/css/hyde.css">
  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=PT+Sans:400,400italic,700|Abril+Fatface">

  
  <link rel="apple-touch-icon-precomposed" sizes="144x144" href="/apple-touch-icon-144-precomposed.png">
  <link rel="shortcut icon" href="/favicon.ico">

  
  <link href="" rel="alternate" type="application/rss+xml" title="rushiagr" />

  <link href="//netdna.bootstrapcdn.com/font-awesome/4.0.3/css/font-awesome.css" rel="stylesheet">

  <link href='https://fonts.googleapis.com/css?family=Raleway:400,300' rel='stylesheet' type='text/css'>

  <script src="//ajax.googleapis.com/ajax/libs/webfont/1.4.7/webfont.js"></script>
  <script>
    WebFont.load({
      google: {
        families: ['Raleway']
      }
    });
  </script>

</head>

<body>

  <div class="sidebar">
  <div class="container sidebar-sticky">
    <div class="sidebar-about">
      <h1 class="brand"><a href="http://www.rushiagr.com">rushiagr</a></h1>
      <p class="lead">
       code by Rushi Agrawal 
      </p>
    </div>



    <ul class="sidebar-nav">
      <li><a href="http://www.rushiagr.com/blog">Posts</a></li>
      
        <li><a href="/about/">About </a></li>
        <li><a href="https://github.com/rushiagr">Code</a></li>
      
      <br/>
      
        
        
        
        
        
        
        
      
    </ul>
      <a href="https://twitter.com/rushiagr"><i class="fa fa-twitter-square"></i></a>&nbsp;&nbsp;
      
      
      <a href="https://github.com/rushiagr"><i class="fa fa-github-square"></i></a>&nbsp;&nbsp;
      

    <p class="footnote">powered by <a href="http://hugo.spf13.com">Hugo</a> <br/>
    &copy; 2016 Rushi Agrawal. Theme by <a href="https://github.com/natefinch/npf/">npf</a>. All rights reserved.</p>
    
  </div>
</div>


  <div class="content container">
    <div class="post">
    <h1 class="post-title">Cache APT packages with Squid proxy</h1>
    <span class="post-date">Jun 5, 2015</span>
    
    

<p>TL;DR: Know how to install and set up Squid proxy, so that you can cache packages,
and hence save bandwidth if you want to install those packages again and again.
Also works if you are already behind a squid proxy.</p>

<h2 id="problem-repetitive-download-slow:4536ae7fffd586a321b78960b2283427">Problem: Repetitive download. Slow.</h2>

<p>If you deal with virtual machines a lot, you might know the pain of
managing packages on each one of them. Every time I had to create a new VM,
I would run <code>apt-get update</code> (to get information about all the latest packages
available for my Ubuntu system), <code>apt-get dist-upgrade</code> (to install latest
versions of all packages already installed), and also install some packages
not present in stock Ubuntu image, like <code>git</code> (yes, it&rsquo;s 2015
and Ubuntu still doesn&rsquo;t come pre-installed with <code>git</code>), <code>ipython</code>, <code>bwm-ng</code>
and some others. This would mean I&rsquo;m downloading the same file over the network
over and over again. Now there are two ways to deal with this situation</p>

<h2 id="solution-1-local-ubuntu-mirror-super-fast-but-unweildy:4536ae7fffd586a321b78960b2283427">Solution 1: Local Ubuntu mirror - Super fast but unweildy</h2>

<p>The first solution is to download a complete Ubuntu mirror to your computer.
That is, download ALL Ubuntu packages to your system, and then it is super fast.
The first download will be close to 80GBs though. It would have been fine for
me to download 80GBs, but you&rsquo;ll realize the problem when you want to update
this mirror. If you are trying to update the local mirror every week or so,
each time it will ask you to download around 5GB of data. And that unfortunately
is too much for me to download every few days.</p>

<h2 id="solution-2-cache-with-squid-proxy-just-about-perfect:4536ae7fffd586a321b78960b2283427">Solution 2: Cache with Squid proxy - Just about perfect</h2>

<p>The other alternative is use a local cache, using Squid proxy. It works like
just another cache: if you want a package of a specific version, Squid will connect
over the internet to find more details about that file. Once it gets these details,
it checks if a file (package) matching those details is already present in the local
cache. If it is locally present, it just sends this local copy to the requester.
So the total Internet bandwidth utilised is only to get the file details, which
is miniscule (Bytes) compared to downloading the whole package (MBs)j. If the
details doesn&rsquo;t match any locally cached packages, the proxy fetches that package
from internet and responds to the requester.</p>

<h2 id="practical:4536ae7fffd586a321b78960b2283427">Practical!</h2>

<p>Enough of theory, let&rsquo;s put theory to some practice :)</p>

<p>All of the commands below are run on Ubuntu 14.04 (Trusty).</p>

<p>Install Squid proxy package.</p>

<pre><code>sudo apt-get install squid
</code></pre>

<p>Configure: replace <code>/etc/squid3/squid.conf</code> and make it contain these lines.
You will need root permissions to edit this file</p>

<pre><code>acl localhost src 127.0.0.1/32 ::1
acl to_localhost dst 127.0.0.0/8 0.0.0.0/32 ::1
acl localnet src 10.0.0.0/8 # RFC1918 possible internal network
acl localnet src 172.16.0.0/12  # RFC1918 possible internal network
acl localnet src 192.168.0.0/16 # RFC1918 possible internal network
acl SSL_ports port 443
acl Safe_ports port 80      # http
acl Safe_ports port 21      # ftp
acl Safe_ports port 443     # https
acl Safe_ports port 70      # gopher
acl Safe_ports port 210     # wais
acl Safe_ports port 1025-65535  # unregistered ports
acl Safe_ports port 280     # http-mgmt
acl Safe_ports port 488     # gss-http
acl Safe_ports port 591     # filemaker
acl Safe_ports port 777     # multiling http
acl CONNECT method CONNECT
http_access allow manager localhost
http_access deny manager
http_access deny !Safe_ports
http_access deny CONNECT !SSL_ports
http_access allow localnet
http_access allow localhost
http_access deny all
http_port 3128
maximum_object_size 1024 MB
cache_dir aufs /var/spool/squid3 5000 24 256
coredump_dir /var/spool/squid3
refresh_pattern ^ftp:       1440    20% 10080
refresh_pattern ^gopher:    1440    0%  1440
refresh_pattern -i (/cgi-bin/|\?) 0 0%  0
refresh_pattern (Release|Packages(.gz)*)$      0       20%     2880
refresh_pattern .       0   20% 4320
refresh_all_ims on
</code></pre>

<p>You don&rsquo;t need to know or remember what is happening here right now. Just copy
and paste :)</p>

<p>Restart the service:</p>

<pre><code>sudo service squid3 restart
</code></pre>

<p>Now squid service is running, and listening on port 3128. You can use any IP
of your base system which is accessible from your VMs to get packages
via this cache. I give my base system an IP of <code>192.168.100.1</code>, so I just
need to do:</p>

<pre><code>export http_proxy=http://192.168.100.1:3128/
</code></pre>

<p>to source the proxy environment variable, which we&rsquo;ll use to point the APT system
to, to fetch packages from. To test if you proxy is working fine locally,
you can provide <code>127.0.0.1</code>, your localhost IP instead.</p>

<p>And after that can start using the cache to download packages by just passing <code>-E</code>
option to the <code>sudo</code> command</p>

<pre><code>sudo -E apt-get install &lt;your package&gt;
</code></pre>

<p>Sure there are alternative ways of using the proxy, but this is my favourite!</p>

<h2 id="i-m-already-behind-a-proxy:4536ae7fffd586a321b78960b2283427">I&rsquo;m already behind a proxy!</h2>

<p>Worry not, add these lines to <code>squid.conf</code>, restart squid and you&rsquo;re all set for using the
brand new proxy instead of the old one :)</p>

<pre><code>cache_peer 10.135.121.138 parent 3128 0 no-query no-digest
never_direct allow all
</code></pre>

<h2 id="ending-thoughts:4536ae7fffd586a321b78960b2283427">Ending thoughts</h2>

<p>You can go to <code>/var/spool/squid3</code> and run a <code>du -sch</code> to see the total size
of cached files. I find it easy sometimes to calculate the total size of
files this directory holds, to make sure the proxy is working correctly &ndash;
if you can &lsquo;new&rsquo; packages being downloaded, but the size of this directory
is not increasing, they&rsquo;re not coming via this proxy, and you need to figure
out why :)</p>

<p>One more important thing I should tell is that the configuration file
we&rsquo;ve used not only caches APT packages, but also any static files
hosted anywhere on the internet. So if let&rsquo;s say you want to download an
Ubuntu ISO or some other ISO multiple times in your setup (say, inside VMs),
you can cache the ISO file as well with our current setup.</p>

<p>Tell me what is the size your <code>/var/spool/squid3/</code> directory has
reached. Mine is at 1GB right now after a year of it&rsquo;s usage.</p>

<p>Cheers!</p>

<p>-Rushi</p>

    

     
	
    <div id="disqus_thread"></div>
<script type="text/javascript">

(function() {
    
    
    if (window.location.hostname == "localhost") 
        return;

    var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
    var disqus_shortname = 'rushiagr';
    dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
    (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
})();
</script>
<noscript>Please enable JavaScript to view the comments powered by <a href="http://disqus.com/?ref_noscript">Disqus.</a></noscript>
</div>
</div> 

</body>w
</html>
