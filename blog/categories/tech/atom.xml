<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: tech | Sense, and Simplicity]]></title>
  <link href="http://rushiagr.github.io/blog/categories/tech/atom.xml" rel="self"/>
  <link href="http://rushiagr.github.io/"/>
  <updated>2014-04-22T18:12:27+05:30</updated>
  <id>http://rushiagr.github.io/</id>
  <author>
    <name><![CDATA[Rushi Agrawal]]></name>
    <email><![CDATA[rushi.agr@gmail.com]]></email>
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Open Source Puppet - Quick Start]]></title>
    <link href="http://rushiagr.github.io/blog/2014/04/12/open-source-puppet-quick-start/"/>
    <updated>2014-04-12T20:18:00+05:30</updated>
    <id>http://rushiagr.github.io/blog/2014/04/12/open-source-puppet-quick-start</id>
    <content type="html"><![CDATA[<p>This post aims to be your quickest guide to get started with Puppet. We'll be using the open source version of Puppet. An hour of spare time and two Ubuntu machines (physical or virtual doesn't matter) is all that is needed.</p>

<!-- more -->


<h2>Quick Introduction</h2>

<p>Lets say you want to install and run apache server on one of the machines in your lab. On another, you want to create a new user. On a third machine, you want to install MySQL, and allow access to this machine only from the first server. Seems like a lot of manual work isn't it? The power of Puppet is, you can specify all these tasks in a file, called 'Puppet manifest', and then execute it. Everything will be set up for you just as you wanted! Now what makes this 'I care about the end result, not the process' approach really powerful is you can 'apply' this manifest over and over again to get the same end result. You can easily modify this manifest file, extend it, and manage it under version control, just like you would with a piece of software. Welcome to the world of IT automation :)</p>

<p>Although the syntax of a Puppet manifest is Ruby-ish, no knowledge of Ruby is required at all (I don't know Ruby).</p>

<p>There is a whole lot of things you can do with Puppet. Here, we'll just get us started with it. Once you are through this post, you can head over to Puppet Labs' documents and tutorials, for more on "how"s and "why"s of Puppet.</p>

<h2>Setup</h2>

<p>You just require two Ubuntu machines connected to each other. One will be the Puppet 'master' node (the machine which will take care of managing the configuration and state of all the machines in our deployment), the other one 'slave' (which unfortunately is the only actual machine in demo deployment :) ).</p>

<p>Here I am using two  virtual machines, but you can create one virtual machine and use your host machine as the other one. The hostnames of the master and slave in my setup are <code>puppet-master</code> and <code>puppet-agent</code>.</p>

<p>Make sure both the machines are ping-able from each other -- by their IP as well as hostnames (e.g. <code>ping 123.123.123.123</code> and <code>ping puppet-master</code>). Make sure your /etc/hosts file looks something like this to achieve that:</p>

<p>(<code>192.168.56.130</code> and <code>192.168.56.131</code> are the IP addresses of externally-visible interfaces of hosts <code>puppet-master</code> and <code>puppet-agent</code> respectively)</p>

<p>Master:</p>

<pre><code>r@puppet-master:~$ cat /etc/hosts
127.0.0.1   localhost
127.0.1.1   puppet-master

192.168.56.131  puppet-agent
</code></pre>

<p>Slave:</p>

<pre><code>r@puppet-agent:~$ cat /etc/hosts
127.0.0.1   localhost
127.0.1.1   puppet-agent

192.168.56.130  puppet-master
</code></pre>

<h2>Getting the hands dirty -- Puppet CLI</h2>

<p>Install <code>puppetmaster</code> package on the master node</p>

<pre><code>sudo apt-get install puppetmaster
</code></pre>

<p>List all the users on the current system:</p>

<pre><code>puppet resource user --list
</code></pre>

<p>So basically a 'user' is a 'resource' in Puppet terminology. Now only list a specific resource. <code>r</code> is the current user in my case.</p>

<pre><code>r@puppet-master:~$ puppet resource user r
user { 'r':
  ensure  =&gt; 'present',
  comment =&gt; 'r,,,',
  gid     =&gt; '1000',
  groups  =&gt; ['adm', 'cdrom', 'sudo', 'dip', 'plugdev', 'lpadmin', 'sambashare'],
  home    =&gt; '/home/r',
  shell   =&gt; '/bin/bash',
  uid     =&gt; '1000',
}
</code></pre>

<p>Notice the syntax. Resource 'r' is of type 'user', with 'ensure', 'comment', etc as keys/attributes, and 'present', 'r,,,' as values for those attributes.</p>

<p>You can change the value using the Puppet CLI</p>

<pre><code>r@puppet-master:~$ sudo puppet resource user r comment='some text missing'
notice: /User[r]/comment: comment changed 'r,,,' to 'some text missing'
user { 'r':
  ensure  =&gt; 'present',
  comment =&gt; 'some text missing',
}
</code></pre>

<p>Create a new user with specified key-value pairs</p>

<pre><code>r@puppet-master:~$ sudo puppet resource user katie ensure=present shell=/bin/bash
notice: /User[katie]/ensure: created
user { 'katie':
  ensure =&gt; 'present',
  shell  =&gt; '/bin/bash',
}
r@puppet-master:~$ sudo puppet resource user katie 
user { 'katie':
  ensure           =&gt; 'present',
  gid              =&gt; '1001',
  home             =&gt; '/home/katie',
  password         =&gt; '!',
  password_max_age =&gt; '99999',
  password_min_age =&gt; '0',
  shell            =&gt; '/bin/bash',
  uid              =&gt; '1001',
}
</code></pre>

<p>Remove the newly created user, but this time, let's put this information into a file <code>katie_remove.pp</code> and ask Puppet to 'apply' this file and thus removing the user 'katie'.</p>

<pre><code>r@puppet-master:~$ cat katie_remove.pp 
user {'katie':
    ensure =&gt; absent,
}
</code></pre>

<p>Apply this Puppet manifest</p>

<pre><code>r@puppet-master:~$ sudo puppet apply katie_absent.pp 
warning: Could not retrieve fact fqdn
notice: /Stage[main]//User[katie]/ensure: removed
notice: Finished catalog run in 0.47 seconds
</code></pre>

<p>Puppet's description of user 'katie':</p>

<pre><code>r@puppet-master:~$ sudo puppet resource user katie
  user { 'katie':
  ensure =&gt; 'absent',
}
</code></pre>

<p>is now same as that of a non-existent user.</p>

<pre><code>r@puppet-master:~$ sudo puppet resource user absent-user
  user { 'absent-user':
  ensure =&gt; 'absent',
}
</code></pre>

<p>That is, the user 'katie' is now deleted. You can see that the 'ensure' attribute can be used to make sure a user (or in general, any 'resource', is present, or absent).</p>

<p><strong>Note</strong>: Ignore the warning which is printed while applying a manifest from a file. Or if you are bothered by it popping up all the time, in the <code>/etc/hosts</code> file, change</p>

<pre><code>127.0.1.1   puppet-master
</code></pre>

<p>to</p>

<pre><code>127.0.1.1   puppet-master.rushiagr.com puppet-master
</code></pre>

<p>where you can choose a domain name of your own choice in place of <code>.rushiagr.com</code>.</p>

<h2>Puppet modules</h2>

<p><strong>Note:</strong> <code>puppet module</code> doesn't work on Precise (Ubuntu 12.04). You need to install ruby, and gems, etc. Too much of a hassle. So I'll just post commands here which work for a higher version of Ubuntu.</p>

<p>Install standard library:</p>

<pre><code>sudo puppet module install puppetlabs/stdlib
</code></pre>

<p>View all the installed modules</p>

<pre><code>r@puppet-master:~$ sudo puppet module list
/etc/puppet/modules
├── puppetlabs-mysql (v2.2.1)
├── puppetlabs-ntp (v3.0.2)
└── puppetlabs-stdlib (v4.1.0)
/usr/share/puppet/modules (no modules installed)
</code></pre>

<p>All the modules, and all other information in the system goes in <code>/etc/puppet</code> directory.</p>

<p><strong>Note</strong>: Modules installed via <code>sudo</code> will be visible when you perform <code>puppet module list</code> with <code>sudo</code> only. Same for non-<code>sudo</code> use.</p>

<h2>Puppet in master-client configuration</h2>

<p>Everything we did so far concerned with a single machine. Let's now introduce another machine -- Puppet agent.</p>

<p>Note that you need to set FQDNs for both the machines. See the step above, where we suppressed a warning.</p>

<p>First, we'll need to install <code>puppet</code> package (the agent) on the agent node.</p>

<pre><code>sudo apt-get install puppet
</code></pre>

<p>By default, the Puppet agent service will not be running.</p>

<pre><code>r@puppet-agent:~$ sudo service puppet status
 * agent is not running
</code></pre>

<p>Before starting it, change <code>START=no</code> to <code>START=yes</code> in <code>/etc/default/puppet</code> file, to start the agent service by default when the system starts/reboots.</p>

<pre><code>sudo sed -i s/START=no/START=yes/g /etc/default/puppet 
</code></pre>

<p>And add these two lines at the end of <code>/etc/puppet/puppet.conf</code> to allow the agent to discover the master by its FQDN.</p>

<pre><code>[agent]
server = puppet-master
</code></pre>

<p>Now start the Puppet agent service</p>

<pre><code>r@puppet-agent:~$ sudo service puppet start
 * Starting puppet agent                                                       [ OK ] 
</code></pre>

<p>I also make sure that clocks of both the machines are synchronized by running <code>ntpdate</code> on both master and slave. I am not sure if this is required, but doesn't do any harm.</p>

<pre><code>sudo ntpdate pool.ntp.org
</code></pre>

<p>Now the master needs to sign the certs by agent.</p>

<p>Execute this command on agent node.</p>

<pre><code>sudo puppet agent --test --waitforcert 60
</code></pre>

<p>Now hop over to the master node, and retrieve the list of certs waiting to be signed</p>

<pre><code>r@puppet-master:~$ sudo puppet cert --list
  "puppet-agent.rushiagr.com" (EB:0F:E4:14:6F:B2:7E:85:7E:21:26:C4:78:80:58:E1)
</code></pre>

<p>Sign the cert</p>

<pre><code>r@puppet-master:~$ sudo puppet cert sign puppet-agent.rushiagr.com
notice: Signed certificate request for puppet-agent.rushiagr.com
notice: Removing file Puppet::SSL::CertificateRequest puppet-agent.rushiagr.com at '/var/lib/puppet/ssl/ca/requests/puppet-agent.rushiagr.com.pem'
</code></pre>

<p>Now we are ready to go. Let's create a file ('Puppet manifest') on master where we write that: 1. We want apache package to be installed. 2. Once we ensure that the package is installed, we want to start the apache service. We'll name the file <code>site.pp</code>, which is the 'main' configuration file for Puppet. We'll put it into <code>/etc/puppet/manifests</code> directory. Note how we can specify a dependency between resources.</p>

<pre><code>package { 'apache2':
    ensure =&gt; installed
}

service { 'apache2':
    ensure =&gt; true,
    enable =&gt; true,
    require =&gt; Package['apache2']
}       
</code></pre>

<p>Puppet works on 'push' model, meaning configurations are pulled by agents at periodic intervals. I think the default periodic interval is 30 minutes. Alternatively, you can pull from agent at your own will, any time. Let's do that now. Execute this command on the agent:</p>

<pre><code>r@puppet-agent:~$ sudo puppet agent --test
info: Caching catalog for puppet-agent.rushiagr.com
info: Applying configuration version '1397343482'
notice: /Stage[main]//Package[apache2]/ensure: ensure changed 'purged' to 'present'
notice: Finished catalog run in 6.30 seconds
</code></pre>

<p>And you can see the apache server running!</p>

<pre><code>r@puppet-agent:~$ sudo service apache2 status
Apache2 is running (pid 5874).
</code></pre>

<p>Ta! Da!</p>

<p>Please comment if you have any ideas to make this post easier for the newbies to understand.</p>

<p>Cheers!</p>

<p><strong>Notes:</strong></p>

<p>This is just a quick start guide. There are excellent resources and docs at <a href="http://puppetlabs.com">puppetlabs.com</a>. I have their beginner's <a href="https://dl.dropboxusercontent.com/u/42084476/OpenStack/learningpuppet.pdf">PDF</a> saved in my DropBox.
Around 80 pages long, it covers almost every aspect of basic Puppet. The only problem with this guide is it is (I think deliberately) made to work only with the Enterprise Puppet version, but you can always refer back to this post to know how to set the open source version :)</p>

<p>If you mess up the cert signing process, here is a quick and dirty way to get it resolved. On master:</p>

<pre><code>sudo puppet cert clean puppet-agent.rushiagr.com
</code></pre>

<p>On both master and slave:</p>

<pre><code>sudo rm -r /var/lib/puppet/ssl 
sudo service puppet restart
</code></pre>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[OpenStack in an hour with DevStack]]></title>
    <link href="http://rushiagr.github.io/blog/2014/04/03/openstack-in-an-hour-with-devstack/"/>
    <updated>2014-04-03T22:01:00+05:30</updated>
    <id>http://rushiagr.github.io/blog/2014/04/03/openstack-in-an-hour-with-devstack</id>
    <content type="html"><![CDATA[<p>So you found out a cool new technology "OpenStack" and want to try it real quick? Or probably you are hired in a company for your Python skills and now you are supposed to work on OpenStack in the shortest possible time? Fear not, it is not that hard to get started. <a href="http://devstack.org">DevStack</a> is your friend-in-need. No, don't click that hyperlink just yet :)</p>

<!--more-->


<p>To put it in a sentence, DevStack is "OpenStack in a box". You just need a popular Linux based distribution with 2GB RAM and you're all set to start. DevStack is basically a set of scripts which will install all the important OpenStack services in your computer. For this, it will first download all the essential packages, pull in the OpenStack code from various OpenStack projects, and set everything up for you to try out all of it.</p>

<p>NOTE: DO NOT set up DevStack for production clouds.</p>

<p>Here, in this tutorial, I'll be setting up DevStack in a 64-bit Ubuntu 12.04 virtual machine. All your virtual machine needs to have is an Internet connection, and 2GB RAM.</p>

<p>NOTE: Do not run any of the script as a root user, unless specified otherwise explicitly.</p>

<h3>Getting started</h3>

<p>Install git</p>

<pre><code>sudo apt-get install git
</code></pre>

<p>Clone the DevStack repository into your computer and <code>cd</code> into it. This is the code which will set up the cloud for you.</p>

<pre><code>git clone http://github.com/openstack-dev/devstack
cd devstack/
</code></pre>

<p>If you do a <code>ls</code>, you will see <code>stack.sh</code>, <code>unstack.sh</code> and <code>rejoin-stack.sh</code> files in there. These are the most important files.</p>

<pre><code>r@ra:~/devstack$ ls
accrc         exercises         HACKING.rst  rejoin-stack.sh  tests
AUTHORS       exercise.sh       lib          run_tests.sh     tools
clean.sh      extras.d          LICENSE      samples          unstack.sh
driver_certs  files             localrc      stackrc
eucarc        functions         openrc       stack-screenrc
exerciserc    functions-common  README.md    stack.sh
</code></pre>

<p>File <code>stack.sh</code> is the most important of them all. Running this script will:
1. Pull OpenStack code from all of it's important projects' repositories and put them in <code>/opt/stack</code> directory. TODO: say that this directory is configurable.
2. Installs all the dependencies these OpenStack projects have -- both in the form of Ubuntu packages, and also the Python "PIP" repositories.
3. Starts all the OpenStack services with a default configuration.</p>

<p>Bringing down the DevStack-created cloud is easy too -- just invoke the <code>unstack.sh</code> script, and all the services are down again, freeing up the memory that these services consume. I'll talk about <code>rejoin-stack.sh</code> in some time. Let's get started before I start writing at lengths again :)</p>

<p>Execute the <code>stack.sh</code> script</p>

<pre><code>r@ra:~/devstack$ ./stack.sh 

################################################################################
ENTER A PASSWORD TO USE FOR THE DATABASE.
################################################################################
This value will be written to your localrc file so you don't have to enter it 
again.  Use only alphanumeric characters.
If you leave this blank, a random default value will be used.
Enter a password now:
</code></pre>

<p>You need to add the MySQL database password here. Don't worry if you have not installed MySQL on this system. Just provide a password here and this script will install MySQL and use this password there.</p>

<p>As you can see, MySQL is where all the important data is stored by different OpenStack components. You can peep into the database later if you want to see what data is stored, etc.</p>

<p>Also, note the first line after the heading. If the <code>stack.sh</code> script finishes successfully, all the inputs you specify (this, and four more after this) will be written to a file named as <code>localrc</code>. All the local configuration setting pertaining to the DevStack environment will go in this file. I'll provide you with details of all of them very soon. Have patience :)</p>

<p>For the other four prompts, enter 'nova'. Just use 'nova' for this MySQL prompt too if it is not installed yet.</p>

<p>You will see that the script now starts spewing a lot of output on our screen. It is downloading all the required code, packages, dependencies, etc, and setting everything up for us -- databases, services, network, configurations, message queues. Pretty much everything. For the first time, the script might take about 30-minutes, but it again depends upon the speed of your Internet connection, and the processing speed of your virtual machine. From the next time, it can provide you with a cloud in less than 10 minutes!</p>

<p>If the script ends with something like this:</p>

<pre><code>+ merge_config_group /home/r/devstack/local.conf post-extra
+ local localfile=/home/r/devstack/local.conf
+ shift
+ local matchgroups=post-extra
+ [[ -r /home/r/devstack/local.conf ]]
+ return 0
+ [[ -x /home/r/devstack/local.sh ]]
+ service_check
+ local service
+ local failures
+ SCREEN_NAME=stack
+ SERVICE_DIR=/opt/stack/status
+ [[ ! -d /opt/stack/status/stack ]]
++ ls '/opt/stack/status/stack/*.failure'
++ /bin/true
+ failures=
+ '[' -n '' ']'
+ set +o xtrace



Horizon is now available at http://10.0.2.15/
Keystone is serving at http://10.0.2.15:5000/v2.0/
Examples on using novaclient command line is in exercise.sh
The default users are: admin and demo
The password: nova
This is your host ip: 10.0.2.15
stack.sh completed in 269 seconds.
</code></pre>

<p>That means your machine is now home to a Cloud! :)</p>

<p>Here, <code>10.0.2.15</code> is the IP of my first network interface. Don't worry about that for now.</p>

<p>So now you can head over to my blog <a href="http://www.rushiagr.com/blog/2013/05/27/cinder-on-devstack-quick-start/">Cinder on DevStack - Quick Start</a> to get started with creating volumes (persistent storage in cloud) with Cinder -- OpenStack's block-storage project. In that guide, you will also be creating a virtual machine, so it will be a good start to OpenStack. But let's get back in our current scope.</p>

<p>You can type the host IP provided by the script into your browser, to access the dashboard 'Horizon'. Log into it using username 'admin', or 'demo' and password 'nova'. (For simplicity's sake, lets just assume there are two users who are allowed to access this cloud -- one has all the administrative privilages, and the other one is just a normal user).</p>

<p>You can view all the process logs inside screen, by typing:</p>

<pre><code>screen -x
</code></pre>

<p>Head over to <a href="http://www.rushiagr.com/blog/2013/06/05/linux-screens-in-devstack/">Linux Screens in DevStack</a> for more information on how to work with <code>screen</code>.</p>

<h3>Housekeeping and customizations</h3>

<p>In your life as an OpenStack developer, you will be setting up and destroying DevStack instance quite a number of times. So it is good to know how to do that in the most efficient manner.</p>

<p>Just like <code>stack.sh</code> script is used to set up DevStack, <code>unstack.sh</code> is used to destroy the DevStack setup. Running it will kill all the services, BUT it will not delete any of the code. If you want to bring down all the services manually, just do a:</p>

<pre><code>sudo killall screen
</code></pre>

<p>Note that this will just kill all the process which were running, for which you were able to see the logs inside screen. <code>unstack.sh</code> does some cleanups as well along with killing processes.</p>

<p>If you had previously run <code>./stack.sh</code>, but have brought down the environment, you can bring it up back by executing the <code>rejoin_stack.sh</code> script.</p>

<p>NOTE: DevStack environment doesn't persist across reboots!</p>

<p>So you need to bring back up the DevStack environment manually everytime you reboot. Here is where using a virtual machine comes handy. You can take a snapshot of the virtual machine, and then go back to it when you want a clean DevStack environment.</p>

<p>Nonetheless, the best way to reboot is: first execute <code>unstack.sh</code> to bring down the current running DevStack instance. Then reboot, and when your machine comes up again, run <code>rejoin_stack.sh</code>. If you don't run <code>unstack.sh</code>, you will need to execute <code>stack.sh</code> again to have the environment up.</p>

<h3>localrc configurations</h3>

<p><code>localrc</code> is the file where all the local configurations (local = your local machine) are kept.</p>

<p>After first successful <code>stack.sh</code> run, will see that a localrc file gets created with the configuration values you specified while running that script.</p>

<pre><code>$ cat localrc 
DATABASE_PASSWORD=nova
RABBIT_PASSWORD=nova
SERVICE_TOKEN=nova
SERVICE_PASSWORD=nova
ADMIN_PASSWORD=nova
</code></pre>

<p>Sometimes you will forget to unstack, and will reboot the machine. And then you will find that running <code>stack.sh</code> will again do an <code>apt-get update</code>, and check for all packages, etc.</p>

<p>If you specify an option <code>OFFLINE=True</code> in a file named <code>localrc</code>, inside the devstack directory, and if after specifying this you run <code>stack.sh</code>, it will not check anything over the Internet, and will set up DevStack using all the packages and code residing in your machine. Setting up a DevStack using this config option will give you a running cloud in the shortest amount of time (after <code>rejoin_stack.sh</code>, but you have already forgotten to do <code>unstack.sh</code>, right :) ).</p>

<p>Note that <code>stack.sh</code> will see if the git repositories of the OpenStack projects are present in <code>/opt/stack/</code> directory. If they are, it will not fetch any latest code into them from Github. But if any of the directory (say, <code>nova</code>), is absent, it will pull latest code into the newly created <code>nova</code> directory inside <code>/opt/stack</code>.</p>

<p>What if you want to get the latest code into all the OpenStack repositories inside <code>/opt/stack</code>? Just specify a <code>RECLONE=yes</code> parameter in localrc, and rerun <code>./stack.sh</code>. This comes particularly handy when you are developing new code.</p>

<p>NOTE: Keep in mind that while developing code, you need to <strong>commit your local changes</strong> in, say, <code>/opt/stack/nova</code> repository, before you restack (re-run <code>stack.sh</code>) with <code>RECLONE=yes</code> option, as otherwise, the changes will be wiped off. Save yourself from a rude shock. You have been warned.</p>

<p>Configuration options <code>RECLONE=yes</code> and <code>OFFLINE=True</code> are complementary, and hence, use only one of them at a time in <code>localrc</code>.</p>

<p>If you have more than one interfaces, you can specify which one to use for external IP using this configuration:</p>

<pre><code>HOST_IP=192.168.xxx.xxx
</code></pre>

<h3>Developing code</h3>

<p>If you want to immediately test out your code by running it inside DevStack, you need to make the changes in the code, and restart the affected services.</p>

<p>For example, let us say you are making code changes in <code>nova</code>. Just after you are done making the changes, go to the screen, and restart all the services which start with "n-". If you are very sure that only one of the Nova service is affected, just restart that. Or if you don't know which one to restart, it is safe to restart all of them.</p>

<p>In order to restart, go to the respective screen and press <code>CTRL</code>+<code>C</code>. Then, press the up arrow once to get the last command which started this screen session, and then press <code>ENTER</code>.</p>

<h3>Final words</h3>

<p>Note that this guide just gets you started with OpenStack using DevStack. OpenStack, and cloud in general, is not about virtual machines or volumes or networks only. It is a philosophy. It is a complete paradigm shift, and as such, it is impossible to cover all of it by me. Your quest to know more about it has just started. Keep reading more and more about it and I guarantee you you will be fascinated by it's limitless possibilities.</p>

<p>This post is written keeping in mind that it will be consumed by a newbie to OpenStack development. If you are one of the one benefitting from this guide, I would love it if you can provide me with suggestions to improve this post, and any feedback you have about it.</p>

<p>Now you can go to the <a href="http://devstack.org">DevStack</a> website :)</p>

<p>Cheers!
Rushi</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[MySQL Cheat Sheet]]></title>
    <link href="http://rushiagr.github.io/blog/2014/03/31/mysql-cheat-sheet/"/>
    <updated>2014-03-31T18:49:00+05:30</updated>
    <id>http://rushiagr.github.io/blog/2014/03/31/mysql-cheat-sheet</id>
    <content type="html"><![CDATA[<p>Databases are so important, yet almost all the time I need to work with it, I find that I have already forgotten all the syntax! So here I am writing down a quick cheat sheet to get me up and running when I'm waking up from slumber. I hope this will help atleast one other guy on this planet.</p>

<!-- more -->


<p>I use mostly Ubuntu, so some of the commands might be Ubuntu specific.</p>

<p>Install mysql</p>

<pre><code>sudo apt-get install mysql-server
</code></pre>

<p>A prompt will ask for the root password.</p>

<p>To change the root password:</p>

<pre><code>UPDATE mysql.user SET password=PASSWORD('nova') WHERE user='root';
</code></pre>

<p>NOTE: MySQL keywords are case insensitive. They're represented in capital here just so that they appear different than the rest. When you're just testing out some things logging into the DB console, people generally prefer writing in small caps.</p>

<p>Note that <code>PASSWORD</code> is a function, and unlike other MySQL keywords cannot be used in small caps.</p>

<p>Log into MySQL console with user <code>root</code> and password <code>mysecretpassword</code>:</p>

<pre><code>mysql -uroot -pmysecretpassword
</code></pre>

<p>or</p>

<pre><code>mysql -u'root' -p'mysecretpassword'
</code></pre>

<p>or entering the password in 'secret' mode:</p>

<pre><code>$ mysql -uroot -p
Enter password: 
</code></pre>

<h3>MySQL console</h3>

<p>List all databases:</p>

<pre><code>mysql&gt; SHOW DATABASES;
+--------------------+
| Database           |
+--------------------+
| information_schema |
| mysql              |
| performance_schema |
| test               |
+--------------------+
4 rows in set (0.01 sec)
</code></pre>

<p>Create a new database <code>rushi</code>:</p>

<pre><code>mysql&gt; CREATE DATABASE rushi;
Query OK, 1 row affected (0.00 sec)

mysql&gt; show databases;
+--------------------+
| Database           |
+--------------------+
| information_schema |
| mysql              |
| performance_schema |
| rushi              |
| test               |
+--------------------+
5 rows in set (0.00 sec)
</code></pre>

<p>Select database <code>rushi</code>, so that all the further operations are executed inside this database:</p>

<pre><code>mysql&gt; USE rushi;
Database changed
</code></pre>

<p>Create a table <code>friends</code> inside <code>rushi</code> database:</p>

<pre><code>mysql&gt; CREATE TABLE friends (name VARCHAR(20), age INT);
Query OK, 0 rows affected (0.03 sec)
</code></pre>

<p>If you didn't select the database in the last to last command, you need to specify table in this format:<code>&lt;database&gt;.&lt;tablename&gt;</code>. So the last command would look like:</p>

<pre><code>mysql&gt; CREATE TABLE rushi.friends (name VARCHAR(20), age INT);
</code></pre>

<p>List all the tables:</p>

<pre><code>mysql&gt; show tables;
+-----------------+
| Tables_in_rushi |
+-----------------+
| friends         |
+-----------------+
1 rows in set (0.00 sec)
</code></pre>

<p>Insert data into <code>friends</code>:</p>

<pre><code>mysql&gt; INSERT INTO friends VALUES ('arvind', 24);
Query OK, 1 row affected (0.01 sec)
</code></pre>

<p>Display all the data from the table:</p>

<pre><code>mysql&gt; SELECT * FROM friends;
+--------+------+
| name   | age  |
+--------+------+
| arvind |   24 |
+--------+------+
1 row in set (0.00 sec)
</code></pre>

<p>Insert another friend:</p>

<pre><code>mysql&gt; INSERT INTO friends VALUES ('honshu', 23);
Query OK, 1 row affected (0.00 sec)

mysql&gt; SELECT * FROM friends;
+--------+------+
| name   | age  |
+--------+------+
| arvind |   24 |
| honshu |   23 |
+--------+------+
2 rows in set (0.00 sec)
</code></pre>

<p>Update a row in the table:</p>

<pre><code>mysql&gt; UPDATE friends SET age=22 WHERE name='honshu';
Query OK, 1 row affected (0.02 sec)
Rows matched: 1  Changed: 1  Warnings: 0

mysql&gt; SELECT * FROM friends;
+--------+------+
| name   | age  |
+--------+------+
| arvind |   24 |
| honshu |   22 |
+--------+------+
2 rows in set (0.00 sec)
</code></pre>

<p>Delete a row from table:</p>

<pre><code>mysql&gt; DELETE FROM friends WHERE age=24;
Query OK, 1 row affected (0.00 sec)

mysql&gt; select * from friends;
+--------+------+
| name   | age  |
+--------+------+
| honshu |   22 |
+--------+------+
1 row in set (0.00 sec)
</code></pre>

<p>Delete all rows from the table in one go, and reset the autoincrement if any:</p>

<pre><code>mysql&gt; TRUNCATE friends;
Query OK, 0 rows affected (0.04 sec)
</code></pre>

<p>Delete the table and all of its contents:</p>

<pre><code>mysql&gt; DROP TABLE friends;
</code></pre>

<p>Other commonly used commands are listed below. Try to try all of them out atleast once.
Count the number of rows in a table:</p>

<pre><code>SELECT COUNT(*) FROM friends;
</code></pre>

<p>Select distinct values for a row, and order them too:</p>

<pre><code>SELECT DISTINCT age FROM friends ORDER BY age;
</code></pre>

<p>Modify table to add one more column to it:</p>

<pre><code>ALTER TABLE friend ADD height varchar(10);
</code></pre>

<p>Use regular expressions:</p>

<pre><code>SELECT * FROM friend WHERE name REGEXP 'arv*';
</code></pre>

<p>CAUTION: Regular expressions comes with some binary/encoding trickery. Use it with a lot of caution.</p>

<p>Create a new user for the database, and give it all the root privileges</p>

<pre><code>CREATE USER 'rushiagr'@'localhost' IDENTIFIED BY 'mysecretpass'
GRANT ALL PRIVILEGES ON * . * TO 'rushiagr'@'localhost'
</code></pre>

<p>Take a dump of database <code>rushi</code> and store it in a file <code>db.dump</code>. Execute this command in bash shell, and not in the MySQL shell.:</p>

<pre><code>mysqldump --user root rushi &gt; db.dump
</code></pre>

<p>The End!</p>

<p>Comments/suggestions/feedback? Please feel free to comment and I'll make sure I acknowledge them to the fullest.</p>

<p>Cheers!</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Playing around with Cinder multi-backend]]></title>
    <link href="http://rushiagr.github.io/blog/2014/01/16/cinder-playing-with-multi-backend/"/>
    <updated>2014-01-16T22:42:00+05:30</updated>
    <id>http://rushiagr.github.io/blog/2014/01/16/cinder-playing-with-multi-backend</id>
    <content type="html"><![CDATA[<p>With Grizzly release, Cinder got equipped with another major feature -- multi-backends
with filter scheduler. So now you can have more than one storage boxes for block storage
and manage them with one Cinder deployment. Here, I'm going to test it out using our
favourite method -- trying it out on DevStack!</p>

<!--more-->


<p>DevStack can provide you with two LVM backends to play around with them. But you'll need to restack it.</p>

<p>Go to the devstack directory and pull the latest code. Destroy previous DevStack deployment if it exists.</p>

<pre><code>rushi@jio:~/devstack$ git pull origin master
rushi@jio:~/devstack$ ./unstack.sh
</code></pre>

<p>Add the config option to <code>localrc</code> which give you pre-cooked multi-backend setup with two LVM backends, both of 10G. Stack</p>

<pre><code>rushi@jio:~$ echo "CINDER_MULTI_LVM_BACKEND=True" &gt;&gt; localrc
rushi@jio:~$ ./devstack/stack.sh
</code></pre>

<p>You can see that the cinder.conf file now has two values for enabled backends:</p>

<pre><code>rushi@jio:~$ less /etc/cinder/cinder.conf | grep enabled_backends
enabled_backends = lvmdriver-1,lvmdriver-2
#enabled_backends=&lt;None&gt;
</code></pre>

<p>Also, you can see that there are two configuration groups created at the end of that config file, one each for configurations
corresponding to that particular backend</p>

<pre><code>rushi@jio:~$ tail /etc/cinder/cinder.conf 

[lvmdriver-1]
volume_backend_name = LVM_iSCSI
volume_driver = cinder.volume.drivers.lvm.LVMISCSIDriver
volume_group = stack-volumes

[lvmdriver-2]
volume_backend_name = LVM_iSCSI_2
volume_driver = cinder.volume.drivers.lvm.LVMISCSIDriver
volume_group = stack-volumes2
</code></pre>

<p>So you have two volume groups created for respective backends. Lets check it directly without using Cinder.</p>

<pre><code>rushi@jio:~$ sudo vgs
  VG             #PV #LV #SN Attr   VSize   VFree 
  stack-volumes    1   0   0 wz--n-  10.01g 10.01g
  stack-volumes2   1   0   0 wz--n-  10.01g 10.01g
  ubuntu-vg        1   2   0 wz--n- 931.27g 44.00m
</code></pre>

<p>Hmmm. Two volume groups, each of size 10G.</p>

<h3>Case 1: Spreading volumes across backends</h3>

<p>Now, lets create a volume and see where it ends up.</p>

<pre><code>rushi@jio:~$ cinder create 1
ERROR: You must provide a username via either --os-username or env[OS_USERNAME]
</code></pre>

<p>Oops! Let me try again..</p>

<pre><code>rushi@jio:~$ . devstack/openrc 
rushi@jio:~$ cinder create 1
+-------------------+--------------------------------------+
|      Property     |                Value                 |
+-------------------+--------------------------------------+
|    attachments    |                  []                  |
| availability_zone |                 nova                 |
|      bootable     |                false                 |
|     created_at    |      2014-01-16T17:29:49.241493      |
|    description    |                 None                 |
|         id        | ecfbfebb-73d5-4faf-b625-e69f18020378 |
|      metadata     |                  {}                  |
|        name       |                 None                 |
|        size       |                  1                   |
|    snapshot_id    |                 None                 |
|    source_volid   |                 None                 |
|       status      |               creating               |
|      user_id      |   e441f49105f343da87316ab7157e2ab7   |
|    volume_type    |                 None                 |
+-------------------+--------------------------------------+

rushi@jio:~$ cinder list
+--------------------------------------+-----------+------+------+-------------+----------+-------------+
|                  ID                  |   Status  | Name | Size | Volume Type | Bootable | Attached to |
+--------------------------------------+-----------+------+------+-------------+----------+-------------+
| ecfbfebb-73d5-4faf-b625-e69f18020378 | available | None |  1   |     None    |  false   |             |
+--------------------------------------+-----------+------+------+-------------+----------+-------------+

rushi@jio:~$ sudo vgs
  VG             #PV #LV #SN Attr   VSize   VFree 
  stack-volumes    1   0   0 wz--n-  10.01g 10.01g
  stack-volumes2   1   2   0 wz--n-  10.01g  9.01g
  ubuntu-vg        1   2   0 wz--n- 931.27g 44.00m
</code></pre>

<p>So it went to backend number 2. If you are admin (<code>source devstack/openrc admin admin</code>), you can do a <code>cinder show</code> too, to get information
as to which host did this volume go to. Only the admin is allowed to view the host information.</p>

<p>The scheduler now gets reported of the capabilities which the backends have (check out the <code>c-shr</code> screen to see it). The scheduler then weighs the backend based on these capabilities and decides which of them has higher 'weight' to serve the next 'create' request. By default, the 'weigher' for scheduler is <code>CapacityWeigher</code>. That is, whichever backend has higher capacity, that backend will be chosen for the next 'create' request.</p>

<p>So in our case, when we'll do another 'create volume' it will now land on to the first backend.</p>

<pre><code>rushi@jio:~$ cinder create 1
+-------------------+--------------------------------------+
|      Property     |                Value                 |
+-------------------+--------------------------------------+
|    attachments    |                  []                  |
| availability_zone |                 nova                 |
|      bootable     |                false                 |
|     created_at    |      2014-01-16T17:39:23.958468      |
|    description    |                 None                 |
|         id        | aa79c608-47cc-44e3-a614-f4bddaab68e5 |
|      metadata     |                  {}                  |
|        name       |                 None                 |
|        size       |                  1                   |
|    snapshot_id    |                 None                 |
|    source_volid   |                 None                 |
|       status      |               creating               |
|      user_id      |   e441f49105f343da87316ab7157e2ab7   |
|    volume_type    |                 None                 |
+-------------------+--------------------------------------+

rushi@jio:~$ sudo vgs
  VG             #PV #LV #SN Attr   VSize   VFree 
  stack-volumes    1   0   0 wz--n-  10.01g  9.01g
  stack-volumes2   1   2   0 wz--n-  10.01g  9.01g
  ubuntu-vg        1   2   0 wz--n- 931.27g 44.00m
</code></pre>

<p>Neat!</p>

<h3>Case 2 : Stacking all volumes at one backend</h3>

<p>What if we want to keep all the volumes at only one backend? Cinder allows you to do that too!
There is a configuration option in cinder.conf, <code>capacity_weight_multiplier</code>, which allows you to multiply the 'capacity weight' by a number.
So if the multiplier is 1, a backend with higher capacity will have higher weight, and will be the choice for the next volume creation request.
This is the default case. BUT what if we set it to -1? The backend with higher available capacity will have more negative weight, which will make that backend less preferable for next 'create' request, and hence the request will go to the backend which has lesser capacity!</p>

<p>Let us see this too in action.</p>

<p>Check out the config option from cinder.conf file.</p>

<pre><code>rushi@jio:~$ cat /etc/cinder/cinder.conf | grep -B 3 ^capacity_weight_multiplier

# Multiplier used for weighing volume capacity. Negative
# numbers mean to stack vs spread. (floating point value)
# capacity_weight_multiplier=1.0
</code></pre>

<p>The config option is commented out and is there just so that you can easily change it. Now uncomment it and change it's value to -1.</p>

<p>Delete previously created volumes. Kill all the three Cinder screen processes (<code>c-api</code>, <code>c-sch</code> and <code>c-vol</code>), and restart them.</p>

<p>Lets create two volumes and see where they end up..</p>

<pre><code>rushi@jio:~$ cinder list
+----+--------+------+------+-------------+----------+-------------+
| ID | Status | Name | Size | Volume Type | Bootable | Attached to |
+----+--------+------+------+-------------+----------+-------------+
+----+--------+------+------+-------------+----------+-------------+
rushi@jio:~$ cinder create 1
+-------------------+--------------------------------------+
|      Property     |                Value                 |
+-------------------+--------------------------------------+
|    attachments    |                  []                  |
| availability_zone |                 nova                 |
|      bootable     |                false                 |
|     created_at    |      2014-01-16T17:56:59.845733      |
|    description    |                 None                 |
|         id        | b927b328-5ae0-411a-9de2-22ed732b4946 |
|      metadata     |                  {}                  |
|        name       |                 None                 |
|        size       |                  1                   |
|    snapshot_id    |                 None                 |
|    source_volid   |                 None                 |
|       status      |               creating               |
|      user_id      |   e441f49105f343da87316ab7157e2ab7   |
|    volume_type    |                 None                 |
+-------------------+--------------------------------------+
rushi@jio:~$ cinder create 1
+-------------------+--------------------------------------+
|      Property     |                Value                 |
+-------------------+--------------------------------------+
|    attachments    |                  []                  |
| availability_zone |                 nova                 |
|      bootable     |                false                 |
|     created_at    |      2014-01-16T17:57:01.132756      |
|    description    |                 None                 |
|         id        | 9f643f2d-7221-4a5c-bf48-1977c9b89fd3 |
|      metadata     |                  {}                  |
|        name       |                 None                 |
|        size       |                  1                   |
|    snapshot_id    |                 None                 |
|    source_volid   |                 None                 |
|       status      |               creating               |
|      user_id      |   e441f49105f343da87316ab7157e2ab7   |
|    volume_type    |                 None                 |
+-------------------+--------------------------------------+

rushi@jio:~$ sudo vgs
  VG             #PV #LV #SN Attr   VSize   VFree 
  stack-volumes    1   0   0 wz--n-  10.01g 10.01g
  stack-volumes2   1   2   0 wz--n-  10.01g  8.01g
  ubuntu-vg        1   2   0 wz--n- 931.27g 44.00m
</code></pre>

<p>:)</p>

<h3>Case 3 : Custom choice</h3>

<p>What if I have two different backends (maybe one is slower, or costlier, than the other), and my users want to exactly specify how many volumes they want of each 'type' of backends? Here, Cinder's 'volume types' have us covered.</p>

<p>We can associate a volume type with a backend, and then the users can create a volume of whatever 'type' they want.
Let's throw some discrimination at these backends. I'll create two volume types: 'gold' and 'bronze', and associate 'stack-volumes' with 'gold' and similarly for 'stack-volumes2'. Note that this job can only be done by the administrator.</p>

<p>Let us be admins</p>

<pre><code>rushi@jio:~$ . devstack/openrc admin admin
</code></pre>

<p>Create both the volume types and list them.</p>

<pre><code>rushi@jio:~$ cinder type-create gold
+--------------------------------------+------+
|                  ID                  | Name |
+--------------------------------------+------+
| dd883ee0-24be-42e1-ab2e-b9a01454f2f9 | gold |
+--------------------------------------+------+
rushi@jio:~$ cinder type-create bronze
+--------------------------------------+--------+
|                  ID                  |  Name  |
+--------------------------------------+--------+
| f63dd2cb-f4e7-4d6d-a84f-5bf2cc6c5671 | bronze |
+--------------------------------------+--------+

rushi@jio:~$ cinder type-list
+--------------------------------------+--------+
|                  ID                  |  Name  |
+--------------------------------------+--------+
| dd883ee0-24be-42e1-ab2e-b9a01454f2f9 |  gold  |
| f63dd2cb-f4e7-4d6d-a84f-5bf2cc6c5671 | bronze |
+--------------------------------------+--------+
</code></pre>

<p>Get the backend names (<code>volume_backend_name</code> config option) from cinder.conf file.</p>

<pre><code>rushi@jio:~$ tail /etc/cinder/cinder.conf 

[lvmdriver-1]
volume_backend_name = LVM_iSCSI
volume_driver = cinder.volume.drivers.lvm.LVMISCSIDriver
volume_group = stack-volumes

[lvmdriver-2]
volume_backend_name = LVM_iSCSI_2
volume_driver = cinder.volume.drivers.lvm.LVMISCSIDriver
volume_group = stack-volumes2
</code></pre>

<p>Now let's associate backend <code>LVM_iSCSI</code> with volume type 'gold', and similarly for the other one.</p>

<pre><code>rushi@jio:~$ cinder type-key gold set volume_backend_name=LVM_iSCSI
rushi@jio:~$ cinder type-key bronze set volume_backend_name=LVM_iSCSI_2
</code></pre>

<p>These association are stored as key-value pairs in the volume type's 'extra specs'. Let's see them</p>

<pre><code>rushi@jio:~$ cinder extra-specs-list 
+--------------------------------------+--------+------------------------------------------+
|                  ID                  |  Name  |               extra_specs                |
+--------------------------------------+--------+------------------------------------------+
| dd883ee0-24be-42e1-ab2e-b9a01454f2f9 |  gold  |  {u'volume_backend_name': u'LVM_iSCSI'}  |
| f63dd2cb-f4e7-4d6d-a84f-5bf2cc6c5671 | bronze | {u'volume_backend_name': u'LVM_iSCSI_2'} |
+--------------------------------------+--------+------------------------------------------+
</code></pre>

<p>You can add more key-value pairs for these volume types with different key names. <code>volume_backend_name</code> is a reserved key name, though.</p>

<p>Let's create two volumes of type 'gold' and see where they end up being created:</p>

<pre><code>rushi@jio:~$ cinder create --volume-type gold --name costly_vol_1 1
+-------------------+--------------------------------------+
|      Property     |                Value                 |
+-------------------+--------------------------------------+
|    attachments    |                  []                  |
| availability_zone |                 nova                 |
|      bootable     |                false                 |
|     created_at    |      2014-01-16T18:24:07.670635      |
|    description    |                 None                 |
|         id        | 767d4c56-6d3d-46f7-b0a3-4a00f696bcad |
|      metadata     |                  {}                  |
|        name       |             costly_vol_1             |
|        size       |                  1                   |
|    snapshot_id    |                 None                 |
|    source_volid   |                 None                 |
|       status      |               creating               |
|      user_id      |   c271eb32e71b411bb98ad7b93792d6d5   |
|    volume_type    |                 gold                 |
+-------------------+--------------------------------------+
rushi@jio:~$ cinder create --volume-type gold --name costly_vol_2 1
+-------------------+--------------------------------------+
|      Property     |                Value                 |
+-------------------+--------------------------------------+
|    attachments    |                  []                  |
| availability_zone |                 nova                 |
|      bootable     |                false                 |
|     created_at    |      2014-01-16T18:24:58.382180      |
|    description    |                 None                 |
|         id        | a938e556-65cf-4547-87ff-513d60f626d3 |
|      metadata     |                  {}                  |
|        name       |             costly_vol_2             |
|        size       |                  1                   |
|    snapshot_id    |                 None                 |
|    source_volid   |                 None                 |
|       status      |               creating               |
|      user_id      |   c271eb32e71b411bb98ad7b93792d6d5   |
|    volume_type    |                 gold                 |
+-------------------+--------------------------------------+
rushi@jio:~$ cinder list
+--------------------------------------+-----------+--------------+------+-------------+----------+-------------+
|                  ID                  |   Status  |     Name     | Size | Volume Type | Bootable | Attached to |
+--------------------------------------+-----------+--------------+------+-------------+----------+-------------+
| 767d4c56-6d3d-46f7-b0a3-4a00f696bcad | available | costly_vol_1 |  1   |     gold    |  false   |             |
| a938e556-65cf-4547-87ff-513d60f626d3 | available | costly_vol_2 |  1   |     gold    |  false   |             |
+--------------------------------------+-----------+--------------+------+-------------+----------+-------------+

rushi@jio:~$ sudo vgs
  VG             #PV #LV #SN Attr   VSize   VFree 
  stack-volumes    1   2   0 wz--n-  10.01g  8.01g
  stack-volumes2   1   0   0 wz--n-  10.01g 10.01g
  ubuntu-vg        1   2   0 wz--n- 931.27g 44.00m
</code></pre>

<p>Now create another one, but with type 'bronze' and ensure it is created on the other backend.</p>

<pre><code>rushi@jio:~$ cinder create --volume-type bronze --name cheap_vol_1 1
+-------------------+--------------------------------------+
|      Property     |                Value                 |
+-------------------+--------------------------------------+
|    attachments    |                  []                  |
| availability_zone |                 nova                 |
|      bootable     |                false                 |
|     created_at    |      2014-01-16T18:27:05.852092      |
|    description    |                 None                 |
|         id        | 97f62c7a-b974-41e8-a659-1e6d3eb876d5 |
|      metadata     |                  {}                  |
|        name       |             cheap_vol_1              |
|        size       |                  1                   |
|    snapshot_id    |                 None                 |
|    source_volid   |                 None                 |
|       status      |               creating               |
|      user_id      |   c271eb32e71b411bb98ad7b93792d6d5   |
|    volume_type    |                bronze                |
+-------------------+--------------------------------------+

rushi@jio:~$ sudo pvs
  PV         VG             Fmt  Attr PSize   PFree 
  /dev/loop0 stack-volumes  lvm2 a--   10.01g  8.01g
  /dev/loop1 stack-volumes2 lvm2 a--   10.01g  9.01g
  /dev/sda5  ubuntu-vg      lvm2 a--  931.27g 44.00m
</code></pre>

<p>Done :)</p>

<p>Cheers!</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Quick Start: Linux Logical Volume Manager]]></title>
    <link href="http://rushiagr.github.io/blog/2014/01/14/quick-start-linux-logical-volume-manager/"/>
    <updated>2014-01-14T20:09:00+05:30</updated>
    <id>http://rushiagr.github.io/blog/2014/01/14/quick-start-linux-logical-volume-manager</id>
    <content type="html"><![CDATA[<p>While installing the latest Ubuntu OS on your computer, you will see that
you can install the OS using LVM (Logical Volume Manager) utility. Ever wonder what is it?
LVM (Logical Volume Manager) is that fantastic utility for storage administration.
It provide the users with abilities which were not possible with raw disks.
The storage is now 'virtualized'. You can now easily create, move and extend volumes (for now, think of it as disk partitions)
without bothering about data corruption. You can carve partitions out of multiple disks,
and can add and remove disks from a 'volume group' containing such volumes without the user noticing anything!
List of all the features of LVM can be found at it's <a href="http://en.wikipedia.org/wiki/Logical_Volume_Manager_(Linux)"
target="_blank">wiki page</a>.</p>

<p>This blog scratches the surface of LVM, and gives some basic insights into some storage concepts.</p>

<!-- more -->


<p>I'll give you a simple example to better explain what a 'physical volume', a 'volume group' and a
'logical volume' is. Say I have two 1 TB hard disks - disk A and disk B. I have two equal-sized partitions on
disk B, one of which I want to keep it to myself for my personal data. The 'partition' term used here is
same as what you see in a file explorer. For the unpartitioned disk, the complete disk is one single partition.</p>

<p>The partitions I described above are 'physical volumes'. That is, on the disk, these are physically separate bytes (think of that
partitioned disk as a spiral on disk divided in its length at the midpoint).
Out of the first disk and one partition of the second disk, we create a 'volume group' -- a logical pool of storage, out of which we can
create lots of 'logical volumes'. Even after you've created logical volumes over this volume group, you can add and remove physical volumes (partitions) from the volume group. You can do many more operations such as resize, move and extend.</p>

<p>I hope the basic idea written above is sufficiently clear. Else, head over to this Ubuntu <a href="https://wiki.ubuntu.com/Lvm" target="_blank">wiki</a> for a slightly more detailed, but still an overview, of LVM. Anyway, I'm concentrating more on the demo, so lets move on.</p>

<h4>Hands-on</h4>

<p>I'm demo'ing everything on an Ubuntu machine, but it should work on any Linux distro (after you install the LVM2 package)</p>

<p>Install LVM2 package</p>

<pre><code>sudo apt-get install lvm2
</code></pre>

<p>One nice thing is you don't need to create actual partitions on disks. We'll use files as <a href="http://en.wikipedia.org/wiki/Loop_device" target="_blank">loopback devices</a>, which will appear to the operating system as partitions. Neat.</p>

<p>Create a file of size 1G to be later used as a physical volume.</p>

<pre><code>rushi@jio:~$ truncate --size 1G backing_file_1
</code></pre>

<p>Create a loopback device over this file. Find the first free loopback device available and show its name.</p>

<pre><code>rushi@jio:~$ sudo losetup --find --show backing_file_1 
/dev/loop0
</code></pre>

<p>List all the loopback devices.</p>

<pre><code>rushi@jio:~$ sudo losetup --all
/dev/loop0: [fc00]:22811987 (/home/rushi/backing_file_1)
</code></pre>

<p>Create a physical volume over this loopback device. Note that</p>

<pre><code>rushi@jio:~$ sudo pvcreate /dev/loop0 
  Physical volume "/dev/loop0" successfully created
</code></pre>

<p>List physical volumes. Apart from <code>pvs</code> (Physical Volume Scan), there are two more
commands which do the same thing, but with different level of verbosity and formatting: <code>pvscan</code> and <code>pvdisplay</code>. (Try them out too!)</p>

<pre><code>rushi@jio:~$ sudo pvs
  PV         VG        Fmt  Attr PSize   PFree 
  /dev/loop0           lvm2 a--    1.00g  1.00g
  /dev/sda5  ubuntu-vg lvm2 a--  931.27g 44.00m
</code></pre>

<p>Let us repeat the steps to create another physical volume:</p>

<pre><code>rushi@jio:~$ truncate --size 1G backing_file_2
rushi@jio:~$ sudo losetup --find --show backing_file_2 
/dev/loop1
rushi@jio:~$ sudo losetup --all
/dev/loop0: [fc00]:22811987 (/home/rushi/backing_file_1)
/dev/loop1: [fc00]:22812001 (/home/rushi/backing_file_2)
rushi@jio:~$ sudo pvcreate /dev/loop1
  Physical volume "/dev/loop1" successfully created
rushi@jio:~$ sudo pvs
  PV         VG        Fmt  Attr PSize   PFree 
  /dev/loop0           lvm2 a--    1.00g  1.00g
  /dev/loop1           lvm2 a--    1.00g  1.00g
  /dev/sda5  ubuntu-vg lvm2 a--  931.27g 44.00m
</code></pre>

<p>Create a volume group <code>test-volgroup</code> over these two physical volumes. (Actually, even if you don't create physical volumes over loopback devices, while creating volume groups it will automatically create physical volumes over them).</p>

<pre><code>rushi@jio:~$ sudo vgcreate test-volgroup /dev/loop0 /dev/loop1
  Volume group "test-volgroup" successfully created
</code></pre>

<p>List the volume groups. (<code>vgs</code>, <code>vgscan</code> or <code>vgdisplay</code> can be used)</p>

<pre><code>rushi@jio:~$ sudo vgs
  VG            #PV #LV #SN Attr   VSize   VFree 
  test-volgroup   2   0   0 wz--n-   1.99g  1.99g
  ubuntu-vg       1   2   0 wz--n- 931.27g 44.00m
</code></pre>

<p>Create a logical volume <code>test-logicalvol</code> over the <code>test-volgroup</code> volume group.</p>

<pre><code>rushi@jio:~$ sudo lvcreate --size 400M --name test-logicalvol test-volgroup
  Logical volume "test-logicalvol" created
</code></pre>

<p>List logical volumes. (<code>lvs</code>, <code>lvscan</code>, <code>lvdisplay</code> can be used)</p>

<pre><code>rushi@jio:~$ sudo lvs
  LV              VG            Attr      LSize   Pool Origin Data%  Move Log Copy%  Convert
  test-logicalvol test-volgroup -wi-a---- 400.00m                                           
  root            ubuntu-vg     -wi-ao--- 923.35g                                           
  swap_1          ubuntu-vg     -wi-ao---   7.88g                                           
</code></pre>

<p>Easy, isn't it? Let's tear down everything. Though a simpler way would be to just remove the loopback device, which will automatically
remove all the physical, logical volumes/volume groups created over them, let's do it step-by-step. Note that you need to specify volume group while deleting logical volumes.</p>

<pre><code>rushi@jio:~$ sudo lvremove test-volgroup
Do you really want to remove active logical volume test-logicalvol? [y/n]: y
  Logical volume "test-logicalvol" successfully removed
rushi@jio:~$ sudo vgremove test-volgroup
  Volume group "test-volgroup" successfully removed
rushi@jio:~$ sudo pvremove /dev/loop0 /dev/loop1
  Labels on physical volume "/dev/loop0" successfully wiped
  Labels on physical volume "/dev/loop1" successfully wiped
rushi@jio:~$ sudo losetup --detach /dev/loop0 /dev/loop1
rushi@jio:~$ rm backing_file_1 backing_file_2
</code></pre>

<p>Cheers!</p>
]]></content>
  </entry>
  
</feed>
