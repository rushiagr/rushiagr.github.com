<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en-us">
<head>
  <link href="https://gmpg.org/xfn/11" rel="profile">
  <meta http-equiv="content-type" content="text/html; charset=utf-8">

  
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1">

  

  <title> rushiagr </title>

  
  <link rel="stylesheet" href="http://rushiagr.com/css/poole.css">
  <link rel="stylesheet" href="http://rushiagr.com/css/syntax.css">
  <link rel="stylesheet" href="http://rushiagr.com/css/hyde.css">
  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=PT+Sans:400,400italic,700|Abril+Fatface">

  
  <link rel="apple-touch-icon-precomposed" sizes="144x144" href="/apple-touch-icon-144-precomposed.png">
  <link rel="shortcut icon" href="/favicon.ico">

  
  <link href="http://rushiagr.com/index.xml" rel="alternate" type="application/rss+xml" title="rushiagr" />

  <link href="//netdna.bootstrapcdn.com/font-awesome/4.0.3/css/font-awesome.css" rel="stylesheet">

  <link href='https://fonts.googleapis.com/css?family=Raleway:400,300' rel='stylesheet' type='text/css'>

  <script src="//ajax.googleapis.com/ajax/libs/webfont/1.4.7/webfont.js"></script>
  <script>
    WebFont.load({
      google: {
        families: ['Raleway']
      }
    });
  </script>

</head>

<body>

<div class="sidebar">
  <div class="container sidebar-sticky">
    <div class="sidebar-about">
      <h1 class="brand"><a href="http://rushiagr.com">rushiagr</a></h1>
      <p class="lead">
       code by Rushi Agrawal 
      </p>
    </div>



    <ul class="sidebar-nav">
      <li><a href="http://rushiagr.com/blog">Posts</a></li>
      
        <li><a href="/about/">About </a></li>
        <li><a href="https://github.com/rushiagr">Code</a></li>
      
      <br/>
      
        
        
        
        
        
        
        
      
    </ul>
      <a href="https://twitter.com/rushiagr"><i class="fa fa-twitter-square"></i></a>&nbsp;&nbsp;
      
      
      <a href="https://github.com/rushiagr"><i class="fa fa-github-square"></i></a>&nbsp;&nbsp;
      

    <p class="footnote">powered by <a href="http://hugo.spf13.com">Hugo</a> <br/>
    &copy; 2016 Rushi Agrawal. Theme by <a href="https://github.com/natefinch/npf/">npf</a>. All rights reserved.</p>
    
  </div>
</div>


    <div class="content container">
<div class="posts">

      
  
  
  
  <div class="post">
    <h1 class="post-title">
      <a href="http://rushiagr.com/blog/2016/01/10/tmux-session-shortcuts/">
        Tmux session shortcuts
      </a>
    </h1>

    <span class="post-date">Jan 10, 2016</span>

    


    

<p>Tmux is awesome. But the session management commands are way too long for my
liking. Listing all sessions is <code>tmux list-sessions</code>, attaching to a session
<code>mysession</code> is <code>tmux attach -t mysession</code>, etc.</p>

<p>So I created a few functions and aliases, which can be found
<a href="https://github.com/rushiagr/myutils/blob/master/aliases/tmux.sh">here</a>.</p>

<p>The general idea is, all commands start with <code>mx</code>, which is basically a
shortcut for &lsquo;tMuX&rsquo;. So <code>mxl</code> is to &lsquo;l&rsquo;ist tmux sessions, <code>mxa</code> is to &lsquo;a&rsquo;ttach
to a tmux session, etc.</p>

<p>List all running tmux sessions</p>

<pre><code>r@rushi:~$ mxl
0: 4 windows (created Sun Jan 10 17:14:11 2016) [89x23] (attached)
</code></pre>

<p>You can see one tmux session. Let&rsquo;s create another tmux session with name
<code>dev</code>.</p>

<pre><code>mx dev
</code></pre>

<p>List all sessions now</p>

<pre><code>r@rushi:~$ mxl
0: 4 windows (created Sun Jan 10 17:14:11 2016) [89x23] (attached)
dev: 1 windows (created Sun Jan 10 17:59:30 2016) [89x23] (attached)
</code></pre>

<p>To attach to session with name <code>dev</code>:</p>

<pre><code>mxa dev
</code></pre>

<p>You can also omit session name, and it will attach to the last session you
attached to.</p>

<p>If there was no session with name <code>dev2</code>, and you type this:</p>

<pre><code>mxa dev2
</code></pre>

<p>It will automatically create a session for you and attach you to it.</p>

<p>To detach:</p>

<pre><code>mxd
</code></pre>

<p>I find this <code>mxd</code> to be easier to type than both <code>CTRL</code>+<code>d</code> and <code>tmux
detach</code>.</p>

<h3 id="installation:e0f68b4969c4b0e373b3bdfb560cffb9">Installation</h3>

<p>You just need to copy the content in the above referenced link to <code>~/.bashrc</code>
file and from a new terminal session things will be ready for you to use :)</p>

  </div>
  
  
  
  <div class="post">
    <h1 class="post-title">
      <a href="http://rushiagr.com/blog/2016/01/02/better-aws-command-line-interface/">
        Better AWS Command Line Interface
      </a>
    </h1>

    <span class="post-date">Jan 2, 2016</span>

    


    

<p>When I first tried to use the AWS CLIs provided by Amazon, I found them not so
human-friendly. Sure, maybe they&rsquo;re good for automating stuff, but if you just
want to view the public IP of a virtual machine, and the CLI throws this on
your screen for just one VM instance, you&rsquo;re likely not going to be impressed:</p>

<pre><code>r@rushi:~$ aws ec2 describe-instances
{
    &quot;Reservations&quot;: [
        {
            &quot;OwnerId&quot;: &quot;123456789012&quot;,
            &quot;ReservationId&quot;: &quot;r-abcd1234&quot;,
            &quot;Groups&quot;: [],
            &quot;Instances&quot;: [
                {
                    &quot;Monitoring&quot;: {
                        &quot;State&quot;: &quot;disabled&quot;
                    },
                    &quot;PublicDnsName&quot;: &quot;ec2-52-52-52-52.ap-southeast-1.compute.amazonaws.com&quot;,
                    &quot;State&quot;: {
                        &quot;Code&quot;: 16,
                        &quot;Name&quot;: &quot;running&quot;
                    },
                    &quot;EbsOptimized&quot;: false,
                    &quot;LaunchTime&quot;: &quot;2015-12-31T12:59:59.000Z&quot;,
                    &quot;PublicIpAddress&quot;: &quot;52.52.52.52&quot;,
                    &quot;PrivateIpAddress&quot;: &quot;172.31.31.31&quot;,
                    &quot;ProductCodes&quot;: [],
                    &quot;VpcId&quot;: &quot;vpc-1234abcd&quot;,
                    &quot;StateTransitionReason&quot;: &quot;&quot;,
                    &quot;InstanceId&quot;: &quot;i-1234abcd&quot;,
                    &quot;ImageId&quot;: &quot;ami-1234abcd&quot;,
                    &quot;PrivateDnsName&quot;: &quot;ip-172-31-31-31.ap-southeast-1.compute.internal&quot;,
                    &quot;KeyName&quot;: &quot;mykey&quot;,
                    &quot;SecurityGroups&quot;: [
                        {
                            &quot;GroupName&quot;: &quot;rushi-sg&quot;,
                            &quot;GroupId&quot;: &quot;sg-abcd1234&quot;
                        }
                    ],
                    &quot;ClientToken&quot;: &quot;&quot;,
                    &quot;SubnetId&quot;: &quot;subnet-abcd1234&quot;,
                    &quot;InstanceType&quot;: &quot;t2.micro&quot;,
                    &quot;NetworkInterfaces&quot;: [
                        {
                            &quot;Status&quot;: &quot;in-use&quot;,
                            &quot;MacAddress&quot;: &quot;06:f3:82:a1:fb:c5&quot;,
                            &quot;SourceDestCheck&quot;: true,
                            &quot;VpcId&quot;: &quot;vpc-abcd1234&quot;,
                            &quot;Description&quot;: &quot;&quot;,
                            &quot;Association&quot;: {
                                &quot;PublicIp&quot;: &quot;52.52.52.52&quot;,
                                &quot;PublicDnsName&quot;: &quot;ec2-52-52-52-52.ap-southeast-1.compute.amazonaws.com&quot;,
                                &quot;IpOwnerId&quot;: &quot;amazon&quot;
                            },
                            &quot;NetworkInterfaceId&quot;: &quot;eni-abcd1234&quot;,
                            &quot;PrivateIpAddresses&quot;: [
                                {
                                    &quot;PrivateDnsName&quot;: &quot;ip-172-31-31-32.ap-southeast-1.compute.internal&quot;,
                                    &quot;Association&quot;: {
                                        &quot;PublicIp&quot;: &quot;52.52.52.52&quot;,
                                        &quot;PublicDnsName&quot;: &quot;ec2-52-52-52-52.ap-southeast-1.compute.amazonaws.com&quot;,
                                        &quot;IpOwnerId&quot;: &quot;amazon&quot;
                                    },
                                    &quot;Primary&quot;: true,
                                    &quot;PrivateIpAddress&quot;: &quot;172.31.31.31&quot;
                                }
                            ],
                            &quot;PrivateDnsName&quot;: &quot;ip-172-31-31-31.ap-southeast-1.compute.internal&quot;,
                            &quot;Attachment&quot;: {
                                &quot;Status&quot;: &quot;attached&quot;,
                                &quot;DeviceIndex&quot;: 0,
                                &quot;DeleteOnTermination&quot;: true,
                                &quot;AttachmentId&quot;: &quot;eni-attach-abcd1234&quot;,
                                &quot;AttachTime&quot;: &quot;2015-12-31T12:59:59.000Z&quot;
                            },
                            &quot;Groups&quot;: [
                                {
                                    &quot;GroupName&quot;: &quot;mygroup&quot;,
                                    &quot;GroupId&quot;: &quot;sg-abcd1234&quot;
                                }
                            ],
                            &quot;SubnetId&quot;: &quot;subnet-abcd1234&quot;,
                            &quot;OwnerId&quot;: &quot;123456789012&quot;,
                            &quot;PrivateIpAddress&quot;: &quot;172.31.31.31&quot;
                        }
                    ],
                    &quot;SourceDestCheck&quot;: true,
                    &quot;Placement&quot;: {
                        &quot;Tenancy&quot;: &quot;default&quot;,
                        &quot;GroupName&quot;: &quot;&quot;,
                        &quot;AvailabilityZone&quot;: &quot;ap-southeast-1a&quot;
                    },
                    &quot;Hypervisor&quot;: &quot;xen&quot;,
                    &quot;BlockDeviceMappings&quot;: [
                        {
                            &quot;DeviceName&quot;: &quot;/dev/sda1&quot;,
                            &quot;Ebs&quot;: {
                                &quot;Status&quot;: &quot;attached&quot;,
                                &quot;DeleteOnTermination&quot;: true,
                                &quot;VolumeId&quot;: &quot;vol-abcd1234&quot;,
                                &quot;AttachTime&quot;: &quot;2015-12-31T12:59:59.000Z&quot;
                            }
                        }
                    ],
                    &quot;Architecture&quot;: &quot;x86_64&quot;,
                    &quot;RootDeviceType&quot;: &quot;ebs&quot;,
                    &quot;RootDeviceName&quot;: &quot;/dev/sda1&quot;,
                    &quot;VirtualizationType&quot;: &quot;hvm&quot;,
                    &quot;Tags&quot;: [
                        {
                            &quot;Value&quot;: &quot;rushi some VM&quot;,
                            &quot;Key&quot;: &quot;Name&quot;
                        }
                    ],
                    &quot;AmiLaunchIndex&quot;: 0
                }
            ]
        },
    ]
}
</code></pre>

<p>The only things I&rsquo;m interested in, after creating a VM is to see it&rsquo;s public
IP, it&rsquo;s flavor, volume size, and instance name. The JSON output which it
throws on my face makes viewing that basic information much harder.</p>

<p>Fortunately, I am a programmer. So I wrote a simple CLI: <code>lsvm</code>:</p>

<pre><code>r@rushi:~$ lsvm -h
lsvm [-h] [-s] [&lt;name&gt;]
    -h      Prints helptext and exits
    -s      Prints sizes of VM disks in GB, starting with root disk
    &lt;name&gt;  Only prints VM whose name contains '&lt;name&gt;'
</code></pre>

<p>Installing the CLI is simple. Just run this command:</p>

<pre><code>sudo sh -c &quot;$(wget -q https://raw.githubusercontent.com/rushiagr/public/master/scripts/simplest-aws-cli.sh -O -)&quot;
</code></pre>

<p>Ensure that you have internet connection before running this command, and also
make sure that your computer can run <code>pip</code> commands. Keep your access and
secret key handy.</p>

<h3 id="list-all-the-vm-instances:a9c5ded79a164e4b6c02d02a570b1d97">List all the VM instances</h3>

<pre><code>r@rushi:~$ lsvm
    ID              Name           Status   Flavor        IP      Vols
i-abcd1234     rushi dev m/c      running  t2.micro 52.12.123.123  1
i-abcd1233   rushi pkg builder    running  t2.micro 52.12.123.122  1
i-abcd1232 rushi vanilla devstack running  t2.large 54.12.123.121  1
i-abcd1231  rushi dbaas devstack  running m4.xlarge 52.12.123.120  1
</code></pre>

<p>List all VMs whose name contains word &lsquo;devstack&rsquo;</p>

<pre><code>r@rushi:~$ lsvm
    ID              Name           Status   Flavor        IP      Vols
i-abcd1232 rushi vanilla devstack running  t2.large 54.12.123.121  1
i-abcd1231  rushi dbaas devstack  running m4.xlarge 52.12.123.120  1
</code></pre>

<p>Show sizes of volumes of instances:</p>

<pre><code>r@rushi:~$ lsvm  -s
    ID                   Name               Status   Flavor        IP       Vols(GB)
i-abcd1234          rushi dev m/c          running  t2.micro 52.12.123.123    [8]
i-abcd1233        rushi pkg builder        running  t2.micro 52.12.123.122    [8]
i-abcd1232      rushi vanilla devstack     running  t2.large 54.12.123.121    [50]
i-abcd1231       rushi dbaas devstack      running m4.xlarge 52.12.123.120    [50]
</code></pre>

<h3 id="creating-vm-instance:a9c5ded79a164e4b6c02d02a570b1d97">Creating VM instance</h3>

<p>Creating a VM instance is tough too, with AWS CLI, so I made another command
<code>mkvm</code> (installed already with the previous script) which is very intuitive for human use. It asks for information in a
step-by-step manner - exactly the way a human sitting in front of a computer should be
treated with:</p>

<pre><code>r@rushi:~$ mkvm
Only Ubuntu image supported as of now
Available flavors: ['t1.micro', 'm1.small', 'm1.medium', 'm1.large', 'm1.xlarge', 'm3.medium', 'm3.large', 'm3.xlarge', 'm3.2xlarge', 'm4.large', 'm4.xlarge', 'm4.2xlarge', 'm4.4xlarge', 'm4.10xlarge', 't2.micro', 't2.small', 't2.medium', 't2.large', 'm2.xlarge', 'm2.2xlarge', 'm2.4xlarge', 'cr1.8xlarge', 'i2.xlarge', 'i2.2xlarge', 'i2.4xlarge', 'i2.8xlarge', 'hi1.4xlarge', 'hs1.8xlarge', 'c1.medium', 'c1.xlarge', 'c3.large', 'c3.xlarge', 'c3.2xlarge', 'c3.4xlarge', 'c3.8xlarge', 'c4.large', 'c4.xlarge', 'c4.2xlarge', 'c4.4xlarge', 'c4.8xlarge', 'cc1.4xlarge', 'cc2.8xlarge', 'g2.2xlarge', 'cg1.4xlarge', 'r3.large', 'r3.xlarge', 'r3.2xlarge', 'r3.4xlarge', 'r3.8xlarge', 'd2.xlarge', 'd2.2xlarge', 'd2.4xlarge', 'd2.8xlarge']
Select flavor ['l' to list]: t2.micro
Available key pairs: ['rushi-kp-1', 'prod-keypair', 'test-keypair']
Select keypair: rushi-kp-1
Available security groups: ['Rushi SecGroup', 'openToAll', 'Rushi SG', 'Rushi Devstack SG']
Select security group. None to create new one: Rushi SecGroup
Enter root volume size in GBs: 8
r@rushi:~$
</code></pre>

<h3 id="ending-notes:a9c5ded79a164e4b6c02d02a570b1d97">Ending notes</h3>

<p>The AWS CLI was created maybe to help automation, but they&rsquo;re not quite
suitable for human use. Here is my attempt to show to the world how the things
could be made easier for human consumption. I use these commands quite a lot
when I want to quickly create a VM, or want to get information about already
created VMs. Logging in into the console is way too slow for my liking.</p>

<p>Just to recap:</p>

<ol>
<li>The commands are shorter, so you have to type less</li>
<li>The output is concise - only important information is included</li>
<li><code>mkvm</code> provides you with information which you&rsquo;ll require while creating the
instances, e.g. security group names, etc.</li>
<li>Nowhere do you need to specify (hexadecimal) IDs while creating VMs</li>
</ol>

<p>I just spent a few hours over the weekend to get this working. So obviously
the code is going to have rough edges, frowned-upon software practices, and a
lot of unhandled edge cases. I&rsquo;ll be pretty excited if you want to help wit
the idea! I&rsquo;ve created a repository at
<a href="http://github.com/rushiagr/aclih">http://github.com/rushiagr/aclih</a> where
please feel free to submit pull requests or issues. Interested in writing
&lsquo;rmvm&rsquo; to delete VM anyone? :)</p>

<p>Thank you :)</p>

  </div>
  
  
  
  <div class="post">
    <h1 class="post-title">
      <a href="http://rushiagr.com/blog/2016/01/02/build-vm-image-using-diskimage-builder/">
        Build VM Images using Diskimage-builder
      </a>
    </h1>

    <span class="post-date">Jan 2, 2016</span>

    


    <p>OpenStack has this nice tool <a href="https://github.com/openstack/diskimage-builder">diskimage-builder</a>to create virtual machine images without the need
of a cloud. These vm images can then be uploaded to cloud (e.g. in Glance for
OpenStack cloud), and they become immediately usable. You can also create VMs in
virtualbox from these images (though I don&rsquo;t remember exact steps to make the
image work with VirtualBox. Do let me know if you get the VM working with
VirtualBox/Vagrant)</p>

<p>Here I&rsquo;ll describe ways to create a bare cloud-uploadable Ubuntu image. I will
also provide information as to how to build an image which will have some
packages pre-installed in them. Note that the commands here will create only
one image file as opposed to three &ndash; one each for ramdisk, kernel and machine image.</p>

<p>Prerequisites</p>

<pre><code>sudo apt-get install qemu-utils
git clone http://github.com/openstack/diskimage-builder
cd diskimage-builder
sudo pip install -r requirements.txt
</code></pre>

<p>All the binaries are in bin filder. You can go in the <code>bin\</code> directory to
execute diskimage-builder commands, or add that directory to your <code>$PATH</code></p>

<p>Create bare Ubuntu image, which you can directly upload to a cloud e.g.
OpenStack.</p>

<pre><code>disk-image-create -a amd64 -o ubuntu-amd64 vm ubuntu
</code></pre>

<p>Image generated will be of name <code>ubuntu-amd64.qcow2</code>. Such an image will be for
same OS version as your host Ubuntu version. If you want
to build an image against a different OS version, specify
<code>DIB_RELEASE=&lt;releasename&gt;</code> as a prefix to the command.</p>

<pre><code>DIB_RELEASE=trusty disk-image-create -a amd64 -o ubuntu-amd64 vm ubuntu
</code></pre>

<p>Create an Ubuntu VM image which you can boot via KVM or VirtualBox/Vagrant.
You will need to manually
add public keys to authorized_keys for a user inside that VM.</p>

<pre><code>disk-image-create -o base -a amd64 vm base ubuntu cloud-init-nocloud
</code></pre>

<p>Create an image with <code>mysql-server</code> and <code>tmux</code> package (and their dependencies) installed inside the image:</p>

<pre><code>disk-image-create -a amd64 -o ubuntu-amd64 -p mysql-server,tmux vm ubuntu
</code></pre>

<p>How to upload image to glance:</p>

<pre><code>glance image-create --name dib-ubuntu --disk-format=qcow2 --container-format=bare &lt; img/ubuntu-amd64.qcow2
</code></pre>

<p>Where <code>ubuntu-amd64.qcow2</code> is the image to upload.</p>

<p>Thanks!</p>

  </div>
  
  
  
  <div class="post">
    <h1 class="post-title">
      <a href="http://rushiagr.com/blog/2015/12/12/better-way-to-view-mysql-tables/">
        Better way to view MySQL tables
      </a>
    </h1>

    <span class="post-date">Dec 12, 2015</span>

    


    

<h3 id="the-problem:1a3447b8e3a40d86311532717f0ef6f7">The problem</h3>

<p>You are trying to print a MySQL table with a large number of columns, with
<code>SELECT *</code> command. You type <code>SELECT * FROM mysql.user LIMIT 1</code>, and your terminal
becomes <a href="https://raw.githubusercontent.com/rushiagr/public/master/img/mysql-table-with-many-rows-messy.png">this</a>.
If you wanted to view more than one row, you&rsquo;re in a trouble :)</p>

<h3 id="the-solution:1a3447b8e3a40d86311532717f0ef6f7">The solution</h3>

<p>Run MySQL with this option:</p>

<pre><code>mysql --pager=&quot;less --chop-long-lines --quit-if-one-screen --no-init'
</code></pre>

<p>This will make your table display only the rows it can in the current screen, something like <a href="https://raw.githubusercontent.com/rushiagr/public/master/img/mysql-with-less-pager-neat.png">this</a>. You can
use the arrow keys to move sideways to view the hidden column. Pressing the &lsquo;right&rsquo; arrow key will move half page towards right. Neat, isn&rsquo;t it?</p>

<p>You can create an alias for mysql:</p>

<pre><code># Using shorter version of 'less' flags mentioned above
alias mysql='mysql -SFX'
</code></pre>

<p>You can put the above line in your <code>~/.bashrc</code> file to load this alias
in every new terminal session.</p>

<h3 id="bonus-point-for-vim-users:1a3447b8e3a40d86311532717f0ef6f7">Bonus point for Vim users</h3>

<p><code>less</code> allows using keys <code>j</code> and <code>k</code> for scrolling down and scrolling up. Unfortunately, you cannot directly use keys <code>h</code> and <code>l</code> to move sideways using <code>less</code>. Fortunately, you can map <code>h</code> and <code>l</code> to move left or right, respectively. Here&rsquo;s how to do that:</p>

<p>Create a file <code>.lesskey</code> in your home directory, with the following contents</p>

<pre><code>l noaction 10\e)
h noaction 10\e)
</code></pre>

<p>Now run this command, to generate <code>~/.less</code> file.</p>

<pre><code>lesskey
</code></pre>

<p>This will generate a binary file which <code>less</code> understands. If you now start a new MySQL terminal session (of course with the above said <code>--pages</code> flag), you can use Vim&rsquo;s <code>HJKL</code> movements. Here I have specified to move 10 characters to the right if you make one &lsquo;right&rsquo; Vim movement.</p>

<h3 id="quick-setup-script:1a3447b8e3a40d86311532717f0ef6f7">Quick setup script</h3>

<p>Don&rsquo;t want to do the above stuff manually? Just run this command and your computer will be set up in a second!</p>

<pre><code>sh -c &quot;$(wget -q https://raw.githubusercontent.com/rushiagr/public/master/scripts/mysql-pretty-table.sh -O -)&quot;
</code></pre>

<p>Note that changes will take effect from a new shell session (or you can run <code>source ~/.bashrc</code> if you want things to work in the current session too.</p>

<h3 id="more-information:1a3447b8e3a40d86311532717f0ef6f7">More information</h3>

<p>Find more information at below links:</p>

<p><a href="http://unix.stackexchange.com/a/169969/91602">About mapping &lsquo;h&rsquo; and &lsquo;k&rsquo; to Vim movements in &lsquo;less&rsquo;</a></p>

<p><a href="http://stackoverflow.com/a/6422698/1143173">About using &lsquo;less&rsquo; as MySQL pager</a></p>

<p>Cheers!</p>

  </div>
  
  
  
  <div class="post">
    <h1 class="post-title">
      <a href="http://rushiagr.com/blog/2015/09/14/quick-justdial-scraper/">
        Quick JustDial scraper
      </a>
    </h1>

    <span class="post-date">Sep 14, 2015</span>

    


    <p>So my friend asked me to scrape data from JustDial and give it to him in an excel sheet.
I thought let&rsquo;s give it a try. He needed
name of firm, address and phone number of any JustDial URL he wants to scrape. After effectively
around 4 hours of work, the below script was created.</p>

<p>Note that the script is dirty. You need to edit the jd_url to search any other URL. Also,
the looping will go on forever, so you have to keep checking the file size of generated
&lsquo;data.csv&rsquo; file, and when you&rsquo;re sure it&rsquo;s not increasing any more, kill the script by
pressing CTRL+C. This script works as of today. Tomorrow it might not. Also, excuse
stray comments/bad formatting of code. I&rsquo;m not sure I want to clean it right now :)</p>

<p>Feel free to use/modify it the way you want.</p>

<pre><code># PIP requirements: requests, beautifulsoup4
import requests
from bs4 import BeautifulSoup
import json
import csv

jd_url = &quot;http://www.justdial.com/Bangalore/Car-Hire-%3Cnear%3E-Shanthinagar&quot;

# Split http/https prefix if any
# TODO: work on URLs which dont' have the CT part in URL
jd_url = jd_url.split('http://www.justdial.com/')[-1].split('https://www.justdial.com/')[-1]
city, search, cat_id = '', '', ''
split_vals = jd_url.split('/')
if len(split_vals) == 3:
    city, search, cat_id = jd_url.split('/')
    cat_id = cat_id.split('-')[-1]
elif len(split_vals) == 2:
    city, search = jd_url.split('/')
search = search.replace('-', '+')


with open('data.csv', 'w') as f:
    #writer = csv.writer(f, delimiter=',', quoting=csv.QUOTE_ALL, lineterminator='\n')

    page = 1
    while True:
        print 'page', page
        resp = requests.get('http://www.justdial.com'+'/functions/ajxsearch.php?national_search=0&amp;act=pagination&amp;city={0}&amp;search={1}&amp;where=&amp;catid={2}&amp;psearch=&amp;prid=&amp;page={3}'.format(city, search, cat_id, page))
        markup = resp.json()['markup'].replace('\/', '/')
        soup = BeautifulSoup(markup, 'html.parser')


        for thing in soup.find_all('section'):
            csv_list = []
            if thing.get('class')==[u'jcar']:
                # Company name
                for a_tag in thing.find_all('a'):
                    if a_tag.get('onclick')==&quot;_ct('clntnm', 'lspg');&quot;:
                        csv_list.append(a_tag.get('title'))

                # Address
                for span_tag in thing.find_all('span'):
                    if span_tag.get('class')==[u'mrehover', u'dn']:
                        csv_list.append(span_tag.get_text().strip())

                # Phone number
                for a_tag in thing.find_all('a'):
                    if a_tag.get('href').startswith('tel:'):
                        csv_list.append(a_tag.get('href').split(':')[-1])


                csv_list = ['&quot;'+item+'&quot;' for item in csv_list]
                writeline = ','.join(csv_list)+'\n'
                f.write(','.join(csv_list)+'\n')
        page+=1
</code></pre>

<p>Cheers!</p>

  </div>
  
  
  
  <div class="post">
    <h1 class="post-title">
      <a href="http://rushiagr.com/blog/2015/09/10/openstack-keystone-with-cassandra-database-in-devstack/">
        OpenStack Keystone with Cassandra Database in DevStack
      </a>
    </h1>

    <span class="post-date">Sep 10, 2015</span>

    


    

<p>Using Cassandra as backing database for OpenStack Keystone was our solution
to multi-region deployment problem of OpenStack cloud. This blog post is not
to discuss the problem. We are talking about how to have a development
environment to play around with Keystone working with a dev Cassandra deployment.</p>

<h4 id="just-run-this-script-and-you-re-all-set:ac993324848a8aead891c139adf0f8b7">&ldquo;Just run this script and you&rsquo;re all set!&rdquo;</h4>

<p>I&rsquo;ve put together all commands into a script which can be found here:</p>

<pre><code>https://raw.githubusercontent.com/rushiagr/keystone-cassandra/master/keystone-cassandra.sh
</code></pre>

<p>If you have a fresh Ubuntu VM, just copy this script into that machine and
execute it. Give it 15-20 mins at least (depending upon your internet connection), and it will set up:</p>

<ol>
<li>DevStack with Keystone installed and running with all the data stored in/fetched from local Cassandra installation</li>
<li>A Cassandra development cluster (CCM) with 5 nodes and replication factor of 3</li>
</ol>

<p>Of course, you will need Internet access inside the VM. Also, give the VM around
3GB of RAM, else things might not work properly. Actually, if you change the
Cassandra configuration to one node instead of 5, probably 2 GB will suffice. But I&rsquo;ve
not tried it. (Let me know if you tried it and it works!)</p>

<p>Notes:</p>

<ol>
<li>Remember, this is a dev cluster. It&rsquo;s not supposed to be used in production. Hell, it&rsquo;s not even ready for it.</li>
<li>Keystone is running on 127.0.0.1. I&rsquo;ve done this so that it will work on any person&rsquo;s VM</li>
<li>I&rsquo;ve tested only on a Ubuntu Trusty VM, on Amazon EC2 m4.large instance which has 8 GB RAM. OpenStack on AWS &ndash; ironic, isn&rsquo;t it? :)</li>
<li>I&rsquo;m using Java which comes with Ubuntu&rsquo;s APT packages. In production one is supposed to use Oracle Java as per Cassandra folks.</li>
<li>The code for this script is located at <code>https://github.com/rushiagr/keystone/tree/liberty-cassandra</code>, i.e. on <code>liberty-cassandra</code> branch. Note that this work is currently based upon Keystone&rsquo;s Liberty code as on first week of June. It might not work directly with latest code as it might require fixing imports which might have become outdated. However, I don&rsquo;t think it&rsquo;s going to take more than an hour to make it work with latest code; just that I don&rsquo;t have enough motivation right now to keep the code updated with &lsquo;latest&rsquo; all the time.</li>
</ol>

<h4 id="credits:ac993324848a8aead891c139adf0f8b7">Credits</h4>

<p>This work was done by the &lsquo;distributed database&rsquo; team of 4 people: Ajaya Agrawal, Rushi Agrawal (me), Vivek Dhayaal and Yogeshwar Shenoy, listed in alphabetical order. And obviously Reliance, for providing us an opportunity to work on this thing.</p>

  </div>
  
  
  
  <div class="post">
    <h1 class="post-title">
      <a href="http://rushiagr.com/blog/2015/07/24/apache-mod_wsgi-parallelization-notes/">
        Apache mod_wsgi parallelization notes
      </a>
    </h1>

    <span class="post-date">Jul 24, 2015</span>

    


    

<p>This is my notes on
<a href="https://code.google.com/p/modwsgi/wiki/ProcessesAndThreading">&lsquo;Processes and Threading&rsquo;</a>
doc by the author of mod_wsgi module of Apache. This blog post just serves as a &lsquo;quick refresher&rsquo;, and
is only useful if you have read the original document but it&rsquo;s been too long since you
read it :)</p>

<h2 id="apache-with-mod-wsgi:d8164b9dd960e232cff9349f39ccb12e">Apache with mod_wsgi</h2>

<p>A Python application can run with multiple processes as well as multiple threads
with mod_wsgi.</p>

<h3 id="prefork-multiprocessing-module:d8164b9dd960e232cff9349f39ccb12e">Prefork multiprocessing module</h3>

<p>Apache creates multiple processes, and each request is handled by one process.
A process only handles one request at a time.
This means, if you have set number of processes to 1, there will be only one
request handeled at a time overall.</p>

<h3 id="worker-multiprocessing-module:d8164b9dd960e232cff9349f39ccb12e">Worker multiprocessing module</h3>

<p>Multiple processes, and multiple threads in each processa.
Even if a process is handling a request, another thread in the same process
can handle one more request.
You might need some synchronization primitive to make sure multiple threads
of same process don&rsquo;t corrupt shared memory (only occurs when shared memory
is mutated)</p>

<h3 id="but-gil:d8164b9dd960e232cff9349f39ccb12e">But GIL?</h3>

<p>Python GIL problem is largely alleviated with mod_wsgi since multiple processes
can handle requests, and GIL has impact ranging to only one process. One more
point to note is that the apache code which maps a URL/request to a wsgi application,
and the code which maps static file URLs to actual static files to serve is
written in C, and is free from GIL.</p>

<p>In the wsgi python code, two environment variables: &lsquo;wsgi.multithread&rsquo; and
&lsquo;wsgi.multiprocess&rsquo; will define which of the above two modules are going to be
used.</p>

  </div>
  
  
  
  <div class="post">
    <h1 class="post-title">
      <a href="http://rushiagr.com/blog/2015/06/07/docker-quick-start-notes/">
        Docker quick start notes
      </a>
    </h1>

    <span class="post-date">Jun 7, 2015</span>

    


    

<p>After reading about docker and containers, I thought let&rsquo;s try them out.
Here are my notes. Obviously all of them are taken from Internet. Maybe this
collection here will help someone start with docker faster than spending time
searching all over the internet.</p>

<p>It assumes your base OS is Ubuntu 14.04 Trusty Tahr (when was the last time
you saw the codename spelled &lsquo;Trusty Tahr&rsquo; and not &lsquo;Trusty&rsquo;? :) ).</p>

<p>Install docker</p>

<pre><code>sudo apt-get install docker.io
</code></pre>

<p>See docker version</p>

<pre><code>sudo docker version
</code></pre>

<p>Pull an Ubuntu Trusty docker image</p>

<pre><code>sudo docker pull ubuntu:14.04
</code></pre>

<p>Alternatively, you can search for a docker image &lsquo;tutorial&rsquo; in docker&rsquo;s repository</p>

<pre><code>sudo docker search tutorial
</code></pre>

<p>And them pull a docker image &lsquo;tutorial&rsquo; by user &lsquo;learn&rsquo;</p>

<pre><code>sudo docker pull learn/tutorial
</code></pre>

<p>List all docker images present in the system</p>

<pre><code>sudo docker images
</code></pre>

<p>Run a docker image, and execute command &lsquo;echo &ldquo;hello world&rdquo;&rsquo; in the docker
container created out of that image</p>

<pre><code>sudo docker run ubuntu:14.04 echo &quot;hello world&quot;
</code></pre>

<p>Container information is stored in /var/lib/docker</p>

<p>If you run the above command multiple times, it will create a new container
each time.</p>

<p>To know the ID of the last container, run</p>

<pre><code>sudo docker ps -l
</code></pre>

<p>To list all the running containers</p>

<pre><code>sudo docker ps
</code></pre>

<p>Note that the above command will not show the container we last run, because
the container which we ran last time terminated just after it finished
executing echo command.</p>

<p>Create a new docker image by name <code>&lt;yourname&gt;/echo</code> by &lsquo;committing&rsquo; the last
container which you ran</p>

<pre><code>sudo docker commit &lt;container ID&gt; &lt;yourname&gt;/echo
</code></pre>

<p>Now running <code>sudo docker images</code> will list you two containers instead of one</p>

<p>Now you can run this new docker container like this:</p>

<pre><code>sudo docker run &lt;yourname&gt;/echo ls -alrth
</code></pre>

<p>If we installed something, or created a file in the old container, it will
be visible now in this container too.</p>

<p>Get more information about a docker image or a running container:</p>

<pre><code>sudo docker inspect &lt;yourname&gt;/echo
</code></pre>

<p>To push docker image to docker repository</p>

<pre><code>sudo docker push &lt;yourname&gt;/echo
</code></pre>

<p>To download ubuntu Trusty base image if not present locally, and open a shell session into it</p>

<pre><code>sudo docker run -t -i ubuntu:14.04 /bin/bash
</code></pre>

<p>-i i.e. &ndash;interactive=false, keeps STDIN open even if not attached</p>

<p>-t i.e. &ndash;tty=false allocates a pseudo tty</p>

<p>Don&rsquo;t worry what these mean. If you add these options, you&rsquo;ll see that
you already get logged in into the container shell, and the container
only dies off once you exit from that session (usually by writing <code>exit</code>
or pressing CTRL + D.</p>

<p>To remove an image:</p>

<pre><code>sudo docker rmi learn/tutorial
</code></pre>

<h4 id="things-not-covered-in-this-tutorial:49285dca7b53d383ade641738736c634">Things not covered in this tutorial:</h4>

<ol>
<li>Create your own custom docker images and share with other people:
<a href="https://docs.docker.com/userguide/dockerimages/">https://docs.docker.com/userguide/dockerimages/</a></li>
</ol>

<p>Cheers!</p>

  </div>
  
  
  
  <div class="post">
    <h1 class="post-title">
      <a href="http://rushiagr.com/blog/2015/06/05/cache-apt-packages-with-squid-proxy/">
        Cache APT packages with Squid proxy
      </a>
    </h1>

    <span class="post-date">Jun 5, 2015</span>

    


    

<p>TL;DR: Know how to install and set up Squid proxy, so that you can cache packages,
and hence save bandwidth if you want to install those packages again and again.
Also works if you are already behind a squid proxy.</p>

<h2 id="problem-repetitive-download-slow:4536ae7fffd586a321b78960b2283427">Problem: Repetitive download. Slow.</h2>

<p>If you deal with virtual machines a lot, you might know the pain of
managing packages on each one of them. Every time I had to create a new VM,
I would run <code>apt-get update</code> (to get information about all the latest packages
available for my Ubuntu system), <code>apt-get dist-upgrade</code> (to install latest
versions of all packages already installed), and also install some packages
not present in stock Ubuntu image, like <code>git</code> (yes, it&rsquo;s 2015
and Ubuntu still doesn&rsquo;t come pre-installed with <code>git</code>), <code>ipython</code>, <code>bwm-ng</code>
and some others. This would mean I&rsquo;m downloading the same file over the network
over and over again. Now there are two ways to deal with this situation</p>

<h2 id="solution-1-local-ubuntu-mirror-super-fast-but-unweildy:4536ae7fffd586a321b78960b2283427">Solution 1: Local Ubuntu mirror - Super fast but unweildy</h2>

<p>The first solution is to download a complete Ubuntu mirror to your computer.
That is, download ALL Ubuntu packages to your system, and then it is super fast.
The first download will be close to 80GBs though. It would have been fine for
me to download 80GBs, but you&rsquo;ll realize the problem when you want to update
this mirror. If you are trying to update the local mirror every week or so,
each time it will ask you to download around 5GB of data. And that unfortunately
is too much for me to download every few days.</p>

<h2 id="solution-2-cache-with-squid-proxy-just-about-perfect:4536ae7fffd586a321b78960b2283427">Solution 2: Cache with Squid proxy - Just about perfect</h2>

<p>The other alternative is use a local cache, using Squid proxy. It works like
just another cache: if you want a package of a specific version, Squid will connect
over the internet to find more details about that file. Once it gets these details,
it checks if a file (package) matching those details is already present in the local
cache. If it is locally present, it just sends this local copy to the requester.
So the total Internet bandwidth utilised is only to get the file details, which
is miniscule (Bytes) compared to downloading the whole package (MBs)j. If the
details doesn&rsquo;t match any locally cached packages, the proxy fetches that package
from internet and responds to the requester.</p>

<h2 id="practical:4536ae7fffd586a321b78960b2283427">Practical!</h2>

<p>Enough of theory, let&rsquo;s put theory to some practice :)</p>

<p>All of the commands below are run on Ubuntu 14.04 (Trusty).</p>

<p>Install Squid proxy package.</p>

<pre><code>sudo apt-get install squid
</code></pre>

<p>Configure: replace <code>/etc/squid3/squid.conf</code> and make it contain these lines.
You will need root permissions to edit this file</p>

<pre><code>acl localhost src 127.0.0.1/32 ::1
acl to_localhost dst 127.0.0.0/8 0.0.0.0/32 ::1
acl localnet src 10.0.0.0/8 # RFC1918 possible internal network
acl localnet src 172.16.0.0/12  # RFC1918 possible internal network
acl localnet src 192.168.0.0/16 # RFC1918 possible internal network
acl SSL_ports port 443
acl Safe_ports port 80      # http
acl Safe_ports port 21      # ftp
acl Safe_ports port 443     # https
acl Safe_ports port 70      # gopher
acl Safe_ports port 210     # wais
acl Safe_ports port 1025-65535  # unregistered ports
acl Safe_ports port 280     # http-mgmt
acl Safe_ports port 488     # gss-http
acl Safe_ports port 591     # filemaker
acl Safe_ports port 777     # multiling http
acl CONNECT method CONNECT
http_access allow manager localhost
http_access deny manager
http_access deny !Safe_ports
http_access deny CONNECT !SSL_ports
http_access allow localnet
http_access allow localhost
http_access deny all
http_port 3128
maximum_object_size 1024 MB
cache_dir aufs /var/spool/squid3 5000 24 256
coredump_dir /var/spool/squid3
refresh_pattern ^ftp:       1440    20% 10080
refresh_pattern ^gopher:    1440    0%  1440
refresh_pattern -i (/cgi-bin/|\?) 0 0%  0
refresh_pattern (Release|Packages(.gz)*)$      0       20%     2880
refresh_pattern .       0   20% 4320
refresh_all_ims on
</code></pre>

<p>You don&rsquo;t need to know or remember what is happening here right now. Just copy
and paste :)</p>

<p>Restart the service:</p>

<pre><code>sudo service squid3 restart
</code></pre>

<p>Now squid service is running, and listening on port 3128. You can use any IP
of your base system which is accessible from your VMs to get packages
via this cache. I give my base system an IP of <code>192.168.100.1</code>, so I just
need to do:</p>

<pre><code>export http_proxy=http://192.168.100.1:3128/
</code></pre>

<p>to source the proxy environment variable, which we&rsquo;ll use to point the APT system
to, to fetch packages from. To test if you proxy is working fine locally,
you can provide <code>127.0.0.1</code>, your localhost IP instead.</p>

<p>And after that can start using the cache to download packages by just passing <code>-E</code>
option to the <code>sudo</code> command</p>

<pre><code>sudo -E apt-get install &lt;your package&gt;
</code></pre>

<p>Sure there are alternative ways of using the proxy, but this is my favourite!</p>

<h2 id="i-m-already-behind-a-proxy:4536ae7fffd586a321b78960b2283427">I&rsquo;m already behind a proxy!</h2>

<p>Worry not, add these lines to <code>squid.conf</code>, restart squid and you&rsquo;re all set for using the
brand new proxy instead of the old one :)</p>

<pre><code>cache_peer 10.135.121.138 parent 3128 0 no-query no-digest
never_direct allow all
</code></pre>

<h2 id="ending-thoughts:4536ae7fffd586a321b78960b2283427">Ending thoughts</h2>

<p>You can go to <code>/var/spool/squid3</code> and run a <code>du -sch</code> to see the total size
of cached files. I find it easy sometimes to calculate the total size of
files this directory holds, to make sure the proxy is working correctly &ndash;
if you can &lsquo;new&rsquo; packages being downloaded, but the size of this directory
is not increasing, they&rsquo;re not coming via this proxy, and you need to figure
out why :)</p>

<p>One more important thing I should tell is that the configuration file
we&rsquo;ve used not only caches APT packages, but also any static files
hosted anywhere on the internet. So if let&rsquo;s say you want to download an
Ubuntu ISO or some other ISO multiple times in your setup (say, inside VMs),
you can cache the ISO file as well with our current setup.</p>

<p>Tell me what is the size your <code>/var/spool/squid3/</code> directory has
reached. Mine is at 1GB right now after a year of it&rsquo;s usage.</p>

<p>Cheers!</p>

<p>-Rushi</p>

  </div>
  
  
  
  
  
  
  
  <div class="post">
    <h1 class="post-title">
      <a href="http://rushiagr.com/blog/2014/11/09/plight-of-online-banking-in-india/">
        Plight of Online Banking in India
      </a>
    </h1>

    <span class="post-date">Nov 9, 2014</span>

    


    

<p>So India is moving ahead. Industry is growing, common facilities are improving,
conditions for living are improving (or so it seems from a middle class guy&rsquo;s
eyes). Banks are becoming more accessible, and easier to use. All banks now
have online banking facility, and makes it less of a hassle to transact - now
you can sit at home and pay your bills, buy things, transfer money to friends
or parents, etc. But, after using online banking for about 4 years, I feel
there is a lot still to be achieved. I find it&rsquo;s not &lsquo;very very&rsquo; convenient.
Online banking experience can be made much much better by fixing these issues.
Below I&rsquo;m writing about my experiences with some of the Indian banks I&rsquo;ve done
online banking with.</p>

<h2 id="state-bank-of-india:8e2dd647e7d0560715f28db5fe7e69c3">State Bank of India</h2>

<p>Hands down India&rsquo;s largest bank. But the user interface of the online website
haven&rsquo;t changed much in the last 4 years I&rsquo;ve seen. There are quite a few
problems with the way the site behaves.</p>

<h4 id="immediate-transfer:8e2dd647e7d0560715f28db5fe7e69c3">Immediate transfer</h4>

<p>The rules of beneficiary addition, and
money transfer are outdated. You can&rsquo;t transfer any amount within the first 24
hours of beneficiary addition. It&rsquo;s Painful that you cannot add a
beneficiary immediately. Beneficiary addition and approval can take upto 24
hours, and I&rsquo;ve seen it taking 4+ hours all the time. If you want to transfer
money immediately, you&rsquo;re out of luck!</p>

<h4 id="imps-is-not-really-immediate:8e2dd647e7d0560715f28db5fe7e69c3">IMPS is not really &lsquo;Immediate&rsquo;</h4>

<p>IMPS was introduced as a faster &lsquo;NEFT&rsquo; &ndash; to work around the limitation that
NEFT transfer cannot be done outside bank working hours, so that you can
transact round the clock. Frustratingly, SBI&rsquo;s IMPS works only till 8PM. You
cannot transfer money after 8PM!</p>

<p>If that was not all, beneficiary addition is separate for NEFT and IMPS. So you
have to add your friend/relative&rsquo;s account number &lsquo;twice&rsquo; to be able to do both
types of transactions.</p>

<p>Also, you need to remember two passwords - one your online banking password,
and another, the &lsquo;profile&rsquo; password, where you can change your profile
settings. I don&rsquo;t know who came up with this idea of two passwords (both
requiring a special character, and a capital, and a digit, sigh) thinking it
might &lsquo;enhance&rsquo; security. Who cares about users anyway, right?</p>

<h2 id="icici:8e2dd647e7d0560715f28db5fe7e69c3">ICICI</h2>

<p>This bank recently completely refurbished its UI, and it&rsquo;s pretty good compared
to the old one. I was pretty impressed that a bank is really putting efforts
into improving the user experience, and not just introducing online banking
because all have it, and just be done with it. Only problem is, it thinks I&rsquo;m
dumb, and wants to force it&rsquo;s own unreasonable &lsquo;secure&rsquo; policies on me.</p>

<p>ICICI debit card has alphabet-digit combinations at the back. For example
A=23,B=01,C=81 upto P=44. Every time you have to do an online transaction, you
need to possess near you 1. Your mobile phone (where it will send an OTP (one
time password), and 2. Your debit card, so that you can enter digits for any
three randomly selected alphabets. I&rsquo;m not sure how the second part increases
security. The bank stops asking OTP once it knows that some specific IP is your
home computer, but still, the debit card alphabet thingy is mandatory. And you
know, there is NO option whatsoever to change this behavior.</p>

<p>There have been two cases when I needed to urgently transfer some amount, but the
poor OTP SMS got stuck somewhere on their servers and didn&rsquo;t reach me for the
whole freaking day.</p>

<h2 id="citibank:8e2dd647e7d0560715f28db5fe7e69c3">CitiBank</h2>

<p>For a couple of months, funnily, their site was not working on any browser except
Internet Explorer. Also, this bank also takes security too seriously. It
doesn&rsquo;t show you all the digits of your bank account (e.g. 1234xxxxxx9), and
does the same with all the account numbers of beneficiaries you added. So once
you add your friend as a beneficiary to this bank, and later you want to add
him/her to another bank, you cannot see his/her account number here by any
possible way. You need to ask him/her again his bank details, or store it
somewhere in your notepad, physical or virtual.</p>

<h2 id="common-problem:8e2dd647e7d0560715f28db5fe7e69c3">Common problem</h2>

<p>All of this don&rsquo;t frustrate me enough. What makes me really furious is
these banks have a habit of not sending an SMS when they debit my account for
maintenance charges or a default. Every other transaction, be it a 10 Rupee
mobile recharge, is accompanied with an SMS. Except when it&rsquo;s them who are
deducting the amount. SBI does it for annual debit card charges, Citibank
deducted 300 Rupees each month, for 4 months, when my account stopped
receiving any salary, without my attention. Turned out they changed my account
from &lsquo;suvidha&rsquo; to &lsquo;basic&rsquo; without my knowledge. And ICICI did that with me too,
debiting annual maintenance fee for the trading account, without a hint of me
noticing. Do they want me to keep checking the online transaction history once
in a while to catch my mistakes?</p>

<p>I consider this practice as ugly way of treating customers, and very very unfair, and should be stopped if the banks
have any moral sense left in them. Perhaps I&rsquo;ll some day use consumer forum (or
will I need to file a PIL maybe?)
to stop this fooling of common people by
these banks. For today, I have an excuse that I don&rsquo;t have enough time.</p>

<p>I am sure these are not the only banks which are below par in customer
satisfaction. India has always had this culture that you need to be just as
good as your competitors. If they are exploiting, you too can exploit upto the
same extent. These banks too don&rsquo;t seem to bother much about user satisfaction.
They are just trying to be as good as their competitors. They don&rsquo;t see this
that if they provide superior services than their rivals, a guy will never ever
leave them and won&rsquo;t think of opening another bank account in his life.</p>

<p>Comments welcome!</p>

<p>Cheers!</p>

<p>-Rushi</p>

  </div>
  
  
  
  <div class="post">
    <h1 class="post-title">
      <a href="http://rushiagr.com/blog/2014/09/14/puppet-installation-from-modules/">
        Puppet installation from modules
      </a>
    </h1>

    <span class="post-date">Sep 14, 2014</span>

    


    <p>A quick example of how to use Puppet to install and manage MySQL. We&rsquo;ll
download required Puppet modules from their git repositories.</p>

<p>Again, everything is tried on Ubuntu (14.04).</p>

<p>Make sure <code>hostname -f</code> shows your FQDN. Then install puppet</p>

<pre><code>sudo apt-get install puppet
</code></pre>

<p>We&rsquo;ll use <code>git submodules</code> to manage different git repositories. But first,
create our own repository</p>

<pre><code>mkdir puppet-mysql
cd puppet-mysql
git init
</code></pre>

<p>Install Puppet modules <code>stdlib</code> and <code>mysql</code> into directory <code>modules</code> as git
submodules.</p>

<pre><code>git submodule add https://github.com/puppetlabs/puppetlabs-stdlib.git modules/stdlib
git submodule add https://github.com/puppetlabs/puppetlabs-mysql.git modules/mysql
</code></pre>

<p>Now create a site.pp file in the root directory of this repository, with the following contents</p>

<pre><code>node default {
    class { 'mysql::server':
        root_password =&gt; 'nova'
    }
}
</code></pre>

<p>Now we&rsquo;ll apply this <code>site.pp</code> file to the system. As our modules directory is
different from Puppet&rsquo;s default, we&rsquo;ll need to specify that while running
Puppet.</p>

<pre><code>sudo puppet apply site.pp --modulepath modules/
</code></pre>

<p>To see the action in more detail, also pass the <code>--debug</code> option to the above
execution</p>

<p>And you&rsquo;re all set.</p>

<p>Now from your commandline, you can try to access mysql and it will work!</p>

<pre><code>mysql -uroot -pnova
</code></pre>

<p>Done! Cheers!</p>

  </div>
  
  
  
  <div class="post">
    <h1 class="post-title">
      <a href="http://rushiagr.com/blog/2014/09/05/openstack-unit-testing-nuggets/">
        OpenStack Unit Testing Nuggets
      </a>
    </h1>

    <span class="post-date">Sep 5, 2014</span>

    


    

<p>A small post about little things I found out while running unit tests in
OpenStack.</p>

<h2 id="unit-testing-setup:ef0fed5d80bf1672d3195cb4c6973c84">Unit-testing setup</h2>

<p>Everybody knows <code>./run_tests.sh</code> is used to run the unit tests of an OpenStack
project. But, you require to install dependencies before doing it. And
installing dependencies might not always succeed. So make sure you install
these packages before running <code>pip install -r requirements.txt</code>:</p>

<pre><code>sudo apt-get install build-essential libssl-dev libffi-dev \
    python-dev libxslt1-dev libpq-dev python-mysqldb \
    libmysqlclient-dev libvirt-dev
</code></pre>

<p>Atleast <code>cinder</code> and <code>nova</code> dependencies will get installed properly after
this.</p>

<h2 id="run-tests-frequently-used-commands:ef0fed5d80bf1672d3195cb4c6973c84">run_tests frequently used commands</h2>

<p>To force the tests to NOT run in a virtual environment, even if it is present:</p>

<pre><code>./run_tests.sh -N
</code></pre>

<p>Force a clean rebuild of virtual environment</p>

<pre><code>./run_tests.sh -f
</code></pre>

<p>Run only PEP8 checks</p>

<pre><code>./run_tests.sh -p
</code></pre>

<p>Run PEP8 checks only on the files which have been changed since last commit</p>

<pre><code>./run_tests.sh -8
</code></pre>

<p>Run all tests from a specific file only, e.g. nova/tests/test_utils.py</p>

<pre><code>./run_tests.sh nova.tests.test_utils
</code></pre>

<p>Run all tests of only a specific class inside a test file</p>

<pre><code>./run_tests.sh nova.tests.test_utils.ResourceFilterTestCase
</code></pre>

<p>Run only a specific test</p>

<pre><code>./run_tests.sh nova.tests.test_utils.ResourceFilterTestCase.test_resource_filtering
</code></pre>

<h2 id="wildcards-while-running-the-tests:ef0fed5d80bf1672d3195cb4c6973c84">Wildcards while running the tests</h2>

<p>Frequently you&rsquo;ll find yourself testing only a couple of tests. In such cases,
a wildcard will save you from typing the whole path of the test. The below
command will also run <code>test_resource_filtering</code> test:</p>

<pre><code>./run_tests.sh nova.tests.*resource_filt*
</code></pre>

<p>I currently don&rsquo;t know how to make a test work without adding <code>nova.tests</code>
before it</p>

<h2 id="run-tests-is-not-happy:ef0fed5d80bf1672d3195cb4c6973c84">run_tests is not happy</h2>

<p>Sometimes you&rsquo;ll see running <code>./run_tests.sh</code> can throw a lot of lines of
ununderstandable gibberish on your screen. In the end it will say <code>testr
failed</code>, but it won&rsquo;t give an indication of where it failed and why. I have
seen that this happens due to only one of the following two reasons:</p>

<ol>
<li><p><em>Syntax error</em>: There is a syntax error in your code.</p></li>

<li><p><em>Dependencies outdated</em>: Dependencies in your virtual environment is
outdated. In such cases, you will need to recreate a virtual environment with
latest packages. Or better: just update the virtual environment with the latest
packages using this command:</p>

<p>./run_tests.sh -u</p></li>
</ol>

<p>UPDATE: I&rsquo;ve seen that nowadays it doesn&rsquo;t throw a lot of gibberish, but just
says &lsquo;testr failed&rsquo;, without any error log or stacktrace. This is the same
situation &ndash; can only happen when there is a syntax error, or if the
dependencies are outdated.</p>

<p>That&rsquo;s it for now.</p>

  </div>
  
  
  
  <div class="post">
    <h1 class="post-title">
      <a href="http://rushiagr.com/blog/2014/09/05/iscsi-administration-on-ubuntu-quick-start/">
        iSCSI administration on Ubuntu - Quick Start
      </a>
    </h1>

    <span class="post-date">Sep 5, 2014</span>

    


    

<p>This post get&rsquo;s you started with iSCSI administration on an Ubuntu machine.
Although I have used Ubuntu Trusty (14.04) version, it should work with Precise
(12.04) too, with the latest packages.</p>

<h4 id="prerequisites:929de0ff9dbcd4c871b27335ee5a3706">Prerequisites</h4>

<p>Make sure you have atleast a little idea of what these terms
mean: iSCSI, LUN, IQN, initiator, target and portal. Google and wikipedia are
your friends.</p>

<h4 id="a-quick-summary:929de0ff9dbcd4c871b27335ee5a3706">A quick summary:</h4>

<p>There are two parts of iSCSI communication - initiator and target. So let&rsquo;s take an example. There is a storage server in your
company, where you have a &lsquo;drive&rsquo; for your team. The storage server is the
&lsquo;target&rsquo;, and your laptop, where you&rsquo;ll mount the drive to access it&rsquo;s contents
is the &lsquo;initiator&rsquo;. In other words, target is like a &lsquo;server&rsquo; which stores
data, and allows initiators (think &lsquo;clients&rsquo;) to connect to it.</p>

<p>In this short hands-on introduction, we&rsquo;ll use the same Ubuntu machine as
target as well as initiator. We can use a file as the storage behind the
target, but this post also shows how to use LVM logical volume as the backing
store for the iSCSI target.</p>

<p>Actually, we&rsquo;ll back the logical volume (LV) with a file, as shown in
<a href="http://www.rushiagr.com/blog/2014/01/14/quick-start-linux-logical-volume-manager/">this</a>,
so essentially we&rsquo;re just using &lsquo;file as a backing store for targets&rsquo; but in a
roundabout way :)</p>

<p>OK, let&rsquo;s get started. Make sure you execute all the following commands as root
user.</p>

<p>First install the required dependencies</p>

<pre><code>apt-get install lvm2 tgt open-iscsi
</code></pre>

<h4 id="initialize-logical-volume:929de0ff9dbcd4c871b27335ee5a3706">Initialize logical volume</h4>

<p>Create a file of 1GB, create a volume group over it, and then over it, create a
400MB logical volume, and see if it got created or not</p>

<pre><code>root@ra:~# truncate --size 1G backingfile
root@ra:~# sudo losetup --find --show backingfile 
/dev/loop0
root@ra:~# sudo vgcreate myvg /dev/loop0
  No physical volume label read from /dev/loop0
  Physical volume &quot;/dev/loop0&quot; successfully created
  Volume group &quot;myvg&quot; successfully created
root@ra:~# sudo lvcreate --size 400M --name mylv myvg
  Logical volume &quot;mylv&quot; created
root@ra:~# lvs
  LV   VG   Attr      LSize   Pool Origin Data%  Move Log Copy% Convert
  mylv myvg -wi-a---- 400.00m                                           
</code></pre>

<h4 id="target-administration:929de0ff9dbcd4c871b27335ee5a3706">Target administration</h4>

<p>Now let&rsquo;s create a target, with target ID 1, and give it an IQN (iSCSI
Qualified Name) <code>iqn.2001-04.example.com:your.first.iscsi.target</code>:</p>

<pre><code>tgtadm --lld iscsi --op new --mode target --tid 1 -T iqn.2001-04.example.com:your.first.iscsi.target
</code></pre>

<p>List the target, see it&rsquo;s properties:</p>

<pre><code>root@ra:~# tgtadm --lld iscsi --op show --mode target
Target 1: iqn.2001-04.example.com:your.first.iscsi.target
    System information:
        Driver: iscsi
        State: ready
    I_T nexus information:
    LUN information:
        LUN: 0
            Type: controller
            SCSI ID: IET     00010000
            SCSI SN: beaf10
            Size: 0 MB, Block size: 1
            Online: Yes
            Removable media: No
            Prevent removal: No
            Readonly: No
            SWP: No
            Thin-provisioning: No
            Backing store type: null
            Backing store path: None
            Backing store flags: 
    Account information:
    ACL information:
</code></pre>

<p>You can see there is a LUN, LUN 0 attached to the target. Let&rsquo;s attach our
logical volume <code>mylv</code> as LUN 1 to the target.</p>

<pre><code>tgtadm --lld iscsi --op new --mode logicalunit --tid 1 --lun 1 -b /dev/myvg/mylv
</code></pre>

<p>Here, actually you could&rsquo;ve attached a flat file as a LUN to the target. So you
could&rsquo;ve skipped all the intermediate steps and attached the <code>backingfile</code>
directly to the target like this:</p>

<pre><code>tgtadm --lld iscsi --op new --mode logicalunit --tid 1 --lun 1 -b backingfile
</code></pre>

<p>A backing file would&rsquo;ve been good enough for this demo, but you know the benefits of logical volume isn&rsquo;t it? :)</p>

<p>Okay, let&rsquo;s see if the LUN got created:</p>

<pre><code>root@ra:~# tgtadm --lld iscsi --op show --mode target
Target 1: iqn.2001-04.example.com:your.first.iscsi.target
    System information:
        Driver: iscsi
        State: ready
    I_T nexus information:
    LUN information:
        LUN: 0
            Type: controller
            SCSI ID: IET     00010000
            SCSI SN: beaf10
            Size: 0 MB, Block size: 1
            Online: Yes
            Removable media: No
            Prevent removal: No
            Readonly: No
            SWP: No
            Thin-provisioning: No
            Backing store type: null
            Backing store path: None
            Backing store flags: 
        LUN: 1
            Type: disk
            SCSI ID: IET     00010001
            SCSI SN: beaf11
            Size: 419 MB, Block size: 512
            Online: Yes
            Removable media: No
            Prevent removal: No
            Readonly: No
            SWP: No
            Thin-provisioning: No
            Backing store type: rdwr
            Backing store path: /dev/myvg/mylv
            Backing store flags: 
    Account information:
    ACL information:
</code></pre>

<p>Now let&rsquo;s allow all initiators to bind to this target:</p>

<pre><code>tgtadm --lld iscsi --op bind --mode target --tid 1 -I ALL
</code></pre>

<p>We&rsquo;re done with the &lsquo;target&rsquo; side now. You can check, using <code>netstat</code> that port
3260, the default port, is now open. Note that all our commands so far started with
<code>tgtadm</code>, i.e., the target administration utility.</p>

<h4 id="initiator-administration:929de0ff9dbcd4c871b27335ee5a3706">Initiator administration</h4>

<p>Now let&rsquo;s start from the &lsquo;initiator&rsquo; end. We&rsquo;ll behave as if we&rsquo;re a client
trying to connect to the server &ndash; the target.</p>

<p>Discover all the targets on our local machine (<code>127.0.0.1</code>).</p>

<pre><code>root@ra:~# sudo iscsiadm --mode discovery --type sendtargets --portal 127.0.0.1
127.0.0.1:3260,1 iqn.2001-04.example.com:your.first.iscsi.target
</code></pre>

<p>From the client perspective, we&rsquo;re now able to see a target. Let&rsquo;s login into
that target</p>

<pre><code>root@ra:~# sudo iscsiadm --mode node --targetname iqn.2001-04.example.com:your.first.iscsi.target --portal 127.0.0.1:3260 --login
Logging in to [iface: default, target: iqn.2001-04.example.com:your.first.iscsi.target, portal: 127.0.0.1,3260] (multiple)
Login to [iface: default, target: iqn.2001-04.example.com:your.first.iscsi.target, portal: 127.0.0.1,3260] successful.
</code></pre>

<p>After logging in, the target will be visible in the client&rsquo;s system as a new
device. Running a <code>fdisk -l</code> shows that there is a new device <code>/dev/sda</code> is now
present.</p>

<pre><code>root@ra:~# fdisk -l

Disk /dev/vda: 57.1 GB, 57076908032 bytes
255 heads, 63 sectors/track, 6939 cylinders, total 111478336 sectors
Units = sectors of 1 * 512 = 512 bytes
Sector size (logical/physical): 512 bytes / 512 bytes
I/O size (minimum/optimal): 512 bytes / 512 bytes
Disk identifier: 0x0001cd46

   Device Boot      Start         End      Blocks   Id  System
/dev/vda1   *        2048   106520575    53259264   83  Linux
/dev/vda2       106522622   111476735     2477057    5  Extended
/dev/vda5       106522624   111476735     2477056   82  Linux swap / Solaris

Disk /dev/mapper/myvg-mylv: 419 MB, 419430400 bytes
255 heads, 63 sectors/track, 50 cylinders, total 819200 sectors
Units = sectors of 1 * 512 = 512 bytes
Sector size (logical/physical): 512 bytes / 512 bytes
I/O size (minimum/optimal): 512 bytes / 512 bytes
Disk identifier: 0x00000000

Disk /dev/mapper/myvg-mylv doesn't contain a valid partition table

Disk /dev/sda: 419 MB, 419430400 bytes
13 heads, 62 sectors/track, 1016 cylinders, total 819200 sectors
Units = sectors of 1 * 512 = 512 bytes
Sector size (logical/physical): 512 bytes / 512 bytes
I/O size (minimum/optimal): 512 bytes / 512 bytes
Disk identifier: 0x00000000

Disk /dev/sda doesn't contain a valid partition table
</code></pre>

<p>Now we just need to format this device with a filesystem, say EXT4, and then
mount it at some location to start using it!</p>

<pre><code>root@ra:~# sudo mkfs.ext4 /dev/sda
mke2fs 1.42.9 (4-Feb-2014)
/dev/sda is entire device, not just one partition!
Proceed anyway? (y,n) y
Filesystem label=
OS type: Linux
Block size=1024 (log=0)
Fragment size=1024 (log=0)
Stride=0 blocks, Stripe width=0 blocks
102400 inodes, 409600 blocks
20480 blocks (5.00%) reserved for the super user
First data block=1
Maximum filesystem blocks=67633152
50 block groups
8192 blocks per group, 8192 fragments per group
2048 inodes per group
Superblock backups stored on blocks: 
    8193, 24577, 40961, 57345, 73729, 204801, 221185, 401409

Allocating group tables: done                            
Writing inode tables: done                            
Creating journal (8192 blocks): done
Writing superblocks and filesystem accounting information: done 

root@ra:~# mkdir tempmount
root@ra:~# mount /dev/sda tempmount/
root@ra:~# cd tempmount/
root@ra:~/tempmount# ls
lost+found
root@ra:~/tempmount# 
</code></pre>

<h4 id="destruction:929de0ff9dbcd4c871b27335ee5a3706">Destruction</h4>

<p>The simplest way to get rid of all the things you&rsquo;ve created is to unmount the
device, and restart the system.</p>

<p>Aaand done!</p>

<p>Cheers!</p>

  </div>
  
  
  
  
  
  <div class="post">
    <h1 class="post-title">
      <a href="http://rushiagr.com/blog/2014/08/09/amazon-ec2-api-with-openstack-developer-quick-start/">
        Amazon EC2 API with OpenStack - Developer Quick Start
      </a>
    </h1>

    <span class="post-date">Aug 9, 2014</span>

    


    <p>OpenStack has support for EC2 API, that is, you can fire Amazon&rsquo;s API against an OpenStack cloud and it will still work. This article gets you started with using them locally against DevStack. It is more of a starter guide to a novice.</p>

<p>Fire a DevStack with it&rsquo;s default settings. See <a href="http://www.rushiagr.com/blog/2014/04/03/openstack-in-an-hour-with-devstack">this post</a> for more information on it.</p>

<pre><code>git clone http://github.com/openstack-dev/devstack
cd devstack/
./stack.sh
</code></pre>

<p>Source openrc</p>

<pre><code>source openrc
</code></pre>

<p>View all EC2 credentials available for the current user (here, <code>demo</code> user in <code>demo</code> tenant)</p>

<pre><code>$ keystone ec2-credentials-list
+----------------------------------+----------------------------------+----------------------------------+
|              tenant              |              access              |              secret              |
+----------------------------------+----------------------------------+----------------------------------+
| 0e9f99a6f2064464aa054d305ba08052 | ef61007dae74468eb9593ffbbd22d9f1 | 28c7ad6248de4e6a8649b3e2d122ac5d |
| 9b93a67201264492be3d0998b87d821b | 1b0a617dbef347cb968c8eed160de0b3 | b6525738ad6044ea9c49abeefabf86de |
+----------------------------------+----------------------------------+----------------------------------+
</code></pre>

<p>But which one is my current tenant? Let&rsquo;s get that from parsing the output of <code>token-get</code> command</p>

<pre><code>$ keystone token-get | grep tenant | awk '{print $4}'
0e9f99a6f2064464aa054d305ba08052
</code></pre>

<p>Note the access and secret keys.</p>

<p>Let&rsquo;s get started with the <code>boto</code> client for consuming AWS APIs. I prefer <code>ipython</code> shell, for its interactive features, but normal Python shell is just fine too. (Install ipython as <code>sudo apt-get install ipython</code>).</p>

<p>Import necessary module</p>

<pre><code>&gt;&gt; import boto
</code></pre>

<p>Create a <code>conn</code> connection object, which we&rsquo;ll use for querying our cloud</p>

<pre><code>&gt;&gt; conn = boto.connect_ec2_endpoint('http://10.0.1.126:8773/services/Cloud',
            aws_access_key_id='ef61007dae74468eb9593ffbbd22d9f1',
            aws_secret_access_key='28c7ad6248de4e6a8649b3e2d122ac5d')
</code></pre>

<p>Here <code>10.0.1.126</code> is the IP of my machine. Don&rsquo;t forget to change it to yours.</p>

<p>If everything is successful, call to <code>get_all_instances()</code> will return an empty list</p>

<pre><code>&gt;&gt; conn.get_all_instances()
[]
</code></pre>

<p>Okay, now let&rsquo;s create an instance. List all the images first</p>

<pre><code>In [20]: conn.get_all_images()
Out[20]:
[Image:aki-00000001,
 Image:ari-00000002,
 Image:ami-00000003,
 Image:ami-00000004]
</code></pre>

<p>Image <code>ami-00000003</code> should be the cirros image from which we&rsquo;ll create an instance. But still, let&rsquo;s confirm that</p>

<pre><code>In [26]: img = conn.get_image('ami-00000003')

In [27]: img.name
Out[27]: u'cirros-0.3.2-x86_64-uec'
</code></pre>

<p>Now let&rsquo;s use this image to create an instance. Boto&rsquo;s <code>get_all_instances</code> returns a list of reservations, which makes getting the instance object slightly roundabout.</p>

<pre><code>In [35]: conn.run_instances(image_id='ami-00000003', instance_type='m1.tiny')
Out[35]: Reservation:r-08b8idoz

In [40]: reservations = conn.get_all_instances()

In [42]: resvn = reservations[0]

In [44]: instance = resvn.instances[0]

In [45]: instance.state
Out[45]: u'running'
</code></pre>

<p>And then delete it</p>

<pre><code>In [47]: conn.terminate_instances('i-00000002')
Out[47]: [Instance:i-00000002]

In [50]: conn.get_all_reservations()
Out[50]: []
</code></pre>

<p>That&rsquo;s it for now :)</p>

<p>Use <code>ipython</code> or <code>bpython</code> for exploring boto library more and discover more APIs.</p>

<p>If you want to see what EC2 API was actually called behind the scenes, create a file <code>/etc/boto.cfg</code> and add these two lines. Now whenever you will use an interactive Python terminal, you&rsquo;ll see on your screen the EC2 API being called.</p>

<pre><code>[Boto]
debug=2
</code></pre>

<p>Cheers!</p>

  </div>
  
  
  
  <div class="post">
    <h1 class="post-title">
      <a href="http://rushiagr.com/blog/2014/08/05/devstack-behind-proxy/">
        DevStack behind proxy
      </a>
    </h1>

    <span class="post-date">Aug 5, 2014</span>

    


    <p>I have now seen some people struggling to get DevStack working behind proxy. Some, thinking it is a bug in DevStack, have actually posted patches for it too! Here, I&rsquo;ll tell you the simple way to get <code>stack.sh</code> complete succesfully from behind a proxy.</p>

<p>By default, <code>devstack</code> will clone from the &lsquo;actual&rsquo; OpenStack git repositories, residing at <code>git://git.openstack.org</code>. Some people might face a problem with it, as DevStack uses <code>git</code> protocol to clone the repo. We&rsquo;ll instead use HTTP which is provided by GitHub mirror  (yes, you heard it right. GitHub is just a &lsquo;mirror&rsquo; for OpenStack code, not the primary repository). For this we&rsquo;ll need to set <code>GIT_BASE</code> in <code>localrc</code> as:</p>

<pre><code>GIT_BASE=http://github.com
</code></pre>

<p>Export http and https proxy variables</p>

<pre><code>export http_proxy=&lt;your-http-proxy&gt;
export https_proxy=&lt;your-https-proxy&gt;
</code></pre>

<p>Now, you will need to export <code>no_proxy</code> environment variable. This environment variable should contain localhost, as well as the IP your current machine has got. Say your current machine has IP <code>12.34.56.78</code>:</p>

<pre><code>export no_proxy=127.0.0.1,12.34.56.78
</code></pre>

<p>After you have exported these three variables, you&rsquo;re free to run <code>./stack.sh</code>, and it should finish successfully.</p>

<p>If you are doing a single-node devstack setup, you don&rsquo;t need to do anything
else and can stop here. If you are doing a multi-node setup, the services
running on one node might not communicate properly with services on a different node. In order to
fix this, do this: go to individual services running inside screens, stop the
service (by pressing <code>CTRL</code>+<code>C</code>), unset the proxy environment variables (<code>unset
http_proxy https_proxy no_proxy</code>), and restart the service again (by pressing
up arrow and then pressing <code>Enter</code>).</p>

<p>Cheers!</p>

  </div>
  
  
  
  <div class="post">
    <h1 class="post-title">
      <a href="http://rushiagr.com/blog/2014/08/02/qcow2-mount/">
        Mounting QCOW2 images
      </a>
    </h1>

    <span class="post-date">Aug 2, 2014</span>

    


    <p>Isn&rsquo;t it fun that even before you start a VM out of an image, you can add files to that image, see and edit the directory and file structure of that VM?</p>

<p>I wanted to boot a VM out of a disk-image, but how will I know out of the 256 available IPs for that VM, which one actually got assigned? I tried vnc console, but the connection was terribly flaky. Even so, it was felt quite ugly to use an interface when I was trying to move to a keyboard-only (command line) world.  So I just inserted a static IP into the <code>/etc/network/interfaces</code> file of that image! (I wasn&rsquo;t aware of <code>arp-scan</code> before I discovered the trick described in this post)</p>

<p>We&rsquo;ll mount the image, tweak the filesystem of that image, and then boot the image.</p>

<p>Install <code>qemu-utils</code> and enable <code>ndb</code> module</p>

<pre><code>sudo apt-get install qemu-utils
sudo modprobe nbd
</code></pre>

<p>Use any qcow2 image, and if you don&rsquo;t have any, download a small CirrOS cloud image (around 13MB).</p>

<pre><code>wget http://download.cirros-cloud.net/0.3.2/cirros-0.3.2-x86_64-disk.img
</code></pre>

<p>Connect the image to the first nbd device</p>

<pre><code>sudo qemu-nbd -c /dev/nbd0 cirros-0.3.2-x86_64-disk.img
</code></pre>

<p>Mount the image. For nbd0, see all the devices available (<code>/dev/nbd0&lt;some-number-or-string&gt;</code>) and try attaching to starting from the first one</p>

<pre><code>sudo mount /dev/nbd0p1 /mnt
</code></pre>

<p>Now at /mnt, you can see the complete filesystem of that image, and make necessary changes. You can do all sorts of things &ndash; change <code>sources.list</code>, <code>/etc/network/interfaces</code>, put additional files inside the VM for particular users, etc.</p>

<p>After you&rsquo;re done, unmount it.</p>

<pre><code>sudo umount /mnt
</code></pre>

<p>And disconnect the loopback device too</p>

<pre><code>sudo qemu-nbd -d /dev/nbd0
</code></pre>

<p>Done!</p>

<p>PS: I actually created two functions for mounting and unmounting, so that I don&rsquo;t remember all these commands. Find them <a href="https://github.com/rushiagr/myutils/blob/master/aliases/qcow2-mount.sh">here</a>.</p>

<p>Credits: Vigneshvar introduced me to <code>qemu-nbd</code> tool.</p>

  </div>
  
  
  
  
  
  
  
  <div class="post">
    <h1 class="post-title">
      <a href="http://rushiagr.com/blog/2014/04/12/open-source-puppet-quick-start/">
        Open Source Puppet - Quick Start
      </a>
    </h1>

    <span class="post-date">Apr 12, 2014</span>

    


    

<p>This post aims to be your quickest guide to get started with Puppet. We&rsquo;ll be using the open source version of Puppet. An hour of spare time and two Ubuntu machines (physical or virtual doesn&rsquo;t matter) is all that is needed.</p>

<!-- more -->

<h2 id="quick-introduction:3eb4397264d4b1e9ded54ff4b133eea0">Quick Introduction</h2>

<p>Lets say you want to install and run apache server on one of the machines in your lab. On another, you want to create a new user. On a third machine, you want to install MySQL, and allow access to this machine only from the first server. Seems like a lot of manual work isn&rsquo;t it? The power of Puppet is, you can specify all these tasks in a file, called &lsquo;Puppet manifest&rsquo;, and then execute it. Everything will be set up for you just as you wanted! Now what makes this &lsquo;I care about the end result, not the process&rsquo; approach really powerful is you can &lsquo;apply&rsquo; this manifest over and over again to get the same end result. You can easily modify this manifest file, extend it, and manage it under version control, just like you would with a piece of software. Welcome to the world of IT automation :)</p>

<p>Although the syntax of a Puppet manifest is Ruby-ish, no knowledge of Ruby is required at all (I don&rsquo;t know Ruby).</p>

<p>There is a whole lot of things you can do with Puppet. Here, we&rsquo;ll just get us started with it. Once you are through this post, you can head over to Puppet Labs&rsquo; documents and tutorials, for more on &ldquo;how&rdquo;s and &ldquo;why&rdquo;s of Puppet.</p>

<h2 id="setup:3eb4397264d4b1e9ded54ff4b133eea0">Setup</h2>

<p>You just require two Ubuntu machines connected to each other. One will be the Puppet &lsquo;master&rsquo; node (the machine which will take care of managing the configuration and state of all the machines in our deployment), the other one &lsquo;slave&rsquo; (which unfortunately is the only actual machine in demo deployment :) ).</p>

<p>Here I am using two  virtual machines, but you can create one virtual machine and use your host machine as the other one. The hostnames of the master and slave in my setup are <code>puppet-master</code> and <code>puppet-agent</code>.</p>

<p>Make sure both the machines are ping-able from each other &ndash; by their IP as well as hostnames (e.g. <code>ping 123.123.123.123</code> and <code>ping puppet-master</code>). Make sure your /etc/hosts file looks something like this to achieve that:</p>

<p>(<code>192.168.56.130</code> and <code>192.168.56.131</code> are the IP addresses of externally-visible interfaces of hosts <code>puppet-master</code> and <code>puppet-agent</code> respectively)</p>

<p>Master:</p>

<pre><code>r@puppet-master:~$ cat /etc/hosts
127.0.0.1   localhost
127.0.1.1   puppet-master

192.168.56.131  puppet-agent
</code></pre>

<p>Slave:</p>

<pre><code>r@puppet-agent:~$ cat /etc/hosts
127.0.0.1   localhost
127.0.1.1   puppet-agent

192.168.56.130  puppet-master
</code></pre>

<h2 id="getting-the-hands-dirty-puppet-cli:3eb4397264d4b1e9ded54ff4b133eea0">Getting the hands dirty &ndash; Puppet CLI</h2>

<p>Install <code>puppetmaster</code> package on the master node</p>

<pre><code>sudo apt-get install puppetmaster
</code></pre>

<p>List all the users on the current system:</p>

<pre><code>puppet resource user --list
</code></pre>

<p>So basically a &lsquo;user&rsquo; is a &lsquo;resource&rsquo; in Puppet terminology. Now only list a specific resource. <code>r</code> is the current user in my case.</p>

<pre><code>r@puppet-master:~$ puppet resource user r
user { 'r':
  ensure  =&gt; 'present',
  comment =&gt; 'r,,,',
  gid     =&gt; '1000',
  groups  =&gt; ['adm', 'cdrom', 'sudo', 'dip', 'plugdev', 'lpadmin', 'sambashare'],
  home    =&gt; '/home/r',
  shell   =&gt; '/bin/bash',
  uid     =&gt; '1000',
}
</code></pre>

<p>Notice the syntax. Resource &lsquo;r&rsquo; is of type &lsquo;user&rsquo;, with &lsquo;ensure&rsquo;, &lsquo;comment&rsquo;, etc as keys/attributes, and &lsquo;present&rsquo;, &lsquo;r,,,&rsquo; as values for those attributes.</p>

<p>You can change the value using the Puppet CLI</p>

<pre><code>r@puppet-master:~$ sudo puppet resource user r comment='some text missing'
notice: /User[r]/comment: comment changed 'r,,,' to 'some text missing'
user { 'r':
  ensure  =&gt; 'present',
  comment =&gt; 'some text missing',
}
</code></pre>

<p>Create a new user with specified key-value pairs</p>

<pre><code>r@puppet-master:~$ sudo puppet resource user katie ensure=present shell=/bin/bash
notice: /User[katie]/ensure: created
user { 'katie':
  ensure =&gt; 'present',
  shell  =&gt; '/bin/bash',
}
r@puppet-master:~$ sudo puppet resource user katie 
user { 'katie':
  ensure           =&gt; 'present',
  gid              =&gt; '1001',
  home             =&gt; '/home/katie',
  password         =&gt; '!',
  password_max_age =&gt; '99999',
  password_min_age =&gt; '0',
  shell            =&gt; '/bin/bash',
  uid              =&gt; '1001',
}
</code></pre>

<p>Remove the newly created user, but this time, let&rsquo;s put this information into a file <code>katie_remove.pp</code> and ask Puppet to &lsquo;apply&rsquo; this file and thus removing the user &lsquo;katie&rsquo;.</p>

<pre><code>r@puppet-master:~$ cat katie_remove.pp 
user {'katie':
    ensure =&gt; absent,
}
</code></pre>

<p>Apply this Puppet manifest</p>

<pre><code>r@puppet-master:~$ sudo puppet apply katie_absent.pp 
warning: Could not retrieve fact fqdn
notice: /Stage[main]//User[katie]/ensure: removed
notice: Finished catalog run in 0.47 seconds
</code></pre>

<p>Puppet&rsquo;s description of user &lsquo;katie&rsquo;:</p>

<pre><code>r@puppet-master:~$ sudo puppet resource user katie
  user { 'katie':
  ensure =&gt; 'absent',
}
</code></pre>

<p>is now same as that of a non-existent user.</p>

<pre><code>r@puppet-master:~$ sudo puppet resource user absent-user
  user { 'absent-user':
  ensure =&gt; 'absent',
}
</code></pre>

<p>That is, the user &lsquo;katie&rsquo; is now deleted. You can see that the &lsquo;ensure&rsquo; attribute can be used to make sure a user (or in general, any &lsquo;resource&rsquo;, is present, or absent).</p>

<p><strong>Note</strong>: Ignore the warning which is printed while applying a manifest from a file. Or if you are bothered by it popping up all the time, in the <code>/etc/hosts</code> file, change</p>

<pre><code>127.0.1.1   puppet-master
</code></pre>

<p>to</p>

<pre><code>127.0.1.1   puppet-master.rushiagr.com puppet-master
</code></pre>

<p>where you can choose a domain name of your own choice in place of <code>.rushiagr.com</code>.</p>

<h2 id="puppet-modules:3eb4397264d4b1e9ded54ff4b133eea0">Puppet modules</h2>

<p><strong>Note:</strong> <code>puppet module</code> doesn&rsquo;t work on Precise (Ubuntu 12.04). You need to install ruby, and gems, etc. Too much of a hassle. So I&rsquo;ll just post commands here which work for a higher version of Ubuntu.</p>

<p>Install standard library:</p>

<pre><code>sudo puppet module install puppetlabs/stdlib
</code></pre>

<p>View all the installed modules</p>

<pre><code>r@puppet-master:~$ sudo puppet module list
/etc/puppet/modules
 puppetlabs-mysql (v2.2.1)
 puppetlabs-ntp (v3.0.2)
 puppetlabs-stdlib (v4.1.0)
/usr/share/puppet/modules (no modules installed)
</code></pre>

<p>All the modules, and all other information in the system goes in <code>/etc/puppet</code> directory.</p>

<p><strong>Note</strong>: Modules installed via <code>sudo</code> will be visible when you perform <code>puppet module list</code> with <code>sudo</code> only. Same for non-<code>sudo</code> use.</p>

<h2 id="puppet-in-master-client-configuration:3eb4397264d4b1e9ded54ff4b133eea0">Puppet in master-client configuration</h2>

<p>Everything we did so far concerned with a single machine. Let&rsquo;s now introduce another machine &ndash; Puppet agent.</p>

<p>Note that you need to set FQDNs for both the machines. See the step above, where we suppressed a warning.</p>

<p>First, we&rsquo;ll need to install <code>puppet</code> package (the agent) on the agent node.</p>

<pre><code>sudo apt-get install puppet
</code></pre>

<p>By default, the Puppet agent service will not be running.</p>

<pre><code>r@puppet-agent:~$ sudo service puppet status
 * agent is not running
</code></pre>

<p>Before starting it, change <code>START=no</code> to <code>START=yes</code> in <code>/etc/default/puppet</code> file, to start the agent service by default when the system starts/reboots.</p>

<pre><code>sudo sed -i s/START=no/START=yes/g /etc/default/puppet 
</code></pre>

<p>And add these two lines at the end of <code>/etc/puppet/puppet.conf</code> to allow the agent to discover the master by its FQDN.</p>

<pre><code>[agent]
server = puppet-master
</code></pre>

<p>Now start the Puppet agent service</p>

<pre><code>r@puppet-agent:~$ sudo service puppet start
 * Starting puppet agent                                   [ OK ] 
</code></pre>

<p>I also make sure that clocks of both the machines are synchronized by running <code>ntpdate</code> on both master and slave. I am not sure if this is required, but doesn&rsquo;t do any harm.
    sudo ntpdate pool.ntp.org</p>

<p>Now the master needs to sign the certs by agent.</p>

<p>Execute this command on agent node.</p>

<pre><code>sudo puppet agent --test --waitforcert 60
</code></pre>

<p>Now hop over to the master node, and retrieve the list of certs waiting to be signed</p>

<pre><code>r@puppet-master:~$ sudo puppet cert --list
  &quot;puppet-agent.rushiagr.com&quot; (EB:0F:E4:14:6F:B2:7E:85:7E:21:26:C4:78:80:58:E1)
</code></pre>

<p>Sign the cert</p>

<pre><code>r@puppet-master:~$ sudo puppet cert sign puppet-agent.rushiagr.com
notice: Signed certificate request for puppet-agent.rushiagr.com
notice: Removing file Puppet::SSL::CertificateRequest puppet-agent.rushiagr.com at '/var/lib/puppet/ssl/ca/requests/puppet-agent.rushiagr.com.pem'
</code></pre>

<p>Now we are ready to go. Let&rsquo;s create a file (&lsquo;Puppet manifest&rsquo;) on master where we write that: 1. We want apache package to be installed. 2. Once we ensure that the package is installed, we want to start the apache service. We&rsquo;ll name the file <code>site.pp</code>, which is the &lsquo;main&rsquo; configuration file for Puppet. We&rsquo;ll put it into <code>/etc/puppet/manifests</code> directory. Note how we can specify a dependency between resources.</p>

<pre><code>package { 'apache2':
    ensure =&gt; installed
}

service { 'apache2':
    ensure =&gt; true,
    enable =&gt; true,
    require =&gt; Package['apache2']
}       
</code></pre>

<p>Puppet works on &lsquo;push&rsquo; model, meaning configurations are pulled by agents at periodic intervals. I think the default periodic interval is 30 minutes. Alternatively, you can pull from agent at your own will, any time. Let&rsquo;s do that now. Execute this command on the agent:</p>

<pre><code>r@puppet-agent:~$ sudo puppet agent --test
info: Caching catalog for puppet-agent.rushiagr.com
info: Applying configuration version '1397343482'
notice: /Stage[main]//Package[apache2]/ensure: ensure changed 'purged' to 'present'
notice: Finished catalog run in 6.30 seconds
</code></pre>

<p>And you can see the apache server running!</p>

<pre><code>r@puppet-agent:~$ sudo service apache2 status
Apache2 is running (pid 5874).
</code></pre>

<p>Ta! Da!</p>

<p>Please comment if you have any ideas to make this post easier for the newbies to understand.</p>

<p>Cheers!</p>

<p><strong>Notes:</strong></p>

<p>This is just a quick start guide. There are excellent resources and docs at <a href="http://puppetlabs.com">puppetlabs.com</a>. I have their beginner&rsquo;s <a href="https://dl.dropboxusercontent.com/u/42084476/OpenStack/learningpuppet.pdf">PDF</a> saved in my DropBox.
Around 80 pages long, it covers almost every aspect of basic Puppet. The only problem with this guide is it is (I think deliberately) made to work only with the Enterprise Puppet version, but you can always refer back to this post to know how to set the open source version :)</p>

<p>If you mess up the cert signing process, here is a quick and dirty way to get it resolved. On master:</p>

<pre><code>sudo puppet cert clean puppet-agent.rushiagr.com
</code></pre>

<p>On both master and slave:
    sudo rm -r /var/lib/puppet/ssl
    sudo service puppet restart</p>

  </div>
  
  
  
  <div class="post">
    <h1 class="post-title">
      <a href="http://rushiagr.com/blog/2014/04/03/openstack-in-an-hour-with-devstack/">
        OpenStack in an hour with DevStack
      </a>
    </h1>

    <span class="post-date">Apr 3, 2014</span>

    


    

<p>So you found out a cool new technology &ldquo;OpenStack&rdquo; and want to try it real quick? Or probably you are hired in a company for your Python skills and now you are supposed to work on OpenStack in the shortest possible time? Fear not, it is not that hard to get started. <a href="http://devstack.org">DevStack</a> is your friend-in-need. No, don&rsquo;t click that hyperlink just yet :)</p>

<p>To put it in a sentence, DevStack is &ldquo;OpenStack in a box&rdquo;. You just need a popular Linux based distribution with 2GB RAM and you&rsquo;re all set to start. DevStack is basically a set of scripts which will install all the important OpenStack services in your computer. For this, it will first download all the essential packages, pull in the OpenStack code from various OpenStack projects, and set everything up for you to try out all of it.</p>

<p>NOTE: DO NOT set up DevStack for production clouds.</p>

<p>Here, in this tutorial, I&rsquo;ll be setting up DevStack in a 64-bit Ubuntu 12.04 virtual machine. All your virtual machine needs to have is an Internet connection, and 2GB RAM.</p>

<p>NOTE: Do not run any of the script as a root user, unless specified otherwise explicitly.</p>

<h3 id="getting-started:98c134cd40c558c50c274d316252e460">Getting started</h3>

<p>Install git</p>

<pre><code>sudo apt-get install git
</code></pre>

<p>Clone the DevStack repository into your computer and <code>cd</code> into it. This is the code which will set up the cloud for you.</p>

<pre><code>git clone http://github.com/openstack-dev/devstack
cd devstack/
</code></pre>

<p>If you do a <code>ls</code>, you will see <code>stack.sh</code>, <code>unstack.sh</code> and <code>rejoin-stack.sh</code> files in there. These are the most important files.</p>

<pre><code>r@ra:~/devstack$ ls
accrc         exercises         HACKING.rst  rejoin-stack.sh  tests
AUTHORS       exercise.sh       lib          run_tests.sh     tools
clean.sh      extras.d          LICENSE      samples          unstack.sh
driver_certs  files             localrc      stackrc
eucarc        functions         openrc       stack-screenrc
exerciserc    functions-common  README.md    stack.sh
</code></pre>

<p>File <code>stack.sh</code> is the most important of them all. Running this script will:
1. Pull OpenStack code from all of it&rsquo;s important projects&rsquo; repositories and put them in <code>/opt/stack</code> directory. TODO: say that this directory is configurable.
2. Installs all the dependencies these OpenStack projects have &ndash; both in the form of Ubuntu packages, and also the Python &ldquo;PIP&rdquo; repositories.
3. Starts all the OpenStack services with a default configuration.</p>

<p>Bringing down the DevStack-created cloud is easy too &ndash; just invoke the <code>unstack.sh</code> script, and all the services are down again, freeing up the memory that these services consume. I&rsquo;ll talk about <code>rejoin-stack.sh</code> in some time. Let&rsquo;s get started before I start writing at lengths again :)</p>

<p>Execute the <code>stack.sh</code> script</p>

<pre><code>r@ra:~/devstack$ ./stack.sh 

################################################################################
ENTER A PASSWORD TO USE FOR THE DATABASE.
################################################################################
This value will be written to your localrc file so you don't have to enter it 
again.  Use only alphanumeric characters.
If you leave this blank, a random default value will be used.
Enter a password now:
</code></pre>

<p>You need to add the MySQL database password here. Don&rsquo;t worry if you have not installed MySQL on this system. Just provide a password here and this script will install MySQL and use this password there.</p>

<p>As you can see, MySQL is where all the important data is stored by different OpenStack components. You can peep into the database later if you want to see what data is stored, etc.</p>

<p>Also, note the first line after the heading. If the <code>stack.sh</code> script finishes successfully, all the inputs you specify (this, and four more after this) will be written to a file named as <code>localrc</code>. All the local configuration setting pertaining to the DevStack environment will go in this file. I&rsquo;ll provide you with details of all of them very soon. Have patience :)</p>

<p>For the other four prompts, enter &lsquo;nova&rsquo;. Just use &lsquo;nova&rsquo; for this MySQL prompt too if it is not installed yet.</p>

<p>You will see that the script now starts spewing a lot of output on our screen. It is downloading all the required code, packages, dependencies, etc, and setting everything up for us &ndash; databases, services, network, configurations, message queues. Pretty much everything. For the first time, the script might take about 30-minutes, but it again depends upon the speed of your Internet connection, and the processing speed of your virtual machine. From the next time, it can provide you with a cloud in less than 10 minutes!</p>

<p>If the script ends with something like this:</p>

<pre><code>+ merge_config_group /home/r/devstack/local.conf post-extra
+ local localfile=/home/r/devstack/local.conf
+ shift
+ local matchgroups=post-extra
+ [[ -r /home/r/devstack/local.conf ]]
+ return 0
+ [[ -x /home/r/devstack/local.sh ]]
+ service_check
+ local service
+ local failures
+ SCREEN_NAME=stack
+ SERVICE_DIR=/opt/stack/status
+ [[ ! -d /opt/stack/status/stack ]]
++ ls '/opt/stack/status/stack/*.failure'
++ /bin/true
+ failures=
+ '[' -n '' ']'
+ set +o xtrace



Horizon is now available at http://10.0.2.15/
Keystone is serving at http://10.0.2.15:5000/v2.0/
Examples on using novaclient command line is in exercise.sh
The default users are: admin and demo
The password: nova
This is your host ip: 10.0.2.15
stack.sh completed in 269 seconds.
</code></pre>

<p>That means your machine is now home to a Cloud! :)</p>

<p>Here, <code>10.0.2.15</code> is the IP of my first network interface. Don&rsquo;t worry about that for now.</p>

<p>So now you can head over to my blog <a href="http://www.rushiagr.com/blog/2013/05/27/cinder-on-devstack-quick-start/">Cinder on DevStack - Quick Start</a> to get started with creating volumes (persistent storage in cloud) with Cinder &ndash; OpenStack&rsquo;s block-storage project. In that guide, you will also be creating a virtual machine, so it will be a good start to OpenStack. But let&rsquo;s get back in our current scope.</p>

<p>You can type the host IP provided by the script into your browser, to access the dashboard &lsquo;Horizon&rsquo;. Log into it using username &lsquo;admin&rsquo;, or &lsquo;demo&rsquo; and password &lsquo;nova&rsquo;. (For simplicity&rsquo;s sake, lets just assume there are two users who are allowed to access this cloud &ndash; one has all the administrative privilages, and the other one is just a normal user).</p>

<p>You can view all the process logs inside screen, by typing:</p>

<pre><code>screen -x
</code></pre>

<p>Head over to <a href="http://www.rushiagr.com/blog/2013/06/05/linux-screens-in-devstack/">Linux Screens in DevStack</a> for more information on how to work with <code>screen</code>.</p>

<h3 id="housekeeping-and-customizations:98c134cd40c558c50c274d316252e460">Housekeeping and customizations</h3>

<p>In your life as an OpenStack developer, you will be setting up and destroying DevStack instance quite a number of times. So it is good to know how to do that in the most efficient manner.</p>

<p>Just like <code>stack.sh</code> script is used to set up DevStack, <code>unstack.sh</code> is used to destroy the DevStack setup. Running it will kill all the services, BUT it will not delete any of the code. If you want to bring down all the services manually, just do a:</p>

<pre><code>sudo killall screen
</code></pre>

<p>Note that this will just kill all the process which were running, for which you were able to see the logs inside screen. <code>unstack.sh</code> does some cleanups as well along with killing processes.</p>

<p>If you had previously run <code>./stack.sh</code>, but have brought down the environment, you can bring it up back by executing the <code>rejoin_stack.sh</code> script.</p>

<p>NOTE: DevStack environment doesn&rsquo;t persist across reboots!</p>

<p>So you need to bring back up the DevStack environment manually everytime you reboot. Here is where using a virtual machine comes handy. You can take a snapshot of the virtual machine, and then go back to it when you want a clean DevStack environment.</p>

<p>Nonetheless, the best way to reboot is: first execute <code>unstack.sh</code> to bring down the current running DevStack instance. Then reboot, and when your machine comes up again, run <code>rejoin_stack.sh</code>. If you don&rsquo;t run <code>unstack.sh</code>, you will need to execute <code>stack.sh</code> again to have the environment up.</p>

<h3 id="localrc-configurations:98c134cd40c558c50c274d316252e460">localrc configurations</h3>

<p><code>localrc</code> is the file where all the local configurations (local = your local machine) are kept.</p>

<p>After first successful <code>stack.sh</code> run, will see that a localrc file gets created with the configuration values you specified while running that script.</p>

<pre><code>$ cat localrc 
DATABASE_PASSWORD=nova
RABBIT_PASSWORD=nova
SERVICE_TOKEN=nova
SERVICE_PASSWORD=nova
ADMIN_PASSWORD=nova
</code></pre>

<p>Sometimes you will forget to unstack, and will reboot the machine. And then you will find that running <code>stack.sh</code> will again do an <code>apt-get update</code>, and check for all packages, etc.</p>

<p>If you specify an option <code>OFFLINE=True</code> in a file named <code>localrc</code>, inside the devstack directory, and if after specifying this you run <code>stack.sh</code>, it will not check anything over the Internet, and will set up DevStack using all the packages and code residing in your machine. Setting up a DevStack using this config option will give you a running cloud in the shortest amount of time (after <code>rejoin_stack.sh</code>, but you have already forgotten to do <code>unstack.sh</code>, right :) ).</p>

<p>Note that <code>stack.sh</code> will see if the git repositories of the OpenStack projects are present in <code>/opt/stack/</code> directory. If they are, it will not fetch any latest code into them from Github. But if any of the directory (say, <code>nova</code>), is absent, it will pull latest code into the newly created <code>nova</code> directory inside <code>/opt/stack</code>.</p>

<p>What if you want to get the latest code into all the OpenStack repositories inside <code>/opt/stack</code>? Just specify a <code>RECLONE=yes</code> parameter in localrc, and rerun <code>./stack.sh</code>. This comes particularly handy when you are developing new code.</p>

<p>NOTE: Keep in mind that while developing code, you need to <strong>commit your local changes</strong> in, say, <code>/opt/stack/nova</code> repository, before you restack (re-run <code>stack.sh</code>) with <code>RECLONE=yes</code> option, as otherwise, the changes will be wiped off. Save yourself from a rude shock. You have been warned.</p>

<p>Configuration options <code>RECLONE=yes</code> and <code>OFFLINE=True</code> are complementary, and hence, use only one of them at a time in <code>localrc</code>.</p>

<p>If you have more than one interfaces, you can specify which one to use for external IP using this configuration:</p>

<pre><code>HOST_IP=192.168.xxx.xxx
</code></pre>

<h3 id="developing-code:98c134cd40c558c50c274d316252e460">Developing code</h3>

<p>If you want to immediately test out your code by running it inside DevStack, you need to make the changes in the code, and restart the affected services.</p>

<p>For example, let us say you are making code changes in <code>nova</code>. Just after you are done making the changes, go to the screen, and restart all the services which start with &ldquo;n-&rdquo;. If you are very sure that only one of the Nova service is affected, just restart that. Or if you don&rsquo;t know which one to restart, it is safe to restart all of them.</p>

<p>In order to restart, go to the respective screen and press <code>CTRL</code>+<code>C</code>. Then, press the up arrow once to get the last command which started this screen session, and then press <code>ENTER</code>.</p>

<h3 id="final-words:98c134cd40c558c50c274d316252e460">Final words</h3>

<p>Note that this guide just gets you started with OpenStack using DevStack. OpenStack, and cloud in general, is not about virtual machines or volumes or networks only. It is a philosophy. It is a complete paradigm shift, and as such, it is impossible to cover all of it by me. Your quest to know more about it has just started. Keep reading more and more about it and I guarantee you you will be fascinated by it&rsquo;s limitless possibilities.</p>

<p>This post is written keeping in mind that it will be consumed by a newbie to OpenStack development. If you are one of the one benefitting from this guide, I would love it if you can provide me with suggestions to improve this post, and any feedback you have about it.</p>

<p>Now you can go to the <a href="http://devstack.org">DevStack</a> website :)</p>

<p>Cheers!
Rushi</p>

  </div>
  
  
  
  <div class="post">
    <h1 class="post-title">
      <a href="http://rushiagr.com/blog/2014/03/31/mysql-cheat-sheet/">
        MySQL Cheat Sheet
      </a>
    </h1>

    <span class="post-date">Mar 31, 2014</span>

    


    

<p>Databases are so important, yet almost all the time I need to work with it, I find that I have already forgotten all the syntax! So here I am writing down a quick cheat sheet to get me up and running when I&rsquo;m waking up from slumber. I hope this will help atleast one other guy on this planet.</p>

<!-- more -->

<p>I use mostly Ubuntu, so some of the commands might be Ubuntu specific.</p>

<p>Install mysql</p>

<pre><code>sudo apt-get install mysql-server
</code></pre>

<p>A prompt will ask for the root password.</p>

<p>To change the root password:</p>

<pre><code>FLUSH PRIVILEGES;
    UPDATE mysql.user SET password=PASSWORD('nova') WHERE user='root';
</code></pre>

<p>NOTE: MySQL keywords are case insensitive. They&rsquo;re represented in capital here just so that they appear different than the rest. When you&rsquo;re just testing out some things logging into the DB console, people generally prefer writing in small caps.</p>

<p>Note that <code>PASSWORD</code> is a function, and unlike other MySQL keywords cannot be used in small caps.</p>

<p>Log into MySQL console with user <code>root</code> and password <code>mysecretpassword</code>:</p>

<pre><code>mysql -uroot -pmysecretpassword
</code></pre>

<p>or</p>

<pre><code>mysql -u'root' -p'mysecretpassword'
</code></pre>

<p>or entering the password in &lsquo;secret&rsquo; mode:</p>

<pre><code>$ mysql -uroot -p
Enter password: 
</code></pre>

<h3 id="mysql-console:5aec0d683ee8bcb2a598c5a9ce48ebc9">MySQL console</h3>

<p>List all databases:</p>

<pre><code>mysql&gt; SHOW DATABASES;
+--------------------+
| Database           |
+--------------------+
| information_schema |
| mysql              |
| performance_schema |
| test               |
+--------------------+
4 rows in set (0.01 sec)
</code></pre>

<p>Create a new database <code>rushi</code>:</p>

<pre><code>mysql&gt; CREATE DATABASE rushi;
Query OK, 1 row affected (0.00 sec)

mysql&gt; show databases;
+--------------------+
| Database           |
+--------------------+
| information_schema |
| mysql              |
| performance_schema |
| rushi              |
| test               |
+--------------------+
5 rows in set (0.00 sec)
</code></pre>

<p>Select database <code>rushi</code>, so that all the further operations are executed inside this database:</p>

<pre><code>mysql&gt; USE rushi;
Database changed
</code></pre>

<p>Create a table <code>friends</code> inside <code>rushi</code> database:</p>

<pre><code>mysql&gt; CREATE TABLE friends (name VARCHAR(20), age INT);
Query OK, 0 rows affected (0.03 sec)
</code></pre>

<p>If you didn&rsquo;t select the database in the last to last command, you need to specify table in this format:<code>&lt;database&gt;.&lt;tablename&gt;</code>. So the last command would look like:</p>

<pre><code>mysql&gt; CREATE TABLE rushi.friends (name VARCHAR(20), age INT);
</code></pre>

<p>List all the tables:</p>

<pre><code>mysql&gt; show tables;
+-----------------+
| Tables_in_rushi |
+-----------------+
| friends         |
+-----------------+
1 rows in set (0.00 sec)
</code></pre>

<p>Insert data into <code>friends</code>:</p>

<pre><code>mysql&gt; INSERT INTO friends VALUES ('arvind', 24);
Query OK, 1 row affected (0.01 sec)
</code></pre>

<p>Display all the data from the table:</p>

<pre><code>mysql&gt; SELECT * FROM friends;
+--------+------+
| name   | age  |
+--------+------+
| arvind |   24 |
+--------+------+
1 row in set (0.00 sec)
</code></pre>

<p>Insert another friend:</p>

<pre><code>mysql&gt; INSERT INTO friends VALUES ('honshu', 23);
Query OK, 1 row affected (0.00 sec)

mysql&gt; SELECT * FROM friends;
+--------+------+
| name   | age  |
+--------+------+
| arvind |   24 |
| honshu |   23 |
+--------+------+
2 rows in set (0.00 sec)
</code></pre>

<p>Update a row in the table:</p>

<pre><code>mysql&gt; UPDATE friends SET age=22 WHERE name='honshu';
Query OK, 1 row affected (0.02 sec)
Rows matched: 1  Changed: 1  Warnings: 0

mysql&gt; SELECT * FROM friends;
+--------+------+
| name   | age  |
+--------+------+
| arvind |   24 |
| honshu |   22 |
+--------+------+
2 rows in set (0.00 sec)
</code></pre>

<p>Delete a row from table:</p>

<pre><code>mysql&gt; DELETE FROM friends WHERE age=24;
Query OK, 1 row affected (0.00 sec)

mysql&gt; select * from friends;
+--------+------+
| name   | age  |
+--------+------+
| honshu |   22 |
+--------+------+
1 row in set (0.00 sec)
</code></pre>

<p>Delete all rows from the table in one go, and reset the autoincrement if any:</p>

<pre><code>mysql&gt; TRUNCATE friends;
Query OK, 0 rows affected (0.04 sec)
</code></pre>

<p>Delete the table and all of its contents:</p>

<pre><code>mysql&gt; DROP TABLE friends;
</code></pre>

<p>Other commonly used commands are listed below. Try to try all of them out atleast once.
Count the number of rows in a table:</p>

<pre><code>SELECT COUNT(*) FROM friends;
</code></pre>

<p>Select distinct values for a row, and order them too:</p>

<pre><code>SELECT DISTINCT age FROM friends ORDER BY age;
</code></pre>

<p>Modify table to add one more column to it:</p>

<pre><code>ALTER TABLE friend ADD height varchar(10);
</code></pre>

<p>Use regular expressions:</p>

<pre><code>SELECT * FROM friend WHERE name REGEXP 'arv*';
</code></pre>

<p>CAUTION: Regular expressions comes with some binary/encoding trickery. Use it with a lot of caution.</p>

<p>Create a new user for the database, and give it all the root privileges</p>

<pre><code>CREATE USER 'rushiagr'@'localhost' IDENTIFIED BY 'mysecretpass'
GRANT ALL PRIVILEGES ON * . * TO 'rushiagr'@'localhost'
</code></pre>

<p>Take a dump of database <code>rushi</code> and store it in a file <code>db.dump</code>. Execute this command in bash shell, and not in the MySQL shell.:</p>

<pre><code>mysqldump --user root rushi &gt; db.dump
</code></pre>

<p>The End!</p>

<p>Comments/suggestions/feedback? Please feel free to comment and I&rsquo;ll make sure I acknowledge them to the fullest.</p>

<p>Cheers!</p>

  </div>
  
  
  
  <div class="post">
    <h1 class="post-title">
      <a href="http://rushiagr.com/blog/2014/01/16/playing-around-with-cinder-backend/">
        Playing around with Cinder multi-backend
      </a>
    </h1>

    <span class="post-date">Jan 16, 2014</span>

    


    

<p>With Grizzly release, Cinder got equipped with another major feature &ndash; multi-backends
with filter scheduler. So now you can have more than one storage boxes for block storage
and manage them with one Cinder deployment. Here, I&rsquo;m going to test it out using our
favourite method &ndash; trying it out on DevStack!</p>

<p>DevStack can provide you with two LVM backends to play around with them. But you&rsquo;ll need to restack it.</p>

<p>Go to the devstack directory and pull the latest code. Destroy previous DevStack deployment if it exists.</p>

<pre><code>rushi@jio:~/devstack$ git pull origin master
rushi@jio:~/devstack$ ./unstack.sh
</code></pre>

<p>Add the config option to <code>localrc</code> which give you pre-cooked multi-backend setup with two LVM backends, both of 10G. Stack</p>

<pre><code>rushi@jio:~$ echo &quot;CINDER_MULTI_LVM_BACKEND=True&quot; &gt;&gt; localrc
rushi@jio:~$ ./devstack/stack.sh
</code></pre>

<p>You can see that the cinder.conf file now has two values for enabled backends:</p>

<pre><code>rushi@jio:~$ less /etc/cinder/cinder.conf | grep enabled_backends
enabled_backends = lvmdriver-1,lvmdriver-2
#enabled_backends=&lt;None&gt;
</code></pre>

<p>Also, you can see that there are two configuration groups created at the end of that config file, one each for configurations
corresponding to that particular backend</p>

<pre><code>rushi@jio:~$ tail /etc/cinder/cinder.conf 

[lvmdriver-1]
volume_backend_name = LVM_iSCSI
volume_driver = cinder.volume.drivers.lvm.LVMISCSIDriver
volume_group = stack-volumes

[lvmdriver-2]
volume_backend_name = LVM_iSCSI_2
volume_driver = cinder.volume.drivers.lvm.LVMISCSIDriver
volume_group = stack-volumes2
</code></pre>

<p>So you have two volume groups created for respective backends. Lets check it directly without using Cinder.</p>

<pre><code>rushi@jio:~$ sudo vgs
  VG             #PV #LV #SN Attr   VSize   VFree 
  stack-volumes    1   0   0 wz--n-  10.01g 10.01g
  stack-volumes2   1   0   0 wz--n-  10.01g 10.01g
  ubuntu-vg        1   2   0 wz--n- 931.27g 44.00m
</code></pre>

<p>Hmmm. Two volume groups, each of size 10G.</p>

<h3 id="case-1-spreading-volumes-across-backends:e7ca627f9f234e54370b6062eba6e3e5">Case 1: Spreading volumes across backends</h3>

<p>Now, lets create a volume and see where it ends up.</p>

<pre><code>rushi@jio:~$ cinder create 1
ERROR: You must provide a username via either --os-username or env[OS_USERNAME]
</code></pre>

<p>Oops! Let me try again..</p>

<pre><code>rushi@jio:~$ . devstack/openrc 
rushi@jio:~$ cinder create 1
+-------------------+--------------------------------------+
|      Property     |                Value                 |
+-------------------+--------------------------------------+
|    attachments    |                  []                  |
| availability_zone |                 nova                 |
|      bootable     |                false                 |
|     created_at    |      2014-01-16T17:29:49.241493      |
|    description    |                 None                 |
|         id        | ecfbfebb-73d5-4faf-b625-e69f18020378 |
|      metadata     |                  {}                  |
|        name       |                 None                 |
|        size       |                  1                   |
|    snapshot_id    |                 None                 |
|    source_volid   |                 None                 |
|       status      |               creating               |
|      user_id      |   e441f49105f343da87316ab7157e2ab7   |
|    volume_type    |                 None                 |
+-------------------+--------------------------------------+

rushi@jio:~$ cinder list
+--------------------------------------+-----------+------+------+-------------+----------+-------------+
|                  ID                  |   Status  | Name | Size | Volume Type | Bootable | Attached to |
+--------------------------------------+-----------+------+------+-------------+----------+-------------+
| ecfbfebb-73d5-4faf-b625-e69f18020378 | available | None |  1   |     None    |  false   |             |
+--------------------------------------+-----------+------+------+-------------+----------+-------------+

rushi@jio:~$ sudo vgs
  VG             #PV #LV #SN Attr   VSize   VFree 
  stack-volumes    1   0   0 wz--n-  10.01g 10.01g
  stack-volumes2   1   2   0 wz--n-  10.01g  9.01g
  ubuntu-vg        1   2   0 wz--n- 931.27g 44.00m
</code></pre>

<p>So it went to backend number 2. If you are admin (<code>source devstack/openrc admin admin</code>), you can do a <code>cinder show</code> too, to get information
as to which host did this volume go to. Only the admin is allowed to view the host information.</p>

<p>The scheduler now gets reported of the capabilities which the backends have (check out the <code>c-shr</code> screen to see it). The scheduler then weighs the backend based on these capabilities and decides which of them has higher &lsquo;weight&rsquo; to serve the next &lsquo;create&rsquo; request. By default, the &lsquo;weigher&rsquo; for scheduler is <code>CapacityWeigher</code>. That is, whichever backend has higher capacity, that backend will be chosen for the next &lsquo;create&rsquo; request.</p>

<p>So in our case, when we&rsquo;ll do another &lsquo;create volume&rsquo; it will now land on to the first backend.</p>

<pre><code>rushi@jio:~$ cinder create 1
+-------------------+--------------------------------------+
|      Property     |                Value                 |
+-------------------+--------------------------------------+
|    attachments    |                  []                  |
| availability_zone |                 nova                 |
|      bootable     |                false                 |
|     created_at    |      2014-01-16T17:39:23.958468      |
|    description    |                 None                 |
|         id        | aa79c608-47cc-44e3-a614-f4bddaab68e5 |
|      metadata     |                  {}                  |
|        name       |                 None                 |
|        size       |                  1                   |
|    snapshot_id    |                 None                 |
|    source_volid   |                 None                 |
|       status      |               creating               |
|      user_id      |   e441f49105f343da87316ab7157e2ab7   |
|    volume_type    |                 None                 |
+-------------------+--------------------------------------+

rushi@jio:~$ sudo vgs
  VG             #PV #LV #SN Attr   VSize   VFree 
  stack-volumes    1   0   0 wz--n-  10.01g  9.01g
  stack-volumes2   1   2   0 wz--n-  10.01g  9.01g
  ubuntu-vg        1   2   0 wz--n- 931.27g 44.00m
</code></pre>

<p>Neat!</p>

<h3 id="case-2-stacking-all-volumes-at-one-backend:e7ca627f9f234e54370b6062eba6e3e5">Case 2 : Stacking all volumes at one backend</h3>

<p>What if we want to keep all the volumes at only one backend? Cinder allows you to do that too!
There is a configuration option in cinder.conf, <code>capacity_weight_multiplier</code>, which allows you to multiply the &lsquo;capacity weight&rsquo; by a number.
So if the multiplier is 1, a backend with higher capacity will have higher weight, and will be the choice for the next volume creation request.
This is the default case. BUT what if we set it to -1? The backend with higher available capacity will have more negative weight, which will make that backend less preferable for next &lsquo;create&rsquo; request, and hence the request will go to the backend which has lesser capacity!</p>

<p>Let us see this too in action.</p>

<p>Check out the config option from cinder.conf file.</p>

<pre><code>rushi@jio:~$ cat /etc/cinder/cinder.conf | grep -B 3 ^capacity_weight_multiplier

# Multiplier used for weighing volume capacity. Negative
# numbers mean to stack vs spread. (floating point value)
# capacity_weight_multiplier=1.0
</code></pre>

<p>The config option is commented out and is there just so that you can easily change it. Now uncomment it and change it&rsquo;s value to -1.</p>

<p>Delete previously created volumes. Kill all the three Cinder screen processes (<code>c-api</code>, <code>c-sch</code> and <code>c-vol</code>), and restart them.</p>

<p>Lets create two volumes and see where they end up..</p>

<pre><code>rushi@jio:~$ cinder list
+----+--------+------+------+-------------+----------+-------------+
| ID | Status | Name | Size | Volume Type | Bootable | Attached to |
+----+--------+------+------+-------------+----------+-------------+
+----+--------+------+------+-------------+----------+-------------+
rushi@jio:~$ cinder create 1
+-------------------+--------------------------------------+
|      Property     |                Value                 |
+-------------------+--------------------------------------+
|    attachments    |                  []                  |
| availability_zone |                 nova                 |
|      bootable     |                false                 |
|     created_at    |      2014-01-16T17:56:59.845733      |
|    description    |                 None                 |
|         id        | b927b328-5ae0-411a-9de2-22ed732b4946 |
|      metadata     |                  {}                  |
|        name       |                 None                 |
|        size       |                  1                   |
|    snapshot_id    |                 None                 |
|    source_volid   |                 None                 |
|       status      |               creating               |
|      user_id      |   e441f49105f343da87316ab7157e2ab7   |
|    volume_type    |                 None                 |
+-------------------+--------------------------------------+
rushi@jio:~$ cinder create 1
+-------------------+--------------------------------------+
|      Property     |                Value                 |
+-------------------+--------------------------------------+
|    attachments    |                  []                  |
| availability_zone |                 nova                 |
|      bootable     |                false                 |
|     created_at    |      2014-01-16T17:57:01.132756      |
|    description    |                 None                 |
|         id        | 9f643f2d-7221-4a5c-bf48-1977c9b89fd3 |
|      metadata     |                  {}                  |
|        name       |                 None                 |
|        size       |                  1                   |
|    snapshot_id    |                 None                 |
|    source_volid   |                 None                 |
|       status      |               creating               |
|      user_id      |   e441f49105f343da87316ab7157e2ab7   |
|    volume_type    |                 None                 |
+-------------------+--------------------------------------+

rushi@jio:~$ sudo vgs
  VG             #PV #LV #SN Attr   VSize   VFree 
  stack-volumes    1   0   0 wz--n-  10.01g 10.01g
  stack-volumes2   1   2   0 wz--n-  10.01g  8.01g
  ubuntu-vg        1   2   0 wz--n- 931.27g 44.00m
</code></pre>

<p>:)</p>

<h3 id="case-3-custom-choice:e7ca627f9f234e54370b6062eba6e3e5">Case 3 : Custom choice</h3>

<p>What if I have two different backends (maybe one is slower, or costlier, than the other), and my users want to exactly specify how many volumes they want of each &lsquo;type&rsquo; of backends? Here, Cinder&rsquo;s &lsquo;volume types&rsquo; have us covered.</p>

<p>We can associate a volume type with a backend, and then the users can create a volume of whatever &lsquo;type&rsquo; they want.
Let&rsquo;s throw some discrimination at these backends. I&rsquo;ll create two volume types: &lsquo;gold&rsquo; and &lsquo;bronze&rsquo;, and associate &lsquo;stack-volumes&rsquo; with &lsquo;gold&rsquo; and similarly for &lsquo;stack-volumes2&rsquo;. Note that this job can only be done by the administrator.</p>

<p>Let us be admins</p>

<pre><code>rushi@jio:~$ . devstack/openrc admin admin
</code></pre>

<p>Create both the volume types and list them.</p>

<pre><code>rushi@jio:~$ cinder type-create gold
+--------------------------------------+------+
|                  ID                  | Name |
+--------------------------------------+------+
| dd883ee0-24be-42e1-ab2e-b9a01454f2f9 | gold |
+--------------------------------------+------+
rushi@jio:~$ cinder type-create bronze
+--------------------------------------+--------+
|                  ID                  |  Name  |
+--------------------------------------+--------+
| f63dd2cb-f4e7-4d6d-a84f-5bf2cc6c5671 | bronze |
+--------------------------------------+--------+

rushi@jio:~$ cinder type-list
+--------------------------------------+--------+
|                  ID                  |  Name  |
+--------------------------------------+--------+
| dd883ee0-24be-42e1-ab2e-b9a01454f2f9 |  gold  |
| f63dd2cb-f4e7-4d6d-a84f-5bf2cc6c5671 | bronze |
+--------------------------------------+--------+
</code></pre>

<p>Get the backend names (<code>volume_backend_name</code> config option) from cinder.conf file.</p>

<pre><code>rushi@jio:~$ tail /etc/cinder/cinder.conf 

[lvmdriver-1]
volume_backend_name = LVM_iSCSI
volume_driver = cinder.volume.drivers.lvm.LVMISCSIDriver
volume_group = stack-volumes

[lvmdriver-2]
volume_backend_name = LVM_iSCSI_2
volume_driver = cinder.volume.drivers.lvm.LVMISCSIDriver
volume_group = stack-volumes2
</code></pre>

<p>Now let&rsquo;s associate backend <code>LVM_iSCSI</code> with volume type &lsquo;gold&rsquo;, and similarly for the other one.</p>

<pre><code>rushi@jio:~$ cinder type-key gold set volume_backend_name=LVM_iSCSI
rushi@jio:~$ cinder type-key bronze set volume_backend_name=LVM_iSCSI_2
</code></pre>

<p>These association are stored as key-value pairs in the volume type&rsquo;s &lsquo;extra specs&rsquo;. Let&rsquo;s see them</p>

<pre><code>rushi@jio:~$ cinder extra-specs-list 
+--------------------------------------+--------+------------------------------------------+
|                  ID                  |  Name  |               extra_specs                |
+--------------------------------------+--------+------------------------------------------+
| dd883ee0-24be-42e1-ab2e-b9a01454f2f9 |  gold  |  {u'volume_backend_name': u'LVM_iSCSI'}  |
| f63dd2cb-f4e7-4d6d-a84f-5bf2cc6c5671 | bronze | {u'volume_backend_name': u'LVM_iSCSI_2'} |
+--------------------------------------+--------+------------------------------------------+
</code></pre>

<p>You can add more key-value pairs for these volume types with different key names. <code>volume_backend_name</code> is a reserved key name, though.</p>

<p>Let&rsquo;s create two volumes of type &lsquo;gold&rsquo; and see where they end up being created:</p>

<pre><code>rushi@jio:~$ cinder create --volume-type gold --name costly_vol_1 1
+-------------------+--------------------------------------+
|      Property     |                Value                 |
+-------------------+--------------------------------------+
|    attachments    |                  []                  |
| availability_zone |                 nova                 |
|      bootable     |                false                 |
|     created_at    |      2014-01-16T18:24:07.670635      |
|    description    |                 None                 |
|         id        | 767d4c56-6d3d-46f7-b0a3-4a00f696bcad |
|      metadata     |                  {}                  |
|        name       |             costly_vol_1             |
|        size       |                  1                   |
|    snapshot_id    |                 None                 |
|    source_volid   |                 None                 |
|       status      |               creating               |
|      user_id      |   c271eb32e71b411bb98ad7b93792d6d5   |
|    volume_type    |                 gold                 |
+-------------------+--------------------------------------+
rushi@jio:~$ cinder create --volume-type gold --name costly_vol_2 1
+-------------------+--------------------------------------+
|      Property     |                Value                 |
+-------------------+--------------------------------------+
|    attachments    |                  []                  |
| availability_zone |                 nova                 |
|      bootable     |                false                 |
|     created_at    |      2014-01-16T18:24:58.382180      |
|    description    |                 None                 |
|         id        | a938e556-65cf-4547-87ff-513d60f626d3 |
|      metadata     |                  {}                  |
|        name       |             costly_vol_2             |
|        size       |                  1                   |
|    snapshot_id    |                 None                 |
|    source_volid   |                 None                 |
|       status      |               creating               |
|      user_id      |   c271eb32e71b411bb98ad7b93792d6d5   |
|    volume_type    |                 gold                 |
+-------------------+--------------------------------------+
rushi@jio:~$ cinder list
+--------------------------------------+-----------+--------------+------+-------------+----------+-------------+
|                  ID                  |   Status  |     Name     | Size | Volume Type | Bootable | Attached to |
+--------------------------------------+-----------+--------------+------+-------------+----------+-------------+
| 767d4c56-6d3d-46f7-b0a3-4a00f696bcad | available | costly_vol_1 |  1   |     gold    |  false   |             |
| a938e556-65cf-4547-87ff-513d60f626d3 | available | costly_vol_2 |  1   |     gold    |  false   |             |
+--------------------------------------+-----------+--------------+------+-------------+----------+-------------+

rushi@jio:~$ sudo vgs
  VG             #PV #LV #SN Attr   VSize   VFree 
  stack-volumes    1   2   0 wz--n-  10.01g  8.01g
  stack-volumes2   1   0   0 wz--n-  10.01g 10.01g
  ubuntu-vg        1   2   0 wz--n- 931.27g 44.00m
</code></pre>

<p>Now create another one, but with type &lsquo;bronze&rsquo; and ensure it is created on the other backend.</p>

<pre><code>rushi@jio:~$ cinder create --volume-type bronze --name cheap_vol_1 1
+-------------------+--------------------------------------+
|      Property     |                Value                 |
+-------------------+--------------------------------------+
|    attachments    |                  []                  |
| availability_zone |                 nova                 |
|      bootable     |                false                 |
|     created_at    |      2014-01-16T18:27:05.852092      |
|    description    |                 None                 |
|         id        | 97f62c7a-b974-41e8-a659-1e6d3eb876d5 |
|      metadata     |                  {}                  |
|        name       |             cheap_vol_1              |
|        size       |                  1                   |
|    snapshot_id    |                 None                 |
|    source_volid   |                 None                 |
|       status      |               creating               |
|      user_id      |   c271eb32e71b411bb98ad7b93792d6d5   |
|    volume_type    |                bronze                |
+-------------------+--------------------------------------+

rushi@jio:~$ sudo pvs
  PV         VG             Fmt  Attr PSize   PFree 
  /dev/loop0 stack-volumes  lvm2 a--   10.01g  8.01g
  /dev/loop1 stack-volumes2 lvm2 a--   10.01g  9.01g
  /dev/sda5  ubuntu-vg      lvm2 a--  931.27g 44.00m
</code></pre>

<p>Done :)</p>

<p>Cheers!</p>

  </div>
  
  
  
  <div class="post">
    <h1 class="post-title">
      <a href="http://rushiagr.com/blog/2014/01/14/quick-start-linux-logical-volume-manager/">
        Quick Start: Linux Logical Volume Manager
      </a>
    </h1>

    <span class="post-date">Jan 14, 2014</span>

    


    

<p>While installing the latest Ubuntu OS on your computer, you will see that
you can install the OS using LVM (Logical Volume Manager) utility. Ever wonder what is it?
LVM (Logical Volume Manager) is that fantastic utility for storage administration.
It provide the users with abilities which were not possible with raw disks.
The storage is now &lsquo;virtualized&rsquo;. You can now easily create, move and extend volumes (for now, think of it as disk partitions)
without bothering about data corruption. You can carve partitions out of multiple disks,
and can add and remove disks from a &lsquo;volume group&rsquo; containing such volumes without the user noticing anything!
List of all the features of LVM can be found at it&rsquo;s <a href="http://en.wikipedia.org/wiki/Logical_Volume_Manager_(Linux)"
target="_blank">wiki page</a>.</p>

<p>This blog scratches the surface of LVM, and gives some basic insights into some storage concepts.</p>

<!-- more -->

<p>I&rsquo;ll give you a simple example to better explain what a &lsquo;physical volume&rsquo;, a &lsquo;volume group&rsquo; and a
&lsquo;logical volume&rsquo; is. Say I have two 1 TB hard disks - disk A and disk B. I have two equal-sized partitions on
disk B, one of which I want to keep it to myself for my personal data. The &lsquo;partition&rsquo; term used here is
same as what you see in a file explorer. For the unpartitioned disk, the complete disk is one single partition.</p>

<p>The partitions I described above are &lsquo;physical volumes&rsquo;. That is, on the disk, these are physically separate bytes (think of that
partitioned disk as a spiral on disk divided in its length at the midpoint).
Out of the first disk and one partition of the second disk, we create a &lsquo;volume group&rsquo; &ndash; a logical pool of storage, out of which we can
create lots of &lsquo;logical volumes&rsquo;. Even after you&rsquo;ve created logical volumes over this volume group, you can add and remove physical volumes (partitions) from the volume group. You can do many more operations such as resize, move and extend.</p>

<p>I hope the basic idea written above is sufficiently clear. Else, head over to this Ubuntu <a href="https://wiki.ubuntu.com/Lvm" target="_blank">wiki</a> for a slightly more detailed, but still an overview, of LVM. Anyway, I&rsquo;m concentrating more on the demo, so lets move on.</p>

<h4 id="hands-on:2d2bf322b35613aefa5a64a06c866c26">Hands-on</h4>

<p>I&rsquo;m demo&rsquo;ing everything on an Ubuntu machine, but it should work on any Linux distro (after you install the LVM2 package)</p>

<p>Install LVM2 package</p>

<pre><code>sudo apt-get install lvm2
</code></pre>

<p>One nice thing is you don&rsquo;t need to create actual partitions on disks. We&rsquo;ll use files as <a href="http://en.wikipedia.org/wiki/Loop_device" target="_blank">loopback devices</a>, which will appear to the operating system as partitions. Neat.</p>

<p>Create a file of size 1G to be later used as a physical volume.</p>

<pre><code>rushi@jio:~$ truncate --size 1G backing_file_1
</code></pre>

<p>Create a loopback device over this file. Find the first free loopback device available and show its name.</p>

<pre><code>rushi@jio:~$ sudo losetup --find --show backing_file_1 
/dev/loop0
</code></pre>

<p>List all the loopback devices.</p>

<pre><code>rushi@jio:~$ sudo losetup --all
/dev/loop0: [fc00]:22811987 (/home/rushi/backing_file_1)
</code></pre>

<p>Create a physical volume over this loopback device. Note that</p>

<pre><code>rushi@jio:~$ sudo pvcreate /dev/loop0 
  Physical volume &quot;/dev/loop0&quot; successfully created
</code></pre>

<p>List physical volumes. Apart from <code>pvs</code> (Physical Volume Scan), there are two more
commands which do the same thing, but with different level of verbosity and formatting: <code>pvscan</code> and <code>pvdisplay</code>. (Try them out too!)</p>

<pre><code>rushi@jio:~$ sudo pvs
  PV         VG        Fmt  Attr PSize   PFree 
  /dev/loop0           lvm2 a--    1.00g  1.00g
  /dev/sda5  ubuntu-vg lvm2 a--  931.27g 44.00m
</code></pre>

<p>Let us repeat the steps to create another physical volume:</p>

<pre><code>rushi@jio:~$ truncate --size 1G backing_file_2
rushi@jio:~$ sudo losetup --find --show backing_file_2 
/dev/loop1
rushi@jio:~$ sudo losetup --all
/dev/loop0: [fc00]:22811987 (/home/rushi/backing_file_1)
/dev/loop1: [fc00]:22812001 (/home/rushi/backing_file_2)
rushi@jio:~$ sudo pvcreate /dev/loop1
  Physical volume &quot;/dev/loop1&quot; successfully created
rushi@jio:~$ sudo pvs
  PV         VG        Fmt  Attr PSize   PFree 
  /dev/loop0           lvm2 a--    1.00g  1.00g
  /dev/loop1           lvm2 a--    1.00g  1.00g
  /dev/sda5  ubuntu-vg lvm2 a--  931.27g 44.00m
</code></pre>

<p>Create a volume group <code>test-volgroup</code> over these two physical volumes. (Actually, even if you don&rsquo;t create physical volumes over loopback devices, while creating volume groups it will automatically create physical volumes over them).</p>

<pre><code>rushi@jio:~$ sudo vgcreate test-volgroup /dev/loop0 /dev/loop1
  Volume group &quot;test-volgroup&quot; successfully created
</code></pre>

<p>List the volume groups. (<code>vgs</code>, <code>vgscan</code> or <code>vgdisplay</code> can be used)</p>

<pre><code>rushi@jio:~$ sudo vgs
  VG            #PV #LV #SN Attr   VSize   VFree 
  test-volgroup   2   0   0 wz--n-   1.99g  1.99g
  ubuntu-vg       1   2   0 wz--n- 931.27g 44.00m
</code></pre>

<p>Create a logical volume <code>test-logicalvol</code> over the <code>test-volgroup</code> volume group.</p>

<pre><code>rushi@jio:~$ sudo lvcreate --size 400M --name test-logicalvol test-volgroup
  Logical volume &quot;test-logicalvol&quot; created
</code></pre>

<p>List logical volumes. (<code>lvs</code>, <code>lvscan</code>, <code>lvdisplay</code> can be used)</p>

<pre><code>rushi@jio:~$ sudo lvs
  LV              VG            Attr      LSize   Pool Origin Data%  Move Log Copy%  Convert
  test-logicalvol test-volgroup -wi-a---- 400.00m                                           
  root            ubuntu-vg     -wi-ao--- 923.35g                                           
  swap_1          ubuntu-vg     -wi-ao---   7.88g                                           
</code></pre>

<p>Easy, isn&rsquo;t it? Let&rsquo;s tear down everything. Though a simpler way would be to just remove the loopback device, which will automatically
remove all the physical, logical volumes/volume groups created over them, let&rsquo;s do it step-by-step. Note that you need to specify volume group while deleting logical volumes.</p>

<pre><code>rushi@jio:~$ sudo lvremove test-volgroup
Do you really want to remove active logical volume test-logicalvol? [y/n]: y
  Logical volume &quot;test-logicalvol&quot; successfully removed
rushi@jio:~$ sudo vgremove test-volgroup
  Volume group &quot;test-volgroup&quot; successfully removed
rushi@jio:~$ sudo pvremove /dev/loop0 /dev/loop1
  Labels on physical volume &quot;/dev/loop0&quot; successfully wiped
  Labels on physical volume &quot;/dev/loop1&quot; successfully wiped
rushi@jio:~$ sudo losetup --detach /dev/loop0 /dev/loop1
rushi@jio:~$ rm backing_file_1 backing_file_2
</code></pre>

<p>Cheers!</p>

  </div>
  
  
  
  <div class="post">
    <h1 class="post-title">
      <a href="http://rushiagr.com/blog/2014/01/12/installing-openid-plugin-for-mediawiki/">
        Installing OpenID plugin for MediaWiki
      </a>
    </h1>

    <span class="post-date">Jan 12, 2014</span>

    


    

<p>This post is about setting up your wiki such that their users access the wiki
only via an OpenID provider login (e.g. Google or Facebook login). This post assumes
MediaWiki is already installed.</p>

<h3 id="assumptions-prerequisites-and-requirements:2f6224b9d71ac646e56d4f9ff31b99ea">Assumptions, prerequisites and requirements</h3>

<p>All of what this blogpost says has been tried on an Ubuntu machine, but it
should work well on other Linux distros too (except for the <code>apt-get</code> package
installs, for which you&rsquo;ll need to find alternatives on your favourite distro).</p>

<p><code>$IP</code> is assumed to be the root of your wiki directory (which in my case is
<code>/var/www/wikis/&lt;my_wiki&gt;/</code>.</p>

<p>Install all the required packages for the plugin to work</p>

<pre><code>sudo apt-get install php5-mcrypt php5-gmp
</code></pre>

<h2 id="installing-the-plugin:2f6224b9d71ac646e56d4f9ff31b99ea">Installing the plugin</h2>

<p>Get the source code for the extension into <code>$IP/extensions</code> directory</p>

<pre><code>	cd extensions
	git clone http://gerrit.wikimedia.org/r/p/mediawiki/extensions/OpenID.git 
</code></pre>

<p>Check your mediawiki version by going to <code>&lt;your_wiki_URL&gt;/index.php?title=Special:Version</code>. Say your version is 1.19.x.
  Check out branch for the same version of OpenID code</p>

<pre><code>	git branch -a 
	git checkout -b stable_REL1_19 origin/REL1_19 
</code></pre>

<p>Add this line at the end of LocalSettings.php file</p>

<pre><code>require_once &quot;$IP/extensions/OpenID/OpenID.php&quot;; 
</code></pre>

<p>Now install Auth subdirectory as following:</p>

<pre><code>	cd $IP/extensions/OpenID 
	git clone http://github.com/openid/php-openid.git 
	mv php-openid/Auth Auth 
	rm -r php-openid 
	cd $IP 
	php maintenance/update.php --conf LocalSettings.php 
</code></pre>

<p>Restart apache server</p>

<pre><code>	/etc/init.d/apache2 restart 
</code></pre>

<h3 id="editing-login-required-page:2f6224b9d71ac646e56d4f9ff31b99ea">Editing &lsquo;Login required&rsquo; page.</h3>

<p>By default, the main page of the wiki is not editable. Generally we would like
to give some information to a user, e.g. what this wiki is all about, how
to log into it, which OpenIDs are permitted, etc.</p>

<p>Now we&rsquo;ll give any registered user the ability to edit the protected pages and the
&lsquo;interface&rsquo; pages, of which our special login page is a part of. Add these lines
 to <code>$IP/LocalSettings.php</code>:</p>

<pre><code>	$wgGroupPermissions['user']['editprotected'] = true; 
	$wgGroupPermissions['user']['editinterface'] = true; 
</code></pre>

<p>Now you can edit the <code>&lt;your_wiki_URL&gt;/jiocloud/index.phpmediawiki:loginreqpagetext</code>
 page which is presented when the user is not logged in.</p>

<h3 id="other-settings:2f6224b9d71ac646e56d4f9ff31b99ea">Other settings</h3>

<p>Below you can see a snip of LocalSettings.php file, which contains many other
fields which I used to customize my wiki. I allowed only the registered user
an edit permission (which most of you would also want I guess). Also, I have disabled
regular login, and made it mandatory users to login via only OpenID, and that too,
only using their launchpad.net accounts (an issue tracking software from Canonical).</p>

<p>If you want to get more information regarding these (and more)
configuration options, see <a href="http://www.mediawiki.org/wiki/Extension:OpenID" target="_blank">this</a> link.</p>

<pre><code># Disable reading by anonymous users
$wgGroupPermissions['*']['read'] = false;

# Disable anonymous editing too
$wgGroupPermissions['*']['edit'] = false;
 
# But allow them to access the OpenID login page or else there will be no way to log in!
$wgWhitelistRead = array (&quot;Special:OpenIDLogin&quot;, &quot;Special:OpenIDFinish&quot;, 
&quot;MediaWiki:Common.css&quot;, &quot;MediaWiki:Common.js&quot;, &quot;MediaWiki:Monobook.css&quot;, 
&quot;MediaWiki:Monobook.js&quot;, &quot;-&quot;);
 
# For registered users, allow editing protected pages
$wgGroupPermissions['user']['editprotected'] = true;
$wgGroupPermissions['user']['editinterface'] = true;

# Only allow OpenIDs for login
$wgOpenIDLoginOnly = true;
$wgOpenIDOnly = true;       # a value used with older versions. Optional

# Your wiki web URL
$wgOpenIDTrustRoot = &quot;http://your.wiki.url.com/&quot;;

# By default, deny all OpenID
$wgOpenIDConsumerDenyByDefault = true;

# Then allow only launchpad.net OpenID (with and without HTTPS both)
$wgOpenIDConsumerAllow = array(&quot;@^(https://)?launchpad.net/@&quot;);
</code></pre>

<h2 id="troubleshooting:2f6224b9d71ac646e56d4f9ff31b99ea">Troubleshooting</h2>

<p>If there are troubles uploading a file via the MediaWiki web interface, go to the wiki directory on the server and chown the <code>images</code> folder.</p>

<pre><code>sudo chown -R www-data:www-data images/
</code></pre>

<p>Don&rsquo;t forget to comment if you find the information presented here is outdated, or is not working for you.</p>

<p>Cheers,
Rushi</p>

  </div>
  
  
  
  <div class="post">
    <h1 class="post-title">
      <a href="http://rushiagr.com/blog/2014/01/01/bye-bye-2013-welcome-2014/">
        Bye bye 2013. Welcome 2014
      </a>
    </h1>

    <span class="post-date">Jan 1, 2014</span>

    


    

<p>How year 2013 fared for me, and my plans for 2014.</p>

<p>Mixed bag of a year. Some pretty hard decisions were made by me. I left the job I loved so much &ndash; joined Amazon,
rival of the technology I was working on (OpenStack). I knew my life was going to be tougher at Amazon. It was not only about
the work, but also about the philosophy. In NetApp, it was a complete opensource, collaborative model of development. Nothing
of this sort of freedom I was going to get at Amazon. But there were some internal issues of working at NetApp which prompted
me to switch over to another company. It wasn&rsquo;t me who approached them for the job but it was the other way round.  The funny part was, I didn&rsquo;t think of joining Amazon till I got the offer letter. I said okay, anyways I will need to move out of this job
(due to those internal conflicts, and partly due to the lower salary), so why not get some interviewing practice by appearing
for them at Amazon! The compensation they were offering was significantly higher than my then salary, which just gave me another reason to accept the offer. I convinced myself that I am going to anyway leave the job at Amazon as soon as I get a better opportunity
at a more freedom-loving place (freedom both in the sense of work-life balance as well as freedom of working on opensource softwares).
I made a mental note for myself that I am going to work for Amazon for 6 months at the max.</p>

<p>But God has different plans. Within a week of joining Amazon, I got a mail that Rick Clark, one of the founders of OpenStack wants to meet me, and wants me on his team which is going to work on OpenStack. The way in which he likes to work, as was told by him over a phone call, impressed me, and I quickly switched jobs. Again, in just over a month. Believe me, joining Reliance, a name not at all known in the software industry, was one heck of a decision. Not to say that switching over to Amazon from NetApp was any less emotionally draining.</p>

<p>Even after joining Reliance (Reliance Jio Infocomm to be precise), as the Bangalore office was not completely set up by the time I joined, I worked from Mumbai office, and then from home for a couple of months. Life before and after this four-month period starting from leaving job at NetApp was more sedate and stable.</p>

<h2 id="things-that-went-well-for-me:d9471f9e8ad67160d0e6ab12cdc84eea">Things that went well for me</h2>

<h4 id="day-job:d9471f9e8ad67160d0e6ab12cdc84eea">Day job</h4>

<p>Absolutely happy with the day job. Totally in love with the ownership model we have in place. I get to decide which project I will be most interested to work on. I decide what needs to be done in what time. Though this causes laziness, I manage it by following a stricter schedule, and by giving importance of the sense of trust shown in me &ndash; if someone trusts me this much, it is my moral responsibility to not disappoint him by underperforming.</p>

<p>Our chief arhitect, Soren Hansen, is exceptionally brilliant, and equally understanding. I can talk to him just like a friend.</p>

<h4 id="day-job-compensation:d9471f9e8ad67160d0e6ab12cdc84eea">Day job compensation</h4>

<p>My salary has grown to an amount that my spendings are now less than 1/5th of my total salary. This means I have fairly early in my career reached a level where I don&rsquo;t care too much about my salary, and how much it is going to increase, and related stuff. It is just another number reflected in my bank account.</p>

<h4 id="task-tracking:d9471f9e8ad67160d0e6ab12cdc84eea">Task tracking</h4>

<p>Be it tracking articles to read, blogposts to write, side projects to do, or things to learn; I am tracking each of them very efficiently thanks to the Trello. An awesome tool, and I definitely recommend you to use it. Till last year, I used to rely upon Microsoft OneNote, and thankfully I have found a better alternative for that after quite some time.</p>

<p>I also now maintain a notebook and a pen. This helps a lot for things to do in a short time, as I can have my notebook always open at my desk &ndash; not the same case with any software in the computer which always gets hidden in the background once we start working. It is a nice feeling to strike off items one-by-one from the bullet list you write down on a paper. I also find paper notebooks very helpful when I am planning something, e.g. a side project. The free form writing/drawing it allows is still not possible in the digital world, I believe.</p>

<h4 id="setting-up-priorities-in-life:d9471f9e8ad67160d0e6ab12cdc84eea">Setting up priorities in life</h4>

<p>Not anymore in mood of going for higher studies. Not going to prepare for interviews, and algorithmic questions. Going to work on side projects, and will look for opportunities of starting something of my own. Marriage? Don&rsquo;t talk about it just yet.</p>

<h2 id="things-that-didn-t-go-that-well:d9471f9e8ad67160d0e6ab12cdc84eea">Things that didn&rsquo;t go that well</h2>

<p>As always, more negatives than positives :)</p>

<h4 id="side-projects:d9471f9e8ad67160d0e6ab12cdc84eea">Side projects</h4>

<p>Two job changes, time spent in decision making and relocation, and day job work from four cities all made my life a little unsettled for a majority of this year. As a result, I couldn&rsquo;t spend much time on any of them. I started with ResumAppGAE (I know, a poor name by any standards), an application to create your resume in a single-page HTML file, but left it completely as soon as I was offered a job at Amazon. Another one, <a href="http://www.rushiagr.com/202020rule/" target="_blank">20-20-20 rule</a>, is a simple one, and I am pretty happy with its progress. Not much learning involved in it, but it gave me important lessons with respect to time and priority management.</p>

<h4 id="very-less-blogs:d9471f9e8ad67160d0e6ab12cdc84eea">Very less blogs</h4>

<p>I did work on a lot of items on which I can write blog articles, but always fell short of doing that. This article can be thought of an attempt to start fixing that.</p>

<h4 id="feeble-concentration:d9471f9e8ad67160d0e6ab12cdc84eea">Feeble Concentration</h4>

<p>Failed hopelessly on the promise of using less online social networking. Still spending too much time on online news and social networks. I still think that at the most half an hour each day is enough to keep oneself abreast of all the happenings in the world, plus keeping in contact with friends. The harder part is execution :)</p>

<p>Also, there is still a very long way to go before I am confident of my breaks between working. Proper management of breaks directly affect the productivity when one is not on a break.</p>

<h4 id="poor-time-management:d9471f9e8ad67160d0e6ab12cdc84eea">Poor time management</h4>

<p>Only in the last months was I able to reasonably balance my time between my day job, family and friends. I hope to continue the same in the coming year.</p>

<h4 id="very-less-travelling-vacation:d9471f9e8ad67160d0e6ab12cdc84eea">Very less travelling/vacation</h4>

<p>Not a single trip to any place worth visiting in the whole year. Whatever vacations I took I spent time at home. I am going to repent in my old age if I continue like this.</p>

<h2 id="plans-for-upcoming-year:d9471f9e8ad67160d0e6ab12cdc84eea">Plans for upcoming year</h2>

<h4 id="better-planning:d9471f9e8ad67160d0e6ab12cdc84eea">Better planning</h4>

<p>Of day job, side projects, blog writing, vacations, time for friends and family.</p>

<h4 id="write-blogs:d9471f9e8ad67160d0e6ab12cdc84eea">Write blogs</h4>

<p>Write as much as I can. It is the easiest, simplest and cheapest medium by which I can help people gain knowledge.</p>

<h4 id="final-goal-plus-some-resolutions:d9471f9e8ad67160d0e6ab12cdc84eea">Final goal, plus some resolutions</h4>

<p>Become expert in OpenStack. Implement and popularize a couple side projects (i.e. get people to love it). Lose weight. Do a simple workout daily.</p>

<p>All in all, a decent year. Not as good as I wanted it to be, but definitely better than the last one.</p>

<p>Cheers!</p>

  </div>
  
  
  
  <div class="post">
    <h1 class="post-title">
      <a href="http://rushiagr.com/blog/2013/06/05/linux-screens-in-devstack/">
        Linux Screens in DevStack
      </a>
    </h1>

    <span class="post-date">Jun 5, 2013</span>

    


    

<p>This blog article explains handling screens within OpenStack running as a DevStack setup. Some useful generic screen commands are also provided at the end.</p>

<p>In a DevStack environment, all the processes run under something special in Linux, called as a <code>screen</code>. For now, you can think of a screen as a terminal running inside a terminal, with the special property that when you close your current terminal, your screens will not actually die, so that you can reconnect to them when you connect to the Linux system through another terminal again! Now that should give you a hint why people use screens :)</p>

<p>Each screen runs a special service of OpenStack. So the logs of each service will go to the respective screen. If you created the DevStack environment as a root user, the process of going to a screen is slightly complicated: You first need to become the <code>stack</code> user if you are currently <code>root</code>, and even before that, you need to run this command in most of the cases:</p>

<pre><code>chown stack:stack `readlink /proc/self/fd/0`
</code></pre>

<p>Else it will produce this error <code>Cannot open your terminal '/dev/pts/2' - please check.</code> , and then you can proceed to run this command to get to the screens:</p>

<pre><code>screen -x
</code></pre>

<p>And if you ran the DevStack <code>stack.sh</code> script as a non-root user, you just need to run that last little thingy to see the screens. One more reason why you should run DevStack as a non-root.</p>

<p>The way to detach from a screen is <code>CTRL+A</code> <code>D</code>, that is, first press <code>CTRL+A</code>, and then press <code>D</code>.</p>

<h2 id="navigating-across-screens:81565885f4011e665cf1e89d6280caf9">Navigating across screens</h2>

<p>You will see names of all the screens at the bottom of the terminal. The screen on which you currently are bears an asterisk (<code>*</code>) near its name. To move to the right screen, do a <code>CTRL+A</code> <code>N</code>. Keep in mind that you are going to use <code>CTRL+A</code> a lot of times during your adventures with screen. Similar to the command <code>CTRL+A</code> <code>N</code> to move to the right (next) screen, to move to the left screen the command is <code>CTRL+A</code> <code>P</code>.</p>

<p>There is one more way to jump directly to a screen. Lets say you want to directly jump to the fourth screen. You just need to do a <code>CTRL+A</code> <code>4</code>, to go to fourth screen! Wasnt that easy? But hey! How do I get to the seventeenth screen? Frankly, I dont know a direct way. I do a <code>CTRL+A</code> <code>9</code> once, and <code>CTRL+A</code> <code>N</code> eight more times. :( If you have a better way, please do tell me.</p>

<p>Navigating inside a screen</p>

<p>The first and biggest difficulty I faced while tracking an error in the screen logs is the periodic updates in Cinder dumps some lines to the Cinder screens every now and then. So if you have a stack trace of an error on the screen, it will go up and up and up till you can no more see it! Nope, scrolling your mouse up, or pulling the scrollbar up wont help either (why not try it once :) ).</p>

<p>Within a few days, I thought Hey, Ill just reduce the font of the terminal and Ill be able to see more lines of screen logs on my screen!. I knew the command to reduce the font size of the terminal font: <code>CTRL</code>+<code>-</code> (just for the sake of completeness, the command to increase font is <code>CTRL</code>+<code>SHIFT</code>+<code>+</code>). That worked pretty okay upto a point. It actually helps to have logs in small font, as the logs will fit in one line on the screen and will look prettier. But what if I come after say a ten-minute break, and see all my logs are too far up to be able to see even by reducing font size?</p>

<p>Then I got to know the command which saved a ton of time in my life: The command to actually scroll up and down the screen.</p>

<p>To scroll up, first press <code>CTRL</code>+<code>[</code>. After that, you can use arrow keys to scroll up and down. You can also use <code>page-up</code> and <code>page-down</code> buttons to scroll one complete page up or down. This isnt all of it. If you are vim user, you will find that the <code>H</code> <code>J</code> <code>K</code> <code>L</code> will work for for <code>left</code>, <code>down</code>, <code>up</code>, and <code>right</code> respectively. And the last and most convenient thing: once you press <code>CTRL</code> <code>[</code>, that is, once you are in copy mode, you can then use your mouse scroll wheel too to scroll up and down!! Now that is a perfect delight :)</p>

<p>To come out of this copy mode (so that you can switch to another screen, and do other such stuff), press <code>]</code> and you are back to normal once again.</p>

<h2 id="some-more-generic-screen-commands:81565885f4011e665cf1e89d6280caf9">Some more generic screen commands</h2>

<p>So that you can start playing around with screens outside OpenStack too</p>

<p>Create a new screen</p>

<pre><code>screen
</code></pre>

<p>To detach from current screen</p>

<pre><code>ctrl+A,D
</code></pre>

<p>To reattach to an existing screen</p>

<pre><code>screen -rd
</code></pre>

<p>To view all the screens, their states and IDs</p>

<pre><code>screen -list
</code></pre>

<p>To kill a screen with id SCREENID</p>

<pre><code>screen -X -S SCREENID kill
</code></pre>

<p>Cheers!</p>

<p>-Rushi Agrawal</p>

  </div>
  
  
  
  <div class="post">
    <h1 class="post-title">
      <a href="http://rushiagr.com/blog/2013/05/27/cinder-on-devstack-quick-start/">
        Cinder on DevStack - Quick Start
      </a>
    </h1>

    <span class="post-date">May 27, 2013</span>

    


    

<p>This blog post covers all the important commands for OpenStack Cinder - The block storage project.
Although this guide is written based on DevStack, it will work with actual deployment of OpenStack
cloud also (except the DevStack/Linux specific bits).</p>

<p>All the Cinder operations can be performed via either of these three means:</p>

<ol>
<li>CLI (Cinder&rsquo;s <code>python-cinderclient</code> command line module)</li>
<li>GUI (Using OpenStack&rsquo;s GUI project <code>horizon</code>)</li>
<li>Directly calling the Cinder APIs</li>
</ol>

<p>Internally, the CLI and GUI both use Cinder APIs to interact with the Cinder API server, but for
a relatively new guy to OpenStack, I think an introduction through CLI would make the most sense.</p>

<p>Assumptions made:</p>

<ol>
<li>You understand how to setup a DevStack environment and already have one ready at hand (remember <code>./stack.sh</code>?)</li>
<li>You know how to pass default credentials to local shell environment (<code>. /home/path_to_your_devstack_repo/eucarc</code> will do)</li>
</ol>

<p>Let&rsquo;s start.</p>

<h3 id="creation-and-deletion-of-volumes:426b24844d0e63b7c5c25db25682ca23">Creation and deletion of volumes</h3>

<p>Create a 1-GB cinder volume with no name by running command <code>cinder create 1</code>.</p>

<pre><code>stack@stlrx300s7-27:/$ cinder create 1
+---------------------+--------------------------------------+
|       Property      |                Value                 |
+---------------------+--------------------------------------+
|     attachments     |                  []                  |
|  availability_zone  |                 nova                 |
|       bootable      |                false                 |
|      created_at     |      2013-05-28T10:32:47.243613      |
| display_description |                 None                 |
|     display_name    |                 None                 |
|          id         | 6754d216-4792-4a38-964a-d002686c8f92 |
|       metadata      |                  {}                  |
|         size        |                  1                   |
|     snapshot_id     |                 None                 |
|     source_volid    |                 None                 |
|        status       |               creating               |
|     volume_type     |                 None                 |
+---------------------+--------------------------------------+
</code></pre>

<p>Here I am describing only the minimal functionality of a command. If you wish to see more info about what all you
can do with that command, just type <code>cinder help &lt;command&gt;</code>, so to see all the optional parameters you can pass
while creating a Cinder volume, execute <code>cinder help create</code>.</p>

<pre><code>stack@stlrx300s7-27:/$ cinder help create
usage: cinder create [--snapshot-id &lt;snapshot-id&gt;]
                     [--source-volid &lt;source-volid&gt;] [--image-id &lt;image-id&gt;]
                     [--display-name &lt;display-name&gt;]
                     [--display-description &lt;display-description&gt;]
                     [--volume-type &lt;volume-type&gt;]
                     [--availability-zone &lt;availability-zone&gt;]
                     [--metadata [&lt;key=value&gt; [&lt;key=value&gt; ...]]]
                     &lt;size&gt;

Add a new volume.

Positional arguments:
  &lt;size&gt;                Size of volume in GB

Optional arguments:
  --snapshot-id &lt;snapshot-id&gt;
                        Create volume from snapshot id (Optional,
                        Default=None)
  --source-volid &lt;source-volid&gt;
                        Create volume from volume id (Optional, Default=None)
  --image-id &lt;image-id&gt;
                        Create volume from image id (Optional, Default=None)
  --display-name &lt;display-name&gt;
                        Volume name (Optional, Default=None)
  --display-description &lt;display-description&gt;
                        Volume description (Optional, Default=None)
  --volume-type &lt;volume-type&gt;
                        Volume type (Optional, Default=None)
  --availability-zone &lt;availability-zone&gt;
                        Availability zone for volume (Optional, Default=None)
  --metadata [&lt;key=value&gt; [&lt;key=value&gt; ...]]
                        Metadata key=value pairs (Optional, Default=None)
</code></pre>

<p>Don&rsquo;t worry about the parameters, we&rsquo;ll use most of them in a short time.</p>

<p>Let&rsquo;s create a Cinder volume of size 1GB with a name, using <code>cinder create --display-name my_second_vol 1</code>:</p>

<pre><code>stack@stlrx300s7-27:/$ cinder create --display-name my_second_vol 1
+---------------------+--------------------------------------+
|       Property      |                Value                 |
+---------------------+--------------------------------------+
|     attachments     |                  []                  |
|  availability_zone  |                 nova                 |
|       bootable      |                false                 |
|      created_at     |      2013-05-28T10:40:32.801981      |
| display_description |                 None                 |
|     display_name    |            my_second_vol             |
|          id         | 25fa2028-46dc-4870-84c5-d062ae99dd7a |
|       metadata      |                  {}                  |
|         size        |                  1                   |
|     snapshot_id     |                 None                 |
|     source_volid    |                 None                 |
|        status       |               creating               |
|     volume_type     |                 None                 |
+---------------------+--------------------------------------+
</code></pre>

<p>Now lets list out all the Cinder volumes, using <code>cinder list</code>:</p>

<pre><code>stack@stlrx300s7-27:/$ cinder list
+--------------------------------------+-----------+---------------+------+-------------+----------+-------------+
|                  ID                  |   Status  |  Display Name | Size | Volume Type | Bootable | Attached to |
+--------------------------------------+-----------+---------------+------+-------------+----------+-------------+
| 25fa2028-46dc-4870-84c5-d062ae99dd7a | available | my_second_vol |  1   |     None    |  false   |             |
| 6754d216-4792-4a38-964a-d002686c8f92 | available |      None     |  1   |     None    |  false   |             |
+--------------------------------------+-----------+---------------+------+-------------+----------+-------------+
</code></pre>

<p>Now lets delete the first volume (the one without a name), using <code>cinder delete &lt;volume_id&gt;</code> command. If you
execute <code>cinder list</code> real quick, you will see the status of the volume going to &lsquo;deleting&rsquo;, and after some time
the volume will be deleted:</p>

<pre><code>stack@stlrx300s7-27:/$ cinder delete 6754d216-4792-4a38-964a-d002686c8f92
stack@stlrx300s7-27:/$ cinder list 
+--------------------------------------+-----------+---------------+------+-------------+----------+-------------+
|                  ID                  |   Status  |  Display Name | Size | Volume Type | Bootable | Attached to |
+--------------------------------------+-----------+---------------+------+-------------+----------+-------------+
| 25fa2028-46dc-4870-84c5-d062ae99dd7a | available | my_second_vol |  1   |     None    |  false   |             |
| 6754d216-4792-4a38-964a-d002686c8f92 |  deleting |      None     |  1   |     None    |  false   |             |
+--------------------------------------+-----------+---------------+------+-------------+----------+-------------+
stack@stlrx300s7-27:/$ 
stack@stlrx300s7-27:/$ 
stack@stlrx300s7-27:/$ cinder list
+--------------------------------------+-----------+---------------+------+-------------+----------+-------------+
|                  ID                  |   Status  |  Display Name | Size | Volume Type | Bootable | Attached to |
+--------------------------------------+-----------+---------------+------+-------------+----------+-------------+
| 25fa2028-46dc-4870-84c5-d062ae99dd7a | available | my_second_vol |  1   |     None    |  false   |             |
+--------------------------------------+-----------+---------------+------+-------------+----------+-------------+
</code></pre>

<p>On a default DevStack installation, for a volume in Cinder, a &lsquo;logical volume&rsquo; is created on the Linux machine,
inside the &lsquo;physical volume&rsquo; named <code>stack-volumes</code>. To see the logical volumes, and physical volumes on the
ubuntu machine, just run <code>lvs</code> (logical volume scan) and <code>pvs</code> (physical volume scan) respectively (this is just
for information and you can entirely skip this part):</p>

<pre><code>stack@stlrx300s7-27:/$ sudo lvs
  LV                                          VG            Attr   LSize Origin Snap%  Move Log Copy%  Convert
  volume-25fa2028-46dc-4870-84c5-d062ae99dd7a stack-volumes -wi-ao 1.00g
stack@stlrx300s7-27:/$
stack@stlrx300s7-27:/$ sudo pvs
  PV         VG            Fmt  Attr PSize PFree
  /dev/loop0 stack-volumes lvm2 a-   5.01g 4.01g
</code></pre>

<h3 id="volume-snapshots:426b24844d0e63b7c5c25db25682ca23">Volume snapshots</h3>

<p>Create the snapshot of volume:</p>

<pre><code>stack@stlrx300s7-27:/$ cinder snapshot-create 25fa2028-46dc-4870-84c5-d062ae99dd7a
+---------------------+--------------------------------------+
|       Property      |                Value                 |
+---------------------+--------------------------------------+
|      created_at     |      2013-05-28T10:55:03.966690      |
| display_description |                 None                 |
|     display_name    |                 None                 |
|          id         | baf8764f-4c9b-496a-b2ff-bd49825c5d09 |
|       metadata      |                  {}                  |
|         size        |                  1                   |
|        status       |               creating               |
|      volume_id      | 25fa2028-46dc-4870-84c5-d062ae99dd7a |
+---------------------+--------------------------------------+
</code></pre>

<p>List all the snapshots:</p>

<pre><code>stack@stlrx300s7-27:/$ cinder snapshot-list
+--------------------------------------+--------------------------------------+-----------+--------------+------+
|                  ID                  |              Volume ID               |   Status  | Display Name | Size |
+--------------------------------------+--------------------------------------+-----------+--------------+------+
| baf8764f-4c9b-496a-b2ff-bd49825c5d09 | 25fa2028-46dc-4870-84c5-d062ae99dd7a | available |     None     |  1   |
+--------------------------------------+--------------------------------------+-----------+--------------+------+
</code></pre>

<p>Now lets create a new volume of 1GB from the snapshot:</p>

<pre><code>stack@stlrx300s7-27:/$ cinder create --snapshot-id baf8764f-4c9b-496a-b2ff-bd49825c5d09 1
+---------------------+--------------------------------------+
|       Property      |                Value                 |
+---------------------+--------------------------------------+
|     attachments     |                  []                  |
|  availability_zone  |                 nova                 |
|       bootable      |                false                 |
|      created_at     |      2013-05-28T10:56:20.478141      |
| display_description |                 None                 |
|     display_name    |                 None                 |
|          id         | 99ebe1d0-678b-4a9a-8ec4-438f9804d327 |
|       metadata      |                  {}                  |
|         size        |                  1                   |
|     snapshot_id     | baf8764f-4c9b-496a-b2ff-bd49825c5d09 |
|     source_volid    |                 None                 |
|        status       |               creating               |
|     volume_type     |                 None                 |
+---------------------+--------------------------------------+
</code></pre>

<p>Now you will see two volumes when you&rsquo;ll do a <code>cinder list</code>.</p>

<h3 id="accessing-volumes-from-inside-a-virtual-instance:426b24844d0e63b7c5c25db25682ca23">Accessing volumes from inside a virtual instance</h3>

<p>You can attach a volume to a VM instance, to provide additional persistent storage to that VM. It
works just like you attach an external HDD to your computer/laptop. But first, we&rsquo;ll need to create a
virtual machine for that.</p>

<p>List out all the virtual machine images present in our DevStack setup, from which we can boot a
brand new VM instance, using <code>glance image-list</code> or &lsquo;nova image-list`:</p>

<pre><code>stack@stlrx300s7-27:/$ nova image-list
+--------------------------------------+---------------------------------+--------+--------+
| ID                                   | Name                            | Status | Server |
+--------------------------------------+---------------------------------+--------+--------+
| 291fe347-3a6f-4a21-9e85-e8809cb05d6e | cirros-0.3.1-x86_64-uec         | ACTIVE |        |
| 69d14d74-4185-4ba3-9666-1e7f569f38c6 | cirros-0.3.1-x86_64-uec-kernel  | ACTIVE |        |
| 8793532d-0c09-4b1c-aab8-d10832f13c09 | cirros-0.3.1-x86_64-uec-ramdisk | ACTIVE |        |
+--------------------------------------+---------------------------------+--------+--------+
</code></pre>

<p>We&rsquo;ll use the image with the shortest name, and boot an instance, giving it a name <code>myinstance</code>.
You can list all the virtual machine instances registered with Nova using command <code>nova list</code>.
If just after running the command to boot the virtual machine, you run <code>nova list</code> a few times,
you will see the machine state going from &lsquo;BUILD&rsquo; to &lsquo;ACTIVE&rsquo; in a few seconds.</p>

<pre><code>stack@stlrx300s7-27:/$ nova boot --flavor m1.tiny --image 291fe347-3a6f-4a21-9e85-e8809cb05d6e myinstance
+-----------------------------+--------------------------------------+
| Property                    | Value                                |
+-----------------------------+--------------------------------------+
| status                      | BUILD                                |
| updated                     | 2013-05-28T11:03:47Z                 |
| OS-EXT-STS:task_state       | scheduling                           |
| key_name                    | None                                 |
| image                       | cirros-0.3.1-x86_64-uec              |
| hostId                      |                                      |
| OS-EXT-STS:vm_state         | building                             |
| flavor                      | m1.tiny                              |
| id                          | 3b6dd9f1-3ca3-4eed-a508-1cd62d55629f |
| security_groups             | [{u'name': u'default'}]              |
| user_id                     | 35708cb6795845fcab6362e908e6b0cf     |
| name                        | myinstance                           |
| adminPass                   | cQh34G96dCHX                         |
| tenant_id                   | 11f8fde7d627422d84036cabd6cbb7f8     |
| created                     | 2013-05-28T11:03:47Z                 |
| OS-DCF:diskConfig           | MANUAL                               |
| metadata                    | {}                                   |
| accessIPv4                  |                                      |
| accessIPv6                  |                                      |
| progress                    | 0                                    |
| OS-EXT-STS:power_state      | 0                                    |
| OS-EXT-AZ:availability_zone | nova                                 |
| config_drive                |                                      |
+-----------------------------+--------------------------------------+
stack@stlrx300s7-27:/$ nova list
+--------------------------------------+------------+--------+------------+-------------+----------+
| ID                                   | Name       | Status | Task State | Power State | Networks |
+--------------------------------------+------------+--------+------------+-------------+----------+
| 3b6dd9f1-3ca3-4eed-a508-1cd62d55629f | myinstance | BUILD  | networking | NOSTATE     |          |
+--------------------------------------+------------+--------+------------+-------------+----------+
stack@stlrx300s7-27:/$ nova list
+--------------------------------------+------------+--------+------------+-------------+----------+
| ID                                   | Name       | Status | Task State | Power State | Networks |
+--------------------------------------+------------+--------+------------+-------------+----------+
| 3b6dd9f1-3ca3-4eed-a508-1cd62d55629f | myinstance | BUILD  | spawning   | NOSTATE     |          |
+--------------------------------------+------------+--------+------------+-------------+----------+
stack@stlrx300s7-27:/$ nova list
+--------------------------------------+------------+--------+------------+-------------+------------------+
| ID                                   | Name       | Status | Task State | Power State | Networks         |
+--------------------------------------+------------+--------+------------+-------------+------------------+
| 3b6dd9f1-3ca3-4eed-a508-1cd62d55629f | myinstance | ACTIVE | None       | Running     | private=10.0.0.2 |
+--------------------------------------+------------+--------+------------+-------------+------------------+
</code></pre>

<p>Now lets attach one of our volume to this instance, and then try to peek into this volume after logging into the instance.</p>

<p>Attach volume using command <code>nova volume-attach &lt;instance_id&gt; &lt;volume_id&gt; &lt;attach_location&gt;</code>. We&rsquo;ll attach at the first
free device location: <code>/dev/vdb</code>:</p>

<pre><code>stack@stlrx300s7-27:/$ nova volume-attach 3b6dd9f1-3ca3-4eed-a508-1cd62d55629f 25fa2028-46dc-4870-84c5-d062ae99dd7a /dev/vdb
+----------+--------------------------------------+
| Property | Value                                |
+----------+--------------------------------------+
| device   | /dev/vdb                             |
| serverId | 3b6dd9f1-3ca3-4eed-a508-1cd62d55629f |
| id       | 25fa2028-46dc-4870-84c5-d062ae99dd7a |
| volumeId | 25fa2028-46dc-4870-84c5-d062ae99dd7a |
+----------+--------------------------------------+
</code></pre>

<p>Now listing the volume will tell you that the volume is attached to an instance (in use):</p>

<pre><code>stack@stlrx300s7-27:/$ cinder list
+--------------------------------------+-----------+---------------+------+-------------+----------+--------------------------------------+
|                  ID                  |   Status  |  Display Name | Size | Volume Type | Bootable |             Attached to              |
+--------------------------------------+-----------+---------------+------+-------------+----------+--------------------------------------+
| 25fa2028-46dc-4870-84c5-d062ae99dd7a |   in-use  | my_second_vol |  1   |     None    |  false   | 3b6dd9f1-3ca3-4eed-a508-1cd62d55629f |
| 99ebe1d0-678b-4a9a-8ec4-438f9804d327 | available |      None     |  1   |     None    |  false   |                                      |
+--------------------------------------+-----------+---------------+------+-------------+----------+--------------------------------------+
</code></pre>

<p>Now let&rsquo;s login into this virtual machine using the private IP of the instance (<code>10.0.0.2</code> in our case). Note how an
error message pops up if you have already created an instance last time when you installed DevStack. If such an error
appears on your screen too, follow the instructions just like the way I did. The default password for the cirros image
we used is <code>cubswin:)</code>. Enter into the instance, and then become root:</p>

<pre><code>stack@stlrx300s7-27:/$ ssh cirros@10.0.0.2
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
@    WARNING: REMOTE HOST IDENTIFICATION HAS CHANGED!     @
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
IT IS POSSIBLE THAT SOMEONE IS DOING SOMETHING NASTY!
Someone could be eavesdropping on you right now (man-in-the-middle attack)!
It is also possible that a host key has just been changed.
The fingerprint for the RSA key sent by the remote host is
f5:ac:45:4c:63:8e:e4:19:cc:5a:76:7e:a1:08:e7:c8.
Please contact your system administrator.
Add correct host key in /opt/stack/.ssh/known_hosts to get rid of this message.
Offending RSA key in /opt/stack/.ssh/known_hosts:4
  remove with: ssh-keygen -f &quot;/opt/stack/.ssh/known_hosts&quot; -R 10.0.0.2
RSA host key for 10.0.0.2 has changed and you have requested strict checking.
Host key verification failed.

stack@stlrx300s7-27:/$ ssh-keygen -f &quot;/opt/stack/.ssh/known_hosts&quot; -R 10.0.0.2
/opt/stack/.ssh/known_hosts updated.
Original contents retained as /opt/stack/.ssh/known_hosts.old
</code></pre>

<pre><code>stack@stlrx300s7-27:/$ ssh cirros@10.0.0.2
The authenticity of host '10.0.0.2 (10.0.0.2)' can't be established.
RSA key fingerprint is f5:ac:45:4c:63:8e:e4:19:cc:5a:76:7e:a1:08:e7:c8.
Are you sure you want to continue connecting (yes/no)? yes
Warning: Permanently added '10.0.0.2' (RSA) to the list of known hosts.
cirros@10.0.0.2's password: 
$sudo -i
#
</code></pre>

<p>Run <code>fdisk -l</code> to see the disks present for the instance. You will see that your newly attached disk
<code>/dev/vdb</code> of size 1GB is now present:</p>

<pre><code># fdisk -l

Disk /dev/vda: 1073 MB, 1073741824 bytes
16 heads, 63 sectors/track, 2080 cylinders, total 2097152 sectors
Units = sectors of 1 * 512 = 512 bytes
Sector size (logical/physical): 512 bytes / 512 bytes
I/O size (minimum/optimal): 512 bytes / 512 bytes
Disk identifier: 0x00000000

Disk /dev/vda doesn't contain a valid partition table

Disk /dev/vdb: 1073 MB, 1073741824 bytes
16 heads, 63 sectors/track, 2080 cylinders, total 2097152 sectors
Units = sectors of 1 * 512 = 512 bytes
Sector size (logical/physical): 512 bytes / 512 bytes
I/O size (minimum/optimal): 512 bytes / 512 bytes
Disk identifier: 0x00000000

Disk /dev/vdb doesn't contain a valid partition table
</code></pre>

<p>Command <code>blkid /dev/vd*</code> lists out the IDs of block devices for this machine and some related info. Running
this command you will see that info of only the virtual disk <code>/dev/vda</code> is present, meaning our disk <code>/dev/vdb</code>
needs formatting.</p>

<pre><code># blkid /dev/vd*
/dev/vda: LABEL=&quot;cirros-rootfs&quot; UUID=&quot;74251bb8-3a28-4a46-9a78-064497b26b9d&quot; SEC_TYPE=&quot;ext2&quot; TYPE=&quot;ext3&quot; 
</code></pre>

<p>Lets format it to make an EXT3 partition with block-size 1024 bytes using command <code>mkfs.ext3 -b 1024 /dev/vdb</code>:</p>

<pre><code># mkfs.ext3 -b 1024 /dev/vdb
mke2fs 1.42.2 (27-Mar-2012)
Filesystem label=
OS type: Linux
Block size=1024 (log=0)
Fragment size=1024 (log=0)
Stride=0 blocks, Stripe width=0 blocks
65536 inodes, 1048576 blocks
52428 blocks (5.00%) reserved for the super user
First data block=1
Maximum filesystem blocks=68157440
128 block groups
8192 blocks per group, 8192 fragments per group
512 inodes per group
Superblock backups stored on blocks: 
        8193, 24577, 40961, 57345, 73729, 204801, 221185, 401409, 663553, 
        1024001

Allocating group tables: done                            
Writing inode tables: done                            
Creating journal (32768 blocks): done
Writing superblocks and filesystem accounting information: done
</code></pre>

<p>Run <code>blkid</code> again to see the newly partitioned disk listed:</p>

<pre><code># blkid /dev/vd*
/dev/vda: LABEL=&quot;cirros-rootfs&quot; UUID=&quot;74251bb8-3a28-4a46-9a78-064497b26b9d&quot; SEC_TYPE=&quot;ext2&quot; TYPE=&quot;ext3&quot; 
/dev/vdb: UUID=&quot;22838e81-eb97-457d-b1e0-4ff3d8e45b05&quot; SEC_TYPE=&quot;ext2&quot; TYPE=&quot;ext3&quot; 
</code></pre>

<p>In order to use this disk, you need to mount it at some location. I&rsquo;ll create a directory <code>/tempmount</code>
and mount our virtual block device there:</p>

<pre><code># mkdir /tempmount
# mount /dev/vdb /tempmount/
</code></pre>

<p>Now you can see the disk listed in the machine disks, using <code>df -h</code> command:</p>

<pre><code># df -h
Filesystem                Size      Used Available Use% Mounted on
/dev                    242.3M         0    242.3M   0% /dev
/dev/vda                 31.0M      9.7M     19.7M  33% /
tmpfs                   245.9M         0    245.9M   0% /dev/shm
tmpfs                   200.0K     76.0K    124.0K  38% /run
/dev/vdb               1007.7M     34.9M    921.6M   4% /tempmount
</code></pre>

<p>Now you can <code>cd</code> into <code>/tempmount</code> directory, and do whatever you want to do with the new disk &ndash; put some files there,
or download one!</p>

<p>Lets wrap up this part. Unmount this volume by <code>umount /tempmount</code>, and log out from the machine by pressing <code>CTRL+D</code> twice, and execute <code>nova volume-detach &lt;server_id&gt; &lt;volume_id&gt;</code> to detach this volume. You can now see the &lsquo;Attached to&rsquo; column becomes empty again after detaching.</p>

<pre><code>stack@stlrx300s7-27:/$ cinder list
+--------------------------------------+-----------+---------------+------+-------------+----------+--------------------------------------+
|                  ID                  |   Status  |  Display Name | Size | Volume Type | Bootable |             Attached to              |
+--------------------------------------+-----------+---------------+------+-------------+----------+--------------------------------------+
| 25fa2028-46dc-4870-84c5-d062ae99dd7a |   in-use  | my_second_vol |  1   |     None    |  false   | 3b6dd9f1-3ca3-4eed-a508-1cd62d55629f |
| 99ebe1d0-678b-4a9a-8ec4-438f9804d327 | available |      None     |  1   |     None    |  false   |                                      |
+--------------------------------------+-----------+---------------+------+-------------+----------+--------------------------------------+
stack@stlrx300s7-27:/$ nova volume-detach 3b6dd9f1-3ca3-4eed-a508-1cd62d55629f 25fa2028-46dc-4870-84c5-d062ae99dd7a
stack@stlrx300s7-27:/$ cinder list
+--------------------------------------+-----------+---------------+------+-------------+----------+-------------+
|                  ID                  |   Status  |  Display Name | Size | Volume Type | Bootable | Attached to |
+--------------------------------------+-----------+---------------+------+-------------+----------+-------------+
| 25fa2028-46dc-4870-84c5-d062ae99dd7a | available | my_second_vol |  1   |     None    |  false   |             |
| 99ebe1d0-678b-4a9a-8ec4-438f9804d327 | available |      None     |  1   |     None    |  false   |             |
+--------------------------------------+-----------+---------------+------+-------------+----------+-------------+
</code></pre>

<h3 id="more-features:426b24844d0e63b7c5c25db25682ca23">More features</h3>

<p>(Will update shortly)</p>

<p>Cheers!</p>

  </div>
  
  
  
  <div class="post">
    <h1 class="post-title">
      <a href="http://rushiagr.com/blog/2013/03/20/openstack-tempest-quick-start-with-devstack/">
        OpenStack Tempest quick start with DevStack
      </a>
    </h1>

    <span class="post-date">Mar 20, 2013</span>

    


    <p>UPDATE(April 2014): Now when you set up DevStack, Tempest is automatically set up for you.</p>

<p>This quick start guide explains setting up Tempest with a DevStack environment
for Grizzly release. Most of the information here is taken from
<a href="http://www.joinfu.com/2012/03/testing-essex-rc1-with-devstack-and-tempest/">here</a>, the only difference being this blog post is more recent, and is based on Grizzly.</p>

<p>Assumptions made are that you understand:
1. What is a <code>localrc</code> file in DevStack.
2. What does <code>./stack.sh</code> do in DevStack.
3. How to clone using git.</p>

<p>##Setting up DevStack</p>

<p>Clone DevStack</p>

<pre><code>git clone https://github.com/openstack-dev/devstack.git
cd devstack
</code></pre>

<p>Tempest requires that the rate-limiting for DevStack is turned off. By default, it is turned on, so turn it off by adding this line to the localrc file.</p>

<pre><code>API_RATE_LIMIT=False
</code></pre>

<p>If you have already created a DevStack environment, you will have to go through the labour of setting it all again by unstacking and restacking it with this parameter in localrc.
Quick tip: If you already had a working DevStack in your computer, adding <code>OFFLINE=True</code> line in localrc will create the DevStack environment in your computer WITHOUT
downloading all the OpenStack code all over again from the Github repos, but will build the environment from the existing code (thus saving you some Internet bandwidth and time).</p>

<p>Build the DevStack environment</p>

<pre><code>./stack.sh
</code></pre>

<p>Supply all the five passwords. (If you are just playing around, just like me, then
you can easily supply <code>nova</code> to all the passwords.)</p>

<p>Note the IP of the system where DevStack is running (The &lsquo;host IP&rsquo; mentioned at the last of the output after running <code>stack.sh</code>).</p>

<p>##Setting up Tempest</p>

<p>Clone latest Tempest code</p>

<pre><code>git clone https://github.com/openstack/tempest.git
cd tempest
</code></pre>

<p>Create tempest.conf file from the sample configuration file. This file will contain the configuration information of the OpenStack environment (here, the DevStack
environment)</p>

<pre><code>cp etc/tempest.conf.sample etc/tempest.conf
</code></pre>

<p>Now open the file tempest.conf in an editor, and replace all instance of word <code>secret</code> with the appropriate password (<code>nova</code> if you followed me, and just typed <code>nova</code> whenever the
<code>stack.sh</code> script asked for passwords)</p>

<p>If, for example, your host IP is 10.0.24.30, change this line in tempest.conf</p>

<pre><code>uri = http://127.0.0.1:5000/v2.0/
</code></pre>

<p>to make it</p>

<pre><code>uri = http://10.0.24.30:5000/v2.0/
</code></pre>

<p>The last thing to update in the tempest.conf file is the ID of the Cirros image. The image ID can be obtained by two ways
####Image ID using glance
This command will return the image ID. Note that I have used the password <code>nova</code> in this line. You might also need to change the host IP address</p>

<pre><code>glance -I admin -K nova -T admin -N http://10.0.24.30:5000/v2.0 -S keystone index | grep ami | cut -f1 | awk '{print $1}'
</code></pre>

<p>####Image ID using OpenStack CLI
Become stack user</p>

<pre><code>su - stack
</code></pre>

<p>Source the sample credentials file</p>

<pre><code>. /opt/stack/devstack/eucarc
</code></pre>

<p>OR</p>

<pre><code>. /opt/stack/devstack/openrc
</code></pre>

<p>Show all the images, with their IDs</p>

<pre><code>$ nova image-list
+--------------------------------------+---------------------------------+--------+--------+
| ID                                   | Name                            | Status | Server |
+--------------------------------------+---------------------------------+--------+--------+
| 13abf9c8-5603-48cb-802e-e27162e10b58 | cirros-0.3.0-x86_64-uec         | ACTIVE |        |
| 39b023ae-9201-427d-8350-4f30e5bbc01a | cirros-0.3.0-x86_64-uec-kernel  | ACTIVE |        |
| 431a9c04-47b1-47e4-9521-7f12295c78e0 | cirros-0.3.0-x86_64-uec-ramdisk | ACTIVE |        |
+--------------------------------------+---------------------------------+--------+--------+
</code></pre>

<p>The ID of the smallest image name is what we&rsquo;re interested in.</p>

<p>Now replace <code>{$IMAGE_ID}</code> and <code>{$IMAGE_ID_ALT}</code> with this value, to make those two lines appear in tempest.conf as</p>

<pre><code>image_ref = 13abf9c8-5603-48cb-802e-e27162e10b58
image_ref_alt = 13abf9c8-5603-48cb-802e-e27162e10b58
</code></pre>

<p>##Installing required dependencies
Install all the required packages needed to run Tempest integration test suite. (The list of required packages is maintained in file <code>tools/pip-requires</code>)</p>

<pre><code>$ sudo pip install -r tools/pip-requires 
</code></pre>

<p>##Show time!
We&rsquo;ll run all the tests in verbose mode. To run all the tests:</p>

<pre><code>nosetests -v tempest
</code></pre>

<p>To run tests only from a specific file, say <code>tempest/tests/volume/test_volumes_list.py</code>:</p>

<pre><code>nosetests -sv tempest.tests.volume.test_volumes_list
</code></pre>

<p>OR</p>

<pre><code>nosetests -sv tempest.tests.volume.test_volumes_list.py
</code></pre>

<p>To run a specific test <code>test_volume_list_with_details</code> from test class <code>VolumeListTest</code>, which resides in the above file:</p>

<pre><code>    nosetests -sv tempest.tests.volume.test_volumes_list:VolumeListTest.test_volume_list_with_details
</code></pre>

<p>And that ladies and gentlemen, is the end! :)</p>

  </div>
  
  
  
  <div class="post">
    <h1 class="post-title">
      <a href="http://rushiagr.com/blog/2013/03/19/github-cheat-sheet/">
        Git(hub) Cheat Sheet
      </a>
    </h1>

    <span class="post-date">Mar 19, 2013</span>

    


    

<p>I am posting my github cheat sheet here. I started writing it as soon as I started
learning Github and Git. So, some of the content here can appear quite naive.
I will try to keep this blog post as updated as I can, and if you find any
suggestion, please comment!</p>

<p>This post is just for a reference of commands. This post will be a bad way to learn
how git works. A basic understanding of git is assumed.</p>

<p>##Initial configuration
Configure user details only for the first time</p>

<pre><code>git config --global user.name &quot;Rushi Agrawal&quot;
git config --global user.email &quot;rushi.agr@gmail.com&quot;
</code></pre>

<p>To check your git configuration</p>

<pre><code>git config --list
</code></pre>

<p>##Branches
List all branches in the local repo</p>

<pre><code>git branch
</code></pre>

<p>List all branches including remote-tracking branches</p>

<pre><code>git branch -r
</code></pre>

<p>List all branches (including the ones at remote)</p>

<pre><code>git branch -a
</code></pre>

<p>Creating your own branch <code>my_branch</code>, with content same as your current branch</p>

<pre><code>git branch my_branch
</code></pre>

<p>Switch to the newly created branch</p>

<pre><code>git checkout my_branch
</code></pre>

<p>Execute the above two commands in one line:</p>

<pre><code>git checkout -b my_branch
</code></pre>

<p>to pull a branch <code>only_remote</code> which exists at github (at remote <code>rushiagr</code> but not in local repo. (More about <code>git remote update</code> later)</p>

<pre><code>git remote update
git checkout -b only_remote rushiagr/only_remote
</code></pre>

<h2 id="remotes:04d9bb0940f5046aa10fc2c8ba66e73a">Remotes</h2>

<p>Create a new remote <code>rushiagr</code> which will track <code>cinder</code> repository by user <code>rushiagr</code></p>

<pre><code>git remote add rushiagr https://github.com/rushiagr/cinder.git
</code></pre>

<p>If this is your personal repo, you can append the username in the remote as shown. After that, every time you push to the origin,
github will not ask for your username but only password.</p>

<pre><code>git remote add rushiagr https://rushiagr@github.com/rushiagr/cinder.git
</code></pre>

<p>Delete the remote <code>rushiagr</code></p>

<pre><code>git remote rm rushiagr
</code></pre>

<p>List all the remotes</p>

<pre><code>git remote
</code></pre>

<p>The above command only shows the names of remotes. To also check the links to the remotes:</p>

<pre><code>git remote -v
</code></pre>

<p>Now this is very important command.</p>

<pre><code>git remote update
</code></pre>

<p>This will contact the git server, and will update the local repository with ALL the content at ALL those remotes. The interesting part is, nothing will actually change. That is, no more new branches (which got created at the server after you last pulled from the server) were created, and the existing branches are also not updated. BUT, all the content goes into the magic <code>.git</code> directory. After you&rsquo;ve run this command, when you create a branch only existing at remote, the local git repo will not contact the server but will fetch all the contents from within the repository.</p>

<p>To take a new branch from remote, and create a new branch having contents of that remote branch. (You might need to run &lsquo;git remote update&rsquo;)</p>

<pre><code>git checkout -b stable/folsom origin/stable/folsom
</code></pre>

<h2 id="push:04d9bb0940f5046aa10fc2c8ba66e73a">Push</h2>

<p>Pushing this newly created branch to remote <code>rushiagr</code></p>

<pre><code>git push rushiagr my_branch
</code></pre>

<p>If you want to push the local branch <code>my_branch</code> with a different name to
remote, say <code>my_remote_branch</code>:</p>

<pre><code>git push rushiagr my_branch:my_remote_branch
</code></pre>

<p>To create an association with the remote (only first time):</p>

<pre><code>git push -u origin my_branch
</code></pre>

<p>or</p>

<pre><code>git push --set-upstream origin my_branch
</code></pre>

<h2 id="pull:04d9bb0940f5046aa10fc2c8ba66e73a">Pull</h2>

<p>Git pullis nothing more than a macro that doesgit fetchandgit merge, in
that order. The common syntax to pull from branch <code>remote_branch</code> located at remote <code>remote_name</code> to the current active branch in the local repo:</p>

<pre><code>git pull remote_name remote_branch
</code></pre>

<h2 id="oops-i-didn-t-intend-to-do-that:04d9bb0940f5046aa10fc2c8ba66e73a">Oops! I didn&rsquo;t intend to do that!</h2>

<p>####To undo last commit.
This will just undo the commit, but will keep changes, so that you can modify the files and commit again</p>

<pre><code>git reset --soft HEAD^
</code></pre>

<p>####To not keep the uncommitted changes.
This command will wipe off all the changes which are not committed. Very useful when you made some changes but dont want to commit it. All the more useful when you <code>pull</code>ed something but everything became a mess (possibly due to a merge conflict, or pulling to/from a different branch!)</p>

<pre><code>git reset --hard
</code></pre>

<p>####To delete a branch <code>timepass_testing</code> from github server</p>

<pre><code>git push rushiagr --delete timepass_testing
</code></pre>

<p>(NOT <code>git push rushiagr --delete rushiagr/timepass_testing</code>)
####Change author of the last commit</p>

<pre><code>git commit --amend --author=&quot;Rushi Agrawal &lt;rushi.agr@gmail.com&gt;&quot;
</code></pre>

<p>You committed some changes, but then you realised you wanted to add this one line to the commit. In such a case
just add that one line, and run this command to have this last change incorporated into that previous commit. This command also gives you an option to
change the commit message.</p>

<pre><code>git commit -a --amend
</code></pre>

<h2 id="show-me-the-money:04d9bb0940f5046aa10fc2c8ba66e73a">Show me the money</h2>

<p>To see the patch of the last commit without undoing the last commit</p>

<pre><code>git show
</code></pre>

<p>To see the changes introduced by any earlier commit with commit id <code>c5bb6d821e10ca8f114fa0b3b0149bc8b7257a92</code></p>

<pre><code>git show c5bb6d821e10ca8f114fa0b3b0149bc8b7257a92
</code></pre>

<p>To see the latest changes you made &ndash; the changes which have not been staged to be committed</p>

<pre><code>git diff
</code></pre>

<p>You can redirect the output from the above three commands to a file, to create corresponding patch file.</p>

<h2 id="patching-in-git:04d9bb0940f5046aa10fc2c8ba66e73a">Patching in git</h2>

<p>Check the status of patch. How many lines changed, etc</p>

<pre><code>git apply --stat patchfile
</code></pre>

<p>Check if the patch can be applied.
If no output or no error, patch can be applied safely</p>

<pre><code>git apply --check patchfile
</code></pre>

<p>Apply patch with signing-off (better way)</p>

<pre><code>git am --signoff &lt; patchfile
</code></pre>

<p>Normal way of applying patch</p>

<pre><code>git apply patchfile
</code></pre>

<p>##Miscellaneous</p>

<p>To pull only specific files from another branch: (here, assuming that we have two branches, &lsquo;test&rsquo;, and &lsquo;master&rsquo;, and currently we are on &lsquo;master&rsquo; branch. If you want to pull ##only &lsquo;testfile.py&rsquo; file from &lsquo;test&rsquo; branch to &lsquo;master&rsquo; branch, do this:)</p>

<pre><code>git checkout test testfile.py1
</code></pre>

<p>If your master changed while you were working on your topic_branch, and if you want to merge the master&rsquo;s changes, and also get an option to squash the changes you made on topic_branch:</p>

<pre><code>git checkout master
git pull origin master
git checkout topic_branch
git rebase -i master
</code></pre>

<p><a href="http://christoph.ruegg.name/blog/2010/5/5/git-howto-revert-a-commit-already-pushed-to-a-remote-reposit.html">Undo last commit at the remote repo</a></p>

<p>(you can use git revert, but dont know how exactly it works)</p>

<p>Clone a specific branch git repository from github</p>

<pre><code>git clone -b stable/essex https://github.com/openstack-dev/devstack.git
</code></pre>

<p><a href="https://makandracards.com/makandra/527-squash-several-git-commits-into-a-single-commit">Squash several commits into one single commit</a></p>

<p>Checkout a previous commit with SHA commit id cff2580ad7bc16934b72dd9be7463eb090b31d55 from the current branch to a new branch &lsquo;neew&rsquo;</p>

<pre><code>git checkout -b neew cff2580ad7bc16934b72dd9be7463eb090b31d55
</code></pre>

  </div>
  
  
  
  <div class="post">
    <h1 class="post-title">
      <a href="http://rushiagr.com/blog/2013/01/02/bye-bye-2012-welcome-2013/">
        Bye-Bye 2012, Welcome 2013
      </a>
    </h1>

    <span class="post-date">Jan 2, 2013</span>

    


    

<p>Listing down the things which went well for me in 2012, and which didn&rsquo;t, and the plans for upcoming year 2013. Beware: More technical stuff than emotional.</p>

<h2 id="things-which-went-well-in-2012:99646ca7efbf03e7e0246d61a4261ee0">Things which went well in 2012</h2>

<h4 id="python:99646ca7efbf03e7e0246d61a4261ee0">Python</h4>

<p>Started learning Python at the start of year 2012, early January, and this same language landed me in the job which I absolutely love: working in one of the biggest &lsquo;OpenSource&rsquo; project in the world, written in Python! Getting paid for working on an opensource project is as awesome as it can become for me.</p>

<h4 id="the-hunger-to-become-different-from-the-rest:99646ca7efbf03e7e0246d61a4261ee0">The hunger to become different from the rest</h4>

<p>Gathered a lot of info on how things work in computer industry. Kept myself in contact with various hot topics, opensource projects.</p>

<h4 id="the-job:99646ca7efbf03e7e0246d61a4261ee0">The job</h4>

<p>Not faring too well on this front - the full time job. But still, I would consider I did good enough with regards to the work assigned to me. I, after six months into the job, still goes to office every morning with a thirst to make a difference.</p>

<h4 id="cleanliness:99646ca7efbf03e7e0246d61a4261ee0">Cleanliness</h4>

<p>Scored much better in the second half. Spent dedicated amount of time each week to keep my room and flat clean and in order.</p>

<h4 id="maintaining-a-todo-list:99646ca7efbf03e7e0246d61a4261ee0">Maintaining a TODO list</h4>

<p>Started late in the year, but seems a good progress on that front.</p>

<h2 id="things-which-didn-t-go-that-well-in-2012:99646ca7efbf03e7e0246d61a4261ee0">Things which didn&rsquo;t go that well in 2012</h2>

<h4 id="concentration:99646ca7efbf03e7e0246d61a4261ee0">Concentration</h4>

<p>Still not able to concentrate on one thing for long. Get distracted too easily. Only rarely I sat at one place, focussed on one thing, for more than 50 minutes. Also, the last year&rsquo;s resolution of opening FaceBook only once a day was put in trashcan on in the very first week of January!</p>

<h4 id="not-focussed-enough-on-the-future-direction:99646ca7efbf03e7e0246d61a4261ee0">Not focussed enough on the future direction</h4>

<p>Poor goal setting. Peeked into a lot of opensource projects, dedicated proper time into none. Opensourced my projects too, but did not work on it much either. Made myself a perfect example of &lsquo;naam bade aur darshan chhote&rsquo; (appearing like an eminent personality, acting like a jerk).</p>

<h4 id="programming-contest:99646ca7efbf03e7e0246d61a4261ee0">Programming contest</h4>

<p>Only kept in touch. Not solved much problems. This year, need to focus a lot on this front.</p>

<h4 id="time-management:99646ca7efbf03e7e0246d61a4261ee0">Time management</h4>

<p>Never was able to manage time. Was not working on the same thing for even a week. Somewhere in the middle of working on a project, I find out &lsquo;hey, this looks cool! Time to try hands on it!&rsquo;. What about the thingy you were currently working on? Into the TODO list! Such an idiot.</p>

<h4 id="work-life-balance:99646ca7efbf03e7e0246d61a4261ee0">Work life balance</h4>

<p>Went for a toss. Not able to regularise job timings. Started and stopped gym. Started and stopped working on many projects. Completed none. Wasted a heck of a lot of time.</p>

<h2 id="plans-for-upcoming-year:99646ca7efbf03e7e0246d61a4261ee0">Plans for upcoming year</h2>

<h4 id="better-planning:99646ca7efbf03e7e0246d61a4261ee0">Better planning</h4>

<p>I need to plan things before acting on it. I would take everything into consideration before jumping into hacking something, and then set a deadline for it. And till that deadline, I would promise I would not digress getting enticed by something which makes my mouth watery.</p>

<h4 id="don-t-just-outright-neglect-daytime-job:99646ca7efbf03e7e0246d61a4261ee0">Don&rsquo;t just outright neglect daytime job</h4>

<p>I agree my daytime job is awesome. But I end up considering the work I do at office as secondary. Need to value it much higher. I concentrate on other projects and aim to complete and polish them. What I did not thought was the work I am doing in my job itself is a project! If I am not faring well in the project on which I work 8 hours a day, how can I expect myself to do good in something I am spending only a fraction of time I spend on the daytime project! And expectedly, none of my projects are in good enough shape to talk about it confidently in public. I need to value OpenStack more. Really.</p>

<h4 id="start-coding-for-programming-contests:99646ca7efbf03e7e0246d61a4261ee0">START coding for programming contests</h4>

<p>Enough of promises, enough of &lsquo;From next month I&rsquo;m gonna do it&rsquo;. I SHOULD spend a specific time every week for coding for programming contests. Looks like I need to start with solving old problems from CodeChef.com alongwith the editorials provided with them.</p>

<h4 id="facebook-once-in-a-day:99646ca7efbf03e7e0246d61a4261ee0">Facebook once in a day</h4>

<p>Period.</p>

<h4 id="need-to-plan-breaks-too:99646ca7efbf03e7e0246d61a4261ee0">Need to plan breaks too</h4>

<p>Realised only the last month that opening facebook, checking out news, and reading articles on Hacker News does not count in a break. A break is not in front of a computer screen. A break is something which gives your strained eyes a rest, especially when you end up spending half of your year staring at a computer screen!</p>

<p>PS. The article is for the writer himself. It is okay if you are finding it a bad piece of English text.</p>

  </div>
  
  
  
  <div class="post">
    <h1 class="post-title">
      <a href="http://rushiagr.com/blog/2012/12/15/testing-the-new-blog/">
        Testing the new blog
      </a>
    </h1>

    <span class="post-date">Dec 15, 2012</span>

    


    

<p>This is a test blog, just to check out some of the basic functionalities of
MarkDown. Visit the MarkDown source of this blog post <a href="https://raw.github.com/rushiagr/rushiagr.github.com/source/source/_posts/2012-12-15-testing-the-new-blog.markdown">here</a>
to understand the simplicity with which a post can be written using MarkDown!</p>

<!-- more -->

<h2 id="this-is-a-subheading:636b095ce918d91cdf51da5ad4a6cada">This is a subheading</h2>

<p>And below is an example of H1 heading in the main text</p>

<h1 id="the-heading:636b095ce918d91cdf51da5ad4a6cada">THE heading</h1>

<p>And below is sub-subheading</p>

<h3 id="the-h3-heading:636b095ce918d91cdf51da5ad4a6cada">The H3 heading</h3>

<p>Trying a smaller heading:</p>

<h4 id="the-sub-sub-subheading:636b095ce918d91cdf51da5ad4a6cada">The sub sub subheading</h4>

<p>Following is a block of syntax-highlighted python code.</p>

<pre><code class="language-python">def factorial(number):
    answer = 1
    for counter in range(1, number+1):
        answer *= counter
    return answer
</code></pre>

<p>To write a monospace block, enclose it in backticks. An example would be a directory location: <code>/home/rushi/Desktop/</code> is where the files on my desktop
reside.</p>

<p>Here is an embedded image:</p>

<p>{% img <a href="http://rushiagr.github.com/images/bird_32_gray.png">http://rushiagr.github.com/images/bird_32_gray.png</a> %}</p>

<p>Thank you!</p>

  </div>
  
  
</div>


  </body>
</html>
